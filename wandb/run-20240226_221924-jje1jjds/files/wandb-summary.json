{"total episode rewards during training": {"adversary_0": -21.402687072753906, "agent_0": -22.12494468688965, "agent_1": -22.12494468688965, "agent_2": -22.12494468688965}, "_timestamp": 1708982672.3363264, "_runtime": 307.5870282649994, "_step": 5145, "training Loss for agent0": 0.06165546923875809, "training Loss for agent1": 0.16322627663612366, "training Loss for agent2": 0.1222306415438652, "training Loss for agent3": 0.06617632508277893, "training step": 981, "evaluation_env  avg_reward": {"adversary_0": -66.37317734001442, "agent_0": 26.759942078789464, "agent_1": 26.759942078789464, "agent_2": 26.759942078789464}, "total steps": 1123, "episode": 44, "_wandb": {"runtime": 306}}