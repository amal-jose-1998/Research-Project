{"total episode rewards during training": {"adversary_0": -21.402687072753906, "agent_0": -22.12494468688965, "agent_1": -22.12494468688965, "agent_2": -22.12494468688965}, "_timestamp": 1708983778.8128028, "_runtime": 293.2084639072418, "_step": 5145, "training Loss for agent0": 0.2760046124458313, "training Loss for agent1": 0.2802172601222992, "training Loss for agent2": 0.14434023201465607, "training Loss for agent3": 0.13944192230701447, "training step": 981, "evaluation_env  avg_reward": {"adversary_0": -35.5842937089342, "agent_0": 2.3212937230349544, "agent_1": 2.3212937230349544, "agent_2": 2.3212937230349544}, "total steps": 1123, "episode": 44, "_wandb": {"runtime": 292}}