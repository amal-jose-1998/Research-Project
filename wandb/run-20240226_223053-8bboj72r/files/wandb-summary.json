{"total episode rewards during training": {"adversary_0": -21.402687072753906, "agent_0": -22.12494468688965, "agent_1": -22.12494468688965, "agent_2": -22.12494468688965}, "_timestamp": 1708983333.6175413, "_runtime": 279.7137134075165, "_step": 5145, "training Loss for agent0": 0.2760046124458313, "training Loss for agent1": 0.2753557562828064, "training Loss for agent2": 0.13560998439788818, "training Loss for agent3": 0.08573400974273682, "training step": 981, "evaluation_env  avg_reward": {"adversary_0": -35.5842937089342, "agent_0": 9.298173798305786, "agent_1": 9.298173798305786, "agent_2": 9.298173798305786}, "total steps": 1123, "episode": 44, "_wandb": {"runtime": 279}}