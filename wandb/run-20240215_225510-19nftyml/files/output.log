episode: 0
0.9999902
episode:  0 training step:  3 loss of agent  0 :  2.7995831966400146
0.9999902
episode:  0 training step:  3 loss of agent  0 :  0.5397212505340576
0.9999902
episode:  0 training step:  3 loss of agent  0 :  0.5321141481399536
0.9999804
episode:  0 training step:  6 loss of agent  1 :  2.9396212100982666
0.9999804
episode:  0 training step:  6 loss of agent  1 :  0.5259759426116943
0.9999804
episode:  0 training step:  6 loss of agent  1 :  0.519067645072937
0.9999706
episode:  0 training step:  9 loss of agent  3 :  2.914602756500244
0.9999706
episode:  0 training step:  9 loss of agent  3 :  0.44533073902130127
0.9999706
episode:  0 training step:  9 loss of agent  3 :  0.5197957158088684
0.9999608
episode:  0 training step:  12 loss of agent  3 :  2.7574470043182373
0.9999608
episode:  0 training step:  12 loss of agent  3 :  0.43840211629867554
0.9999608
episode:  0 training step:  12 loss of agent  3 :  0.49967509508132935
0.999951
episode:  0 training step:  15 loss of agent  1 :  2.8581016063690186
0.999951
episode:  0 training step:  15 loss of agent  1 :  0.44285374879837036
0.999951
episode:  0 training step:  15 loss of agent  1 :  0.5545234680175781
0.9999412
episode:  0 training step:  18 loss of agent  4 :  2.8568618297576904
0.9999412
episode:  0 training step:  18 loss of agent  4 :  0.44731903076171875
0.9999412
episode:  0 training step:  18 loss of agent  4 :  0.5229986906051636
0.9999314
episode:  0 training step:  21 loss of agent  2 :  2.6810152530670166
0.9999314
episode:  0 training step:  21 loss of agent  2 :  0.43060240149497986
0.9999314
episode:  0 training step:  21 loss of agent  2 :  0.5037121772766113
0.9999216
episode:  0 training step:  24 loss of agent  0 :  2.511315107345581
0.9999216
episode:  0 training step:  24 loss of agent  0 :  0.33799973130226135
0.9999216
episode:  0 training step:  24 loss of agent  0 :  0.3721958100795746
0.9999118
episode:  0 training step:  27 loss of agent  2 :  2.7701427936553955
0.9999118
episode:  0 training step:  27 loss of agent  2 :  0.3326055705547333
0.9999118
episode:  0 training step:  27 loss of agent  2 :  0.39008668065071106
0.999902
episode:  0 training step:  30 loss of agent  1 :  2.4405016899108887
0.999902
episode:  0 training step:  30 loss of agent  1 :  0.26703548431396484
0.999902
episode:  0 training step:  30 loss of agent  1 :  0.3957459032535553
Traceback (most recent call last):
  File "c:\Users\amalj\OneDrive\Desktop\lecture materials\S3\Research Project\Local Git Repo\Adversarial-MATL\Transfer learning in simple adversarial MPE env\main.py", line 138, in <module>
    main()
  File "c:\Users\amalj\OneDrive\Desktop\lecture materials\S3\Research Project\Local Git Repo\Adversarial-MATL\Transfer learning in simple adversarial MPE env\main.py", line 81, in main
    wandb.log({f'episode {j} terminated at global step {e}'})
  File "C:\Users\amalj\anaconda3\lib\site-packages\wandb\sdk\wandb_run.py", line 368, in wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\amalj\anaconda3\lib\site-packages\wandb\sdk\wandb_run.py", line 331, in wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\amalj\anaconda3\lib\site-packages\wandb\sdk\wandb_run.py", line 1712, in log
    self._log(data=data, step=step, commit=commit)
  File "C:\Users\amalj\anaconda3\lib\site-packages\wandb\sdk\wandb_run.py", line 1489, in _log
    raise ValueError("wandb.log must be passed a dictionary")
ValueError: wandb.log must be passed a dictionary
0.9998922
episode:  0 training step:  33 loss of agent  0 :  2.8584601879119873
0.9998922
episode:  0 training step:  33 loss of agent  0 :  0.5489419102668762
0.9998922
episode:  0 training step:  33 loss of agent  0 :  0.5794291496276855
0.9998824
episode:  0 training step:  36 loss of agent  0 :  3.130964756011963
0.9998824
episode:  0 training step:  36 loss of agent  0 :  0.4850572943687439
0.9998824
episode:  0 training step:  36 loss of agent  0 :  0.5253592729568481
0.9998726
episode:  0 training step:  39 loss of agent  3 :  2.735349655151367
0.9998726
episode:  0 training step:  39 loss of agent  3 :  0.5521640777587891
0.9998726
episode:  0 training step:  39 loss of agent  3 :  0.4933711588382721
0.9998628
episode:  0 training step:  42 loss of agent  4 :  3.009509801864624
0.9998628
episode:  0 training step:  42 loss of agent  4 :  0.48648035526275635
0.9998628
episode:  0 training step:  42 loss of agent  4 :  0.4970274567604065
0.999853
episode:  0 training step:  45 loss of agent  3 :  2.7683210372924805
0.999853
episode:  0 training step:  45 loss of agent  3 :  0.4679662585258484
0.999853
episode:  0 training step:  45 loss of agent  3 :  0.49822402000427246
0.9998432
episode:  0 training step:  48 loss of agent  3 :  2.5681800842285156
0.9998432
episode:  0 training step:  48 loss of agent  3 :  0.45755648612976074
0.9998432
episode:  0 training step:  48 loss of agent  3 :  0.5552135705947876
episode 0 terminated at 100