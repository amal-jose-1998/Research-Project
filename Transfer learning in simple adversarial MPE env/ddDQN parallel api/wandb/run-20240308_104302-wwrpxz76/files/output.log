----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 5, 6]              20
              ReLU-2                 [-1, 5, 6]               0
            Conv1d-3                [-1, 10, 4]             160
              ReLU-4                [-1, 10, 4]               0
            Conv1d-5                [-1, 15, 4]             465
              ReLU-6                [-1, 15, 4]               0
            Conv1d-7                [-1, 20, 4]             920
              ReLU-8                [-1, 20, 4]               0
            Conv1d-9                [-1, 25, 4]           1,525
             ReLU-10                [-1, 25, 4]               0
           Conv1d-11                [-1, 30, 2]           2,280
             ReLU-12                [-1, 30, 2]               0
          Flatten-13                   [-1, 60]               0
           Linear-14                  [-1, 100]           6,100
             ReLU-15                  [-1, 100]               0
           Linear-16                    [-1, 1]             101
           Linear-17                    [-1, 5]             505
================================================================
Total params: 12,076
Trainable params: 12,076
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.05
Estimated Total Size (MB): 0.05
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 5, 6]              20
              ReLU-2                 [-1, 5, 6]               0
            Conv1d-3                [-1, 10, 4]             160
              ReLU-4                [-1, 10, 4]               0
            Conv1d-5                [-1, 15, 4]             465
              ReLU-6                [-1, 15, 4]               0
            Conv1d-7                [-1, 20, 4]             920
              ReLU-8                [-1, 20, 4]               0
            Conv1d-9                [-1, 25, 4]           1,525
             ReLU-10                [-1, 25, 4]               0
           Conv1d-11                [-1, 30, 2]           2,280
             ReLU-12                [-1, 30, 2]               0
          Flatten-13                   [-1, 60]               0
           Linear-14                  [-1, 100]           6,100
             ReLU-15                  [-1, 100]               0
           Linear-16                    [-1, 1]             101
           Linear-17                    [-1, 5]             505
================================================================
Total params: 12,076
Trainable params: 12,076
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.05
Estimated Total Size (MB): 0.05
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                 [-1, 1, 8]             104
          Inputnet-2                 [-1, 1, 8]               0
            Conv1d-3                 [-1, 5, 6]              20
              ReLU-4                 [-1, 5, 6]               0
            Conv1d-5                [-1, 10, 4]             160
              ReLU-6                [-1, 10, 4]               0
            Conv1d-7                [-1, 15, 4]             465
              ReLU-8                [-1, 15, 4]               0
            Conv1d-9                [-1, 20, 4]             920
             ReLU-10                [-1, 20, 4]               0
           Conv1d-11                [-1, 25, 4]           1,525
             ReLU-12                [-1, 25, 4]               0
           Conv1d-13                [-1, 30, 2]           2,280
             ReLU-14                [-1, 30, 2]               0
          Flatten-15                   [-1, 60]               0
           Linear-16                  [-1, 100]           6,100
             ReLU-17                  [-1, 100]               0
           Linear-18                    [-1, 1]             101
           Linear-19                    [-1, 5]             505
         dddQ_Net-20  [[-1, 1], [-1, 5], [-1, 5]]               0
           Linear-21                    [-1, 5]              30
        Outputnet-22                    [-1, 5]               0
================================================================
Total params: 12,210
Trainable params: 12,210
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.05
Estimated Total Size (MB): 0.05
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                [-1, 1, 10]             150
          Inputnet-2                [-1, 1, 10]               0
            Conv1d-3                 [-1, 4, 8]              16
              ReLU-4                 [-1, 4, 8]               0
            Conv1d-5                 [-1, 8, 6]             104
              ReLU-6                 [-1, 8, 6]               0
            Conv1d-7                [-1, 16, 4]             400
              ReLU-8                [-1, 16, 4]               0
            Conv1d-9                [-1, 32, 4]             544
             ReLU-10                [-1, 32, 4]               0
          Flatten-11                  [-1, 128]               0
           Linear-12                  [-1, 100]          12,900
             ReLU-13                  [-1, 100]               0
           Linear-14                    [-1, 1]             101
           Linear-15                    [-1, 5]             505
         dddQ_Net-16  [[-1, 1], [-1, 5], [-1, 5]]               0
           Linear-17                    [-1, 5]              30
        Outputnet-18                    [-1, 5]               0
================================================================
Total params: 14,750
Trainable params: 14,750
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                [-1, 1, 10]             150
          Inputnet-2                [-1, 1, 10]               0
            Conv1d-3                 [-1, 4, 8]              16
              ReLU-4                 [-1, 4, 8]               0
            Conv1d-5                 [-1, 8, 6]             104
              ReLU-6                 [-1, 8, 6]               0
            Conv1d-7                [-1, 16, 4]             400
              ReLU-8                [-1, 16, 4]               0
            Conv1d-9                [-1, 32, 4]             544
             ReLU-10                [-1, 32, 4]               0
          Flatten-11                  [-1, 128]               0
           Linear-12                  [-1, 100]          12,900
             ReLU-13                  [-1, 100]               0
           Linear-14                    [-1, 1]             101
           Linear-15                    [-1, 5]             505
         dddQ_Net-16  [[-1, 1], [-1, 5], [-1, 5]]               0
           Linear-17                    [-1, 5]              30
        Outputnet-18                    [-1, 5]               0
================================================================
Total params: 14,750
Trainable params: 14,750
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                [-1, 1, 10]             150
          Inputnet-2                [-1, 1, 10]               0
            Conv1d-3                 [-1, 4, 8]              16
              ReLU-4                 [-1, 4, 8]               0
            Conv1d-5                 [-1, 8, 6]             104
              ReLU-6                 [-1, 8, 6]               0
            Conv1d-7                [-1, 16, 4]             400
              ReLU-8                [-1, 16, 4]               0
            Conv1d-9                [-1, 32, 4]             544
             ReLU-10                [-1, 32, 4]               0
          Flatten-11                  [-1, 128]               0
           Linear-12                  [-1, 100]          12,900
             ReLU-13                  [-1, 100]               0
           Linear-14                    [-1, 1]             101
           Linear-15                    [-1, 5]             505
         dddQ_Net-16  [[-1, 1], [-1, 5], [-1, 5]]               0
           Linear-17                    [-1, 5]              30
        Outputnet-18                    [-1, 5]               0
================================================================
Total params: 14,750
Trainable params: 14,750
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
episode: 0
epoch: 1
episode 0 terminated at 25
epoch: 2
episode 0 terminated at 50
episode: 1
epoch: 1
episode 1 terminated at 75
epoch: 2
episode 1 terminated at 100
episode: 2
epoch: 1
episode:  2 training step:  1 loss of agent  0 :  0.502913773059845
episode:  2 training step:  1 loss of agent  1 :  0.39132168889045715
episode:  2 training step:  1 loss of agent  2 :  0.4848131239414215
episode:  2 training step:  1 loss of agent  3 :  0.3204306662082672
episode:  2 training step:  2 loss of agent  0 :  0.3155874013900757
episode:  2 training step:  2 loss of agent  1 :  0.3816492259502411
episode:  2 training step:  2 loss of agent  2 :  0.5626280307769775
episode:  2 training step:  2 loss of agent  3 :  0.3697192072868347
episode:  2 training step:  3 loss of agent  0 :  0.22730576992034912
episode:  2 training step:  3 loss of agent  1 :  0.4168562889099121
episode:  2 training step:  3 loss of agent  2 :  0.5614711046218872
episode:  2 training step:  3 loss of agent  3 :  0.3331357538700104
episode:  2 training step:  4 loss of agent  0 :  0.2032771110534668
episode:  2 training step:  4 loss of agent  1 :  0.38177260756492615
episode:  2 training step:  4 loss of agent  2 :  0.4877952039241791
episode:  2 training step:  4 loss of agent  3 :  0.2855827510356903
episode:  2 training step:  5 loss of agent  0 :  0.20005840063095093
episode:  2 training step:  5 loss of agent  1 :  0.20128196477890015
episode:  2 training step:  5 loss of agent  2 :  0.41661736369132996
episode:  2 training step:  5 loss of agent  3 :  0.4467061460018158
Evaluation
env seed: 6 evaluation score at the training step:  5 :  {'adversary_0': -66.10922380651378, 'agent_0': 15.33716041548918, 'agent_1': 15.33716041548918, 'agent_2': 15.33716041548918}
episode:  2 training step:  6 loss of agent  0 :  0.17173786461353302
episode:  2 training step:  6 loss of agent  1 :  0.363342821598053
episode:  2 training step:  6 loss of agent  2 :  0.3467996418476105
episode:  2 training step:  6 loss of agent  3 :  0.27200111746788025
episode:  2 training step:  7 loss of agent  0 :  0.22939661145210266
episode:  2 training step:  7 loss of agent  1 :  0.31461796164512634
episode:  2 training step:  7 loss of agent  2 :  0.2713897228240967
episode:  2 training step:  7 loss of agent  3 :  0.2712562680244446
episode:  2 training step:  8 loss of agent  0 :  0.13637663424015045
episode:  2 training step:  8 loss of agent  1 :  0.2374681532382965
episode:  2 training step:  8 loss of agent  2 :  0.4098886251449585
episode:  2 training step:  8 loss of agent  3 :  0.2545572519302368
episode:  2 training step:  9 loss of agent  0 :  0.2203173041343689
episode:  2 training step:  9 loss of agent  1 :  0.4208138883113861
episode:  2 training step:  9 loss of agent  2 :  0.4251352548599243
episode:  2 training step:  9 loss of agent  3 :  0.32345789670944214
episode:  2 training step:  10 loss of agent  0 :  0.2263926863670349
episode:  2 training step:  10 loss of agent  1 :  0.4048405885696411
episode:  2 training step:  10 loss of agent  2 :  0.26110944151878357
episode:  2 training step:  10 loss of agent  3 :  0.2797176241874695
Evaluation
env seed: 6 evaluation score at the training step:  10 :  {'adversary_0': -66.4586569447313, 'agent_0': 15.13414898262116, 'agent_1': 15.13414898262116, 'agent_2': 15.13414898262116}
model saving.................................
episode:  2 training step:  11 loss of agent  0 :  0.19688597321510315
episode:  2 training step:  11 loss of agent  1 :  0.2996554970741272
episode:  2 training step:  11 loss of agent  2 :  0.2804444134235382
episode:  2 training step:  11 loss of agent  3 :  0.3560950756072998
episode:  2 training step:  12 loss of agent  0 :  0.2029482126235962
episode:  2 training step:  12 loss of agent  1 :  0.39429911971092224
episode:  2 training step:  12 loss of agent  2 :  0.4286668598651886
episode:  2 training step:  12 loss of agent  3 :  0.27810773253440857
episode:  2 training step:  13 loss of agent  0 :  0.15761977434158325
episode:  2 training step:  13 loss of agent  1 :  0.24866895377635956
episode:  2 training step:  13 loss of agent  2 :  0.3425367474555969
episode:  2 training step:  13 loss of agent  3 :  0.2522868514060974
episode:  2 training step:  14 loss of agent  0 :  0.13730940222740173
episode:  2 training step:  14 loss of agent  1 :  0.24554960429668427
episode:  2 training step:  14 loss of agent  2 :  0.21980053186416626
episode:  2 training step:  14 loss of agent  3 :  0.24174761772155762
episode:  2 training step:  15 loss of agent  0 :  0.10786949098110199
episode:  2 training step:  15 loss of agent  1 :  0.3324022591114044
episode:  2 training step:  15 loss of agent  2 :  0.2665785253047943
episode:  2 training step:  15 loss of agent  3 :  0.25705456733703613
Evaluation
env seed: 6 evaluation score at the training step:  15 :  {'adversary_0': -66.00659376667807, 'agent_0': 17.8874058926739, 'agent_1': 17.8874058926739, 'agent_2': 17.8874058926739}
episode:  2 training step:  16 loss of agent  0 :  0.14826825261116028
episode:  2 training step:  16 loss of agent  1 :  0.24475446343421936
episode:  2 training step:  16 loss of agent  2 :  0.2814299762248993
episode:  2 training step:  16 loss of agent  3 :  0.23004238307476044
episode:  2 training step:  17 loss of agent  0 :  0.11129529774188995
episode:  2 training step:  17 loss of agent  1 :  0.2279444932937622
episode:  2 training step:  17 loss of agent  2 :  0.1995229870080948
episode:  2 training step:  17 loss of agent  3 :  0.33035537600517273
episode:  2 training step:  18 loss of agent  0 :  0.17684417963027954
episode:  2 training step:  18 loss of agent  1 :  0.3311278223991394
episode:  2 training step:  18 loss of agent  2 :  0.3107489049434662
episode:  2 training step:  18 loss of agent  3 :  0.2766982316970825
episode:  2 training step:  19 loss of agent  0 :  0.06328180432319641
episode:  2 training step:  19 loss of agent  1 :  0.21673882007598877
episode:  2 training step:  19 loss of agent  2 :  0.19926060736179352
episode:  2 training step:  19 loss of agent  3 :  0.20886501669883728
episode:  2 training step:  20 loss of agent  0 :  0.19317512214183807
episode:  2 training step:  20 loss of agent  1 :  0.1722240298986435
episode:  2 training step:  20 loss of agent  2 :  0.3390132784843445
episode:  2 training step:  20 loss of agent  3 :  0.20035018026828766
Evaluation
env seed: 6 evaluation score at the training step:  20 :  {'adversary_0': -66.4586569447313, 'agent_0': 23.60343226010277, 'agent_1': 23.60343226010277, 'agent_2': 23.60343226010277}
model saving.................................
episode:  2 training step:  21 loss of agent  0 :  0.09355172514915466
episode:  2 training step:  21 loss of agent  1 :  0.3677431046962738
episode:  2 training step:  21 loss of agent  2 :  0.26263463497161865
episode:  2 training step:  21 loss of agent  3 :  0.278749942779541
episode 2 terminated at 125
epoch: 2
episode:  2 training step:  22 loss of agent  0 :  0.19557154178619385
episode:  2 training step:  22 loss of agent  1 :  0.23920616507530212
episode:  2 training step:  22 loss of agent  2 :  0.2536633014678955
episode:  2 training step:  22 loss of agent  3 :  0.2871134877204895
episode:  2 training step:  23 loss of agent  0 :  0.1278124749660492
episode:  2 training step:  23 loss of agent  1 :  0.22073592245578766
episode:  2 training step:  23 loss of agent  2 :  0.28720709681510925
episode:  2 training step:  23 loss of agent  3 :  0.17334264516830444
episode:  2 training step:  24 loss of agent  0 :  0.1293378472328186
episode:  2 training step:  24 loss of agent  1 :  0.27920931577682495
episode:  2 training step:  24 loss of agent  2 :  0.2699708342552185
episode:  2 training step:  24 loss of agent  3 :  0.2680778205394745
episode:  2 training step:  25 loss of agent  0 :  0.12261194735765457
episode:  2 training step:  25 loss of agent  1 :  0.18911808729171753
episode:  2 training step:  25 loss of agent  2 :  0.17065498232841492
episode:  2 training step:  25 loss of agent  3 :  0.15786528587341309
Evaluation
env seed: 6 evaluation score at the training step:  25 :  {'adversary_0': -66.05769849994263, 'agent_0': 25.844159090459478, 'agent_1': 25.844159090459478, 'agent_2': 25.844159090459478}
episode:  2 training step:  26 loss of agent  0 :  0.0979297012090683
episode:  2 training step:  26 loss of agent  1 :  0.20079578459262848
episode:  2 training step:  26 loss of agent  2 :  0.31626826524734497
episode:  2 training step:  26 loss of agent  3 :  0.17857162654399872
episode:  2 training step:  27 loss of agent  0 :  0.16818591952323914
episode:  2 training step:  27 loss of agent  1 :  0.20483846962451935
episode:  2 training step:  27 loss of agent  2 :  0.18154898285865784
episode:  2 training step:  27 loss of agent  3 :  0.17326653003692627
episode:  2 training step:  28 loss of agent  0 :  0.11197181046009064
episode:  2 training step:  28 loss of agent  1 :  0.17831258475780487
episode:  2 training step:  28 loss of agent  2 :  0.20783711969852448
episode:  2 training step:  28 loss of agent  3 :  0.19488096237182617
episode:  2 training step:  29 loss of agent  0 :  0.04789140447974205
episode:  2 training step:  29 loss of agent  1 :  0.17952550947666168
episode:  2 training step:  29 loss of agent  2 :  0.20885449647903442
episode:  2 training step:  29 loss of agent  3 :  0.16583962738513947
episode:  2 training step:  30 loss of agent  0 :  0.08875635266304016
episode:  2 training step:  30 loss of agent  1 :  0.11551377922296524
episode:  2 training step:  30 loss of agent  2 :  0.17711693048477173
episode:  2 training step:  30 loss of agent  3 :  0.18330538272857666
Evaluation
env seed: 6 evaluation score at the training step:  30 :  {'adversary_0': -65.93347648973896, 'agent_0': 27.167026923036154, 'agent_1': 27.167026923036154, 'agent_2': 27.167026923036154}
model saving.................................
episode:  2 training step:  31 loss of agent  0 :  0.13446885347366333
episode:  2 training step:  31 loss of agent  1 :  0.15553885698318481
episode:  2 training step:  31 loss of agent  2 :  0.19508537650108337
episode:  2 training step:  31 loss of agent  3 :  0.2768700420856476
episode:  2 training step:  32 loss of agent  0 :  0.09371808916330338
episode:  2 training step:  32 loss of agent  1 :  0.20861145853996277
episode:  2 training step:  32 loss of agent  2 :  0.14998838305473328
episode:  2 training step:  32 loss of agent  3 :  0.17538602650165558
episode:  2 training step:  33 loss of agent  0 :  0.039458297193050385
episode:  2 training step:  33 loss of agent  1 :  0.16787675023078918
episode:  2 training step:  33 loss of agent  2 :  0.2510261833667755
episode:  2 training step:  33 loss of agent  3 :  0.16929645836353302
episode:  2 training step:  34 loss of agent  0 :  0.06977807730436325
episode:  2 training step:  34 loss of agent  1 :  0.21161644160747528
episode:  2 training step:  34 loss of agent  2 :  0.22953537106513977
episode:  2 training step:  34 loss of agent  3 :  0.14938537776470184
episode:  2 training step:  35 loss of agent  0 :  0.0691707506775856
episode:  2 training step:  35 loss of agent  1 :  0.1860503852367401
episode:  2 training step:  35 loss of agent  2 :  0.2212378978729248
episode:  2 training step:  35 loss of agent  3 :  0.23182430863380432
Evaluation
env seed: 6 evaluation score at the training step:  35 :  {'adversary_0': -64.54032969019424, 'agent_0': 26.91248655339333, 'agent_1': 26.91248655339333, 'agent_2': 26.91248655339333}
episode:  2 training step:  36 loss of agent  0 :  0.06368882954120636
episode:  2 training step:  36 loss of agent  1 :  0.17339925467967987
episode:  2 training step:  36 loss of agent  2 :  0.2513010501861572
episode:  2 training step:  36 loss of agent  3 :  0.20588789880275726
episode:  2 training step:  37 loss of agent  0 :  0.07757573574781418
episode:  2 training step:  37 loss of agent  1 :  0.24252840876579285
episode:  2 training step:  37 loss of agent  2 :  0.1675298660993576
episode:  2 training step:  37 loss of agent  3 :  0.2607337236404419
episode:  2 training step:  38 loss of agent  0 :  0.06266303360462189
episode:  2 training step:  38 loss of agent  1 :  0.22126585245132446
episode:  2 training step:  38 loss of agent  2 :  0.1783207505941391
episode:  2 training step:  38 loss of agent  3 :  0.0970970168709755
episode:  2 training step:  39 loss of agent  0 :  0.046913836151361465
episode:  2 training step:  39 loss of agent  1 :  0.1557604968547821
episode:  2 training step:  39 loss of agent  2 :  0.27976328134536743
episode:  2 training step:  39 loss of agent  3 :  0.25702565908432007
episode:  2 training step:  40 loss of agent  0 :  0.10198015719652176
episode:  2 training step:  40 loss of agent  1 :  0.17425502836704254
episode:  2 training step:  40 loss of agent  2 :  0.20733237266540527
episode:  2 training step:  40 loss of agent  3 :  0.18302632868289948
Evaluation
env seed: 6 evaluation score at the training step:  40 :  {'adversary_0': -42.15663872021339, 'agent_0': 6.189766875384546, 'agent_1': 6.189766875384546, 'agent_2': 6.189766875384546}
model saving.................................
episode:  2 training step:  41 loss of agent  0 :  0.05402709171175957
episode:  2 training step:  41 loss of agent  1 :  0.22374412417411804
episode:  2 training step:  41 loss of agent  2 :  0.1877976357936859
episode:  2 training step:  41 loss of agent  3 :  0.12157712876796722
episode:  2 training step:  42 loss of agent  0 :  0.045691683888435364
episode:  2 training step:  42 loss of agent  1 :  0.20074251294136047
episode:  2 training step:  42 loss of agent  2 :  0.15561938285827637
episode:  2 training step:  42 loss of agent  3 :  0.22477945685386658
episode:  2 training step:  43 loss of agent  0 :  0.06842759251594543
episode:  2 training step:  43 loss of agent  1 :  0.25551173090934753
episode:  2 training step:  43 loss of agent  2 :  0.28858819603919983
episode:  2 training step:  43 loss of agent  3 :  0.20186284184455872
episode:  2 training step:  44 loss of agent  0 :  0.04094105586409569
episode:  2 training step:  44 loss of agent  1 :  0.19194288551807404
episode:  2 training step:  44 loss of agent  2 :  0.2216419279575348
episode:  2 training step:  44 loss of agent  3 :  0.1561335325241089
episode:  2 training step:  45 loss of agent  0 :  0.08829391747713089
episode:  2 training step:  45 loss of agent  1 :  0.35927021503448486
episode:  2 training step:  45 loss of agent  2 :  0.1754813939332962
episode:  2 training step:  45 loss of agent  3 :  0.23696069419384003
Evaluation
env seed: 6 evaluation score at the training step:  45 :  {'adversary_0': -42.357211849535844, 'agent_0': 7.30242046325434, 'agent_1': 7.30242046325434, 'agent_2': 7.30242046325434}
episode 2 terminated at 150
episode: 3
epoch: 1
episode:  3 training step:  46 loss of agent  0 :  0.05893274396657944
episode:  3 training step:  46 loss of agent  1 :  0.21781331300735474
episode:  3 training step:  46 loss of agent  2 :  0.19757309556007385
episode:  3 training step:  46 loss of agent  3 :  0.19709280133247375
episode:  3 training step:  47 loss of agent  0 :  0.05565684288740158
episode:  3 training step:  47 loss of agent  1 :  0.2700839936733246
episode:  3 training step:  47 loss of agent  2 :  0.2945067286491394
episode:  3 training step:  47 loss of agent  3 :  0.3141912519931793
episode:  3 training step:  48 loss of agent  0 :  0.05725591257214546
episode:  3 training step:  48 loss of agent  1 :  0.24494105577468872
episode:  3 training step:  48 loss of agent  2 :  0.1325540542602539
episode:  3 training step:  48 loss of agent  3 :  0.24186773598194122
episode:  3 training step:  49 loss of agent  0 :  0.09336484223604202
episode:  3 training step:  49 loss of agent  1 :  0.15105696022510529
episode:  3 training step:  49 loss of agent  2 :  0.3096962869167328
episode:  3 training step:  49 loss of agent  3 :  0.28120505809783936
episode:  3 training step:  50 loss of agent  0 :  0.08318807184696198
episode:  3 training step:  50 loss of agent  1 :  0.2125350385904312
episode:  3 training step:  50 loss of agent  2 :  0.1813853681087494
episode:  3 training step:  50 loss of agent  3 :  0.18516278266906738
Evaluation
env seed: 6 evaluation score at the training step:  50 :  {'adversary_0': -42.5051500257056, 'agent_0': 7.7559008164485475, 'agent_1': 7.7559008164485475, 'agent_2': 7.7559008164485475}
model saving.................................
episode:  3 training step:  51 loss of agent  0 :  0.0762709528207779
episode:  3 training step:  51 loss of agent  1 :  0.25225794315338135
episode:  3 training step:  51 loss of agent  2 :  0.280150443315506
episode:  3 training step:  51 loss of agent  3 :  0.18610645830631256
episode:  3 training step:  52 loss of agent  0 :  0.10371921211481094
episode:  3 training step:  52 loss of agent  1 :  0.2777453064918518
episode:  3 training step:  52 loss of agent  2 :  0.20818248391151428
episode:  3 training step:  52 loss of agent  3 :  0.27374333143234253
episode:  3 training step:  53 loss of agent  0 :  0.04798838496208191
episode:  3 training step:  53 loss of agent  1 :  0.19623473286628723
episode:  3 training step:  53 loss of agent  2 :  0.21297134459018707
episode:  3 training step:  53 loss of agent  3 :  0.225176602602005
episode:  3 training step:  54 loss of agent  0 :  0.08384773135185242
episode:  3 training step:  54 loss of agent  1 :  0.2103351503610611
episode:  3 training step:  54 loss of agent  2 :  0.2097240537405014
episode:  3 training step:  54 loss of agent  3 :  0.17842316627502441
episode:  3 training step:  55 loss of agent  0 :  0.09623807668685913
episode:  3 training step:  55 loss of agent  1 :  0.22803573310375214
episode:  3 training step:  55 loss of agent  2 :  0.18679921329021454
episode:  3 training step:  55 loss of agent  3 :  0.1576157957315445
Evaluation
env seed: 6 evaluation score at the training step:  55 :  {'adversary_0': -41.99376593687586, 'agent_0': 7.043366810765882, 'agent_1': 7.043366810765882, 'agent_2': 7.043366810765882}
episode:  3 training step:  56 loss of agent  0 :  0.09184793382883072
episode:  3 training step:  56 loss of agent  1 :  0.14955683052539825
episode:  3 training step:  56 loss of agent  2 :  0.17036351561546326
episode:  3 training step:  56 loss of agent  3 :  0.13210837543010712
episode:  3 training step:  57 loss of agent  0 :  0.05801458656787872
episode:  3 training step:  57 loss of agent  1 :  0.1915169656276703
episode:  3 training step:  57 loss of agent  2 :  0.192143976688385
episode:  3 training step:  57 loss of agent  3 :  0.22696319222450256
episode:  3 training step:  58 loss of agent  0 :  0.04927322641015053
episode:  3 training step:  58 loss of agent  1 :  0.15160463750362396
episode:  3 training step:  58 loss of agent  2 :  0.15993306040763855
episode:  3 training step:  58 loss of agent  3 :  0.2244918942451477
episode:  3 training step:  59 loss of agent  0 :  0.04964601993560791
episode:  3 training step:  59 loss of agent  1 :  0.340851753950119
episode:  3 training step:  59 loss of agent  2 :  0.2271384447813034
episode:  3 training step:  59 loss of agent  3 :  0.16842682659626007
episode:  3 training step:  60 loss of agent  0 :  0.10508504509925842
episode:  3 training step:  60 loss of agent  1 :  0.23049040138721466
episode:  3 training step:  60 loss of agent  2 :  0.2973135709762573
episode:  3 training step:  60 loss of agent  3 :  0.23813410103321075
Evaluation
env seed: 6 evaluation score at the training step:  60 :  {'adversary_0': -42.76531713049941, 'agent_0': 7.899433918820277, 'agent_1': 7.899433918820277, 'agent_2': 7.899433918820277}
model saving.................................
episode:  3 training step:  61 loss of agent  0 :  0.09839405119419098
episode:  3 training step:  61 loss of agent  1 :  0.32213667035102844
episode:  3 training step:  61 loss of agent  2 :  0.20848390460014343
episode:  3 training step:  61 loss of agent  3 :  0.13580046594142914
episode:  3 training step:  62 loss of agent  0 :  0.05310407280921936
episode:  3 training step:  62 loss of agent  1 :  0.22420285642147064
episode:  3 training step:  62 loss of agent  2 :  0.11750482767820358
episode:  3 training step:  62 loss of agent  3 :  0.15326184034347534
episode:  3 training step:  63 loss of agent  0 :  0.0512106716632843
episode:  3 training step:  63 loss of agent  1 :  0.3582536578178406
episode:  3 training step:  63 loss of agent  2 :  0.15480902791023254
episode:  3 training step:  63 loss of agent  3 :  0.2543184459209442
episode:  3 training step:  64 loss of agent  0 :  0.06930036097764969
episode:  3 training step:  64 loss of agent  1 :  0.3058445155620575
episode:  3 training step:  64 loss of agent  2 :  0.1873439997434616
episode:  3 training step:  64 loss of agent  3 :  0.19371843338012695
episode:  3 training step:  65 loss of agent  0 :  0.06268755346536636
episode:  3 training step:  65 loss of agent  1 :  0.2320806384086609
episode:  3 training step:  65 loss of agent  2 :  0.2218421995639801
episode:  3 training step:  65 loss of agent  3 :  0.16521604359149933
Evaluation
env seed: 6 evaluation score at the training step:  65 :  {'adversary_0': -42.364334462827, 'agent_0': 7.168615538993291, 'agent_1': 7.168615538993291, 'agent_2': 7.168615538993291}
episode:  3 training step:  66 loss of agent  0 :  0.06899282336235046
episode:  3 training step:  66 loss of agent  1 :  0.258862167596817
episode:  3 training step:  66 loss of agent  2 :  0.20839744806289673
episode:  3 training step:  66 loss of agent  3 :  0.14349979162216187
episode:  3 training step:  67 loss of agent  0 :  0.10675569623708725
episode:  3 training step:  67 loss of agent  1 :  0.312566876411438
episode:  3 training step:  67 loss of agent  2 :  0.28637075424194336
episode:  3 training step:  67 loss of agent  3 :  0.17571239173412323
episode:  3 training step:  68 loss of agent  0 :  0.06531043350696564
episode:  3 training step:  68 loss of agent  1 :  0.3268830478191376
episode:  3 training step:  68 loss of agent  2 :  0.23772618174552917
episode:  3 training step:  68 loss of agent  3 :  0.14606116712093353
episode:  3 training step:  69 loss of agent  0 :  0.08211535960435867
episode:  3 training step:  69 loss of agent  1 :  0.2649780809879303
episode:  3 training step:  69 loss of agent  2 :  0.3353594243526459
episode:  3 training step:  69 loss of agent  3 :  0.2027282416820526
episode 3 terminated at 175
epoch: 2
episode:  3 training step:  70 loss of agent  0 :  0.08880696445703506
episode:  3 training step:  70 loss of agent  1 :  0.30959001183509827
episode:  3 training step:  70 loss of agent  2 :  0.30032724142074585
episode:  3 training step:  70 loss of agent  3 :  0.25031018257141113
Evaluation
env seed: 6 evaluation score at the training step:  70 :  {'adversary_0': -41.828608306778065, 'agent_0': 6.349783829099408, 'agent_1': 6.349783829099408, 'agent_2': 6.349783829099408}
model saving.................................
episode:  3 training step:  71 loss of agent  0 :  0.060813263058662415
episode:  3 training step:  71 loss of agent  1 :  0.2881018817424774
episode:  3 training step:  71 loss of agent  2 :  0.22347906231880188
episode:  3 training step:  71 loss of agent  3 :  0.20007610321044922
episode:  3 training step:  72 loss of agent  0 :  0.08491803705692291
episode:  3 training step:  72 loss of agent  1 :  0.29344403743743896
episode:  3 training step:  72 loss of agent  2 :  0.17282918095588684
episode:  3 training step:  72 loss of agent  3 :  0.2642567455768585
episode:  3 training step:  73 loss of agent  0 :  0.06896994262933731
episode:  3 training step:  73 loss of agent  1 :  0.22178243100643158
episode:  3 training step:  73 loss of agent  2 :  0.2693761885166168
episode:  3 training step:  73 loss of agent  3 :  0.23330016434192657
episode:  3 training step:  74 loss of agent  0 :  0.057039231061935425
episode:  3 training step:  74 loss of agent  1 :  0.27231481671333313
episode:  3 training step:  74 loss of agent  2 :  0.17962920665740967
episode:  3 training step:  74 loss of agent  3 :  0.2026892453432083
episode:  3 training step:  75 loss of agent  0 :  0.05470387637615204
episode:  3 training step:  75 loss of agent  1 :  0.20294955372810364
episode:  3 training step:  75 loss of agent  2 :  0.17012058198451996
episode:  3 training step:  75 loss of agent  3 :  0.16490438580513
Evaluation
env seed: 6 evaluation score at the training step:  75 :  {'adversary_0': -40.92317346870727, 'agent_0': 5.253307721463503, 'agent_1': 5.253307721463503, 'agent_2': 5.253307721463503}
episode:  3 training step:  76 loss of agent  0 :  0.08790861070156097
episode:  3 training step:  76 loss of agent  1 :  0.3197851777076721
episode:  3 training step:  76 loss of agent  2 :  0.25228339433670044
episode:  3 training step:  76 loss of agent  3 :  0.2596017122268677
episode:  3 training step:  77 loss of agent  0 :  0.06937147676944733
episode:  3 training step:  77 loss of agent  1 :  0.2921926975250244
episode:  3 training step:  77 loss of agent  2 :  0.26799872517585754
episode:  3 training step:  77 loss of agent  3 :  0.2256060093641281
episode:  3 training step:  78 loss of agent  0 :  0.09754625707864761
episode:  3 training step:  78 loss of agent  1 :  0.3497895300388336
episode:  3 training step:  78 loss of agent  2 :  0.26997968554496765
episode:  3 training step:  78 loss of agent  3 :  0.1856452226638794
episode:  3 training step:  79 loss of agent  0 :  0.08389084786176682
episode:  3 training step:  79 loss of agent  1 :  0.18477164208889008
episode:  3 training step:  79 loss of agent  2 :  0.23779131472110748
episode:  3 training step:  79 loss of agent  3 :  0.21531538665294647
episode:  3 training step:  80 loss of agent  0 :  0.08954764157533646
episode:  3 training step:  80 loss of agent  1 :  0.263752281665802
episode:  3 training step:  80 loss of agent  2 :  0.1969604343175888
episode:  3 training step:  80 loss of agent  3 :  0.2073015719652176
Evaluation
env seed: 6 evaluation score at the training step:  80 :  {'adversary_0': -40.305941986812314, 'agent_0': 5.322847322552977, 'agent_1': 5.322847322552977, 'agent_2': 5.322847322552977}
model saving.................................
episode:  3 training step:  81 loss of agent  0 :  0.09095007926225662
episode:  3 training step:  81 loss of agent  1 :  0.2123105525970459
episode:  3 training step:  81 loss of agent  2 :  0.15222716331481934
episode:  3 training step:  81 loss of agent  3 :  0.18401947617530823
episode:  3 training step:  82 loss of agent  0 :  0.07911069691181183
episode:  3 training step:  82 loss of agent  1 :  0.1577434092760086
episode:  3 training step:  82 loss of agent  2 :  0.21269181370735168
episode:  3 training step:  82 loss of agent  3 :  0.2694565951824188
episode:  3 training step:  83 loss of agent  0 :  0.06282299011945724
episode:  3 training step:  83 loss of agent  1 :  0.28112685680389404
episode:  3 training step:  83 loss of agent  2 :  0.21419522166252136
episode:  3 training step:  83 loss of agent  3 :  0.17116433382034302
episode:  3 training step:  84 loss of agent  0 :  0.07436854392290115
episode:  3 training step:  84 loss of agent  1 :  0.2784777283668518
episode:  3 training step:  84 loss of agent  2 :  0.1712309867143631
episode:  3 training step:  84 loss of agent  3 :  0.23746708035469055
episode:  3 training step:  85 loss of agent  0 :  0.08731533586978912
episode:  3 training step:  85 loss of agent  1 :  0.23496893048286438
episode:  3 training step:  85 loss of agent  2 :  0.25492629408836365
episode:  3 training step:  85 loss of agent  3 :  0.16510146856307983
Evaluation
env seed: 6 evaluation score at the training step:  85 :  {'adversary_0': -39.223941859121744, 'agent_0': 5.204093572664283, 'agent_1': 5.204093572664283, 'agent_2': 5.204093572664283}
episode:  3 training step:  86 loss of agent  0 :  0.0990837812423706
episode:  3 training step:  86 loss of agent  1 :  0.24845106899738312
episode:  3 training step:  86 loss of agent  2 :  0.19112911820411682
episode:  3 training step:  86 loss of agent  3 :  0.2021247148513794
episode:  3 training step:  87 loss of agent  0 :  0.09127560257911682
episode:  3 training step:  87 loss of agent  1 :  0.33607545495033264
episode:  3 training step:  87 loss of agent  2 :  0.2587714195251465
episode:  3 training step:  87 loss of agent  3 :  0.2070440798997879
episode:  3 training step:  88 loss of agent  0 :  0.05710882321000099
episode:  3 training step:  88 loss of agent  1 :  0.2644485831260681
episode:  3 training step:  88 loss of agent  2 :  0.22148555517196655
episode:  3 training step:  88 loss of agent  3 :  0.16037948429584503
episode:  3 training step:  89 loss of agent  0 :  0.0766306072473526
episode:  3 training step:  89 loss of agent  1 :  0.21812601387500763
episode:  3 training step:  89 loss of agent  2 :  0.2457323521375656
episode:  3 training step:  89 loss of agent  3 :  0.2569117546081543
episode:  3 training step:  90 loss of agent  0 :  0.062345027923583984
episode:  3 training step:  90 loss of agent  1 :  0.3146851360797882
episode:  3 training step:  90 loss of agent  2 :  0.1607397198677063
episode:  3 training step:  90 loss of agent  3 :  0.10104061663150787
Evaluation
env seed: 6 evaluation score at the training step:  90 :  {'adversary_0': -36.319793205850715, 'agent_0': 1.7029355479406743, 'agent_1': 1.7029355479406743, 'agent_2': 1.7029355479406743}
model saving.................................
episode:  3 training step:  91 loss of agent  0 :  0.0931820496916771
episode:  3 training step:  91 loss of agent  1 :  0.22096695005893707
episode:  3 training step:  91 loss of agent  2 :  0.23986868560314178
episode:  3 training step:  91 loss of agent  3 :  0.2407059371471405
episode:  3 training step:  92 loss of agent  0 :  0.04431261122226715
episode:  3 training step:  92 loss of agent  1 :  0.18320249021053314
episode:  3 training step:  92 loss of agent  2 :  0.1652628779411316
episode:  3 training step:  92 loss of agent  3 :  0.15485143661499023
episode:  3 training step:  93 loss of agent  0 :  0.1213541030883789
episode:  3 training step:  93 loss of agent  1 :  0.19752255082130432
episode:  3 training step:  93 loss of agent  2 :  0.26346448063850403
episode:  3 training step:  93 loss of agent  3 :  0.14346857368946075
episode 3 terminated at 200
episode: 4
epoch: 1
episode:  4 training step:  94 loss of agent  0 :  0.061516109853982925
episode:  4 training step:  94 loss of agent  1 :  0.22205869853496552
episode:  4 training step:  94 loss of agent  2 :  0.15390005707740784
episode:  4 training step:  94 loss of agent  3 :  0.17176082730293274
episode:  4 training step:  95 loss of agent  0 :  0.11536560952663422
episode:  4 training step:  95 loss of agent  1 :  0.16346129775047302
episode:  4 training step:  95 loss of agent  2 :  0.3902893364429474
episode:  4 training step:  95 loss of agent  3 :  0.18297646939754486
Evaluation
env seed: 6 evaluation score at the training step:  95 :  {'adversary_0': -34.90715160793691, 'agent_0': 0.5734945100884732, 'agent_1': 0.5734945100884732, 'agent_2': 0.5734945100884732}
episode:  4 training step:  96 loss of agent  0 :  0.097601018846035
episode:  4 training step:  96 loss of agent  1 :  0.20630234479904175
episode:  4 training step:  96 loss of agent  2 :  0.19691182672977448
episode:  4 training step:  96 loss of agent  3 :  0.2559705078601837
episode:  4 training step:  97 loss of agent  0 :  0.057463377714157104
episode:  4 training step:  97 loss of agent  1 :  0.14021910727024078
episode:  4 training step:  97 loss of agent  2 :  0.21939730644226074
episode:  4 training step:  97 loss of agent  3 :  0.23327584564685822
episode:  4 training step:  98 loss of agent  0 :  0.045306529849767685
episode:  4 training step:  98 loss of agent  1 :  0.2547708749771118
episode:  4 training step:  98 loss of agent  2 :  0.2413957267999649
episode:  4 training step:  98 loss of agent  3 :  0.23809117078781128
episode:  4 training step:  99 loss of agent  0 :  0.11308593302965164
episode:  4 training step:  99 loss of agent  1 :  0.1869504451751709
episode:  4 training step:  99 loss of agent  2 :  0.17466174066066742
episode:  4 training step:  99 loss of agent  3 :  0.2686529755592346
episode:  4 training step:  100 loss of agent  0 :  0.06210186332464218
episode:  4 training step:  100 loss of agent  1 :  0.15245550870895386
episode:  4 training step:  100 loss of agent  2 :  0.2948540449142456
episode:  4 training step:  100 loss of agent  3 :  0.22497372329235077
Evaluation
env seed: 6 evaluation score at the training step:  100 :  {'adversary_0': -37.633176679566304, 'agent_0': 3.661819775553951, 'agent_1': 3.661819775553951, 'agent_2': 3.661819775553951}
model saving.................................
episode:  4 training step:  101 loss of agent  0 :  0.12240969389677048
episode:  4 training step:  101 loss of agent  1 :  0.21189139783382416
episode:  4 training step:  101 loss of agent  2 :  0.1621716320514679
episode:  4 training step:  101 loss of agent  3 :  0.22617612779140472
episode:  4 training step:  102 loss of agent  0 :  0.11864413321018219
episode:  4 training step:  102 loss of agent  1 :  0.2227756530046463
episode:  4 training step:  102 loss of agent  2 :  0.21431562304496765
episode:  4 training step:  102 loss of agent  3 :  0.20229437947273254
episode:  4 training step:  103 loss of agent  0 :  0.05300837382674217
episode:  4 training step:  103 loss of agent  1 :  0.18893052637577057
episode:  4 training step:  103 loss of agent  2 :  0.11019495874643326
episode:  4 training step:  103 loss of agent  3 :  0.20928004384040833
episode:  4 training step:  104 loss of agent  0 :  0.06154090538620949
episode:  4 training step:  104 loss of agent  1 :  0.15656080842018127
episode:  4 training step:  104 loss of agent  2 :  0.19128721952438354
episode:  4 training step:  104 loss of agent  3 :  0.2810497283935547
episode:  4 training step:  105 loss of agent  0 :  0.1357845664024353
episode:  4 training step:  105 loss of agent  1 :  0.14776486158370972
episode:  4 training step:  105 loss of agent  2 :  0.13132594525814056
episode:  4 training step:  105 loss of agent  3 :  0.17455413937568665
Evaluation
env seed: 6 evaluation score at the training step:  105 :  {'adversary_0': -38.93201378377663, 'agent_0': 3.8609880195056356, 'agent_1': 3.8609880195056356, 'agent_2': 3.8609880195056356}
episode:  4 training step:  106 loss of agent  0 :  0.040303654968738556
episode:  4 training step:  106 loss of agent  1 :  0.19195079803466797
episode:  4 training step:  106 loss of agent  2 :  0.15430527925491333
episode:  4 training step:  106 loss of agent  3 :  0.130801722407341
episode:  4 training step:  107 loss of agent  0 :  0.08028135448694229
episode:  4 training step:  107 loss of agent  1 :  0.2218988537788391
episode:  4 training step:  107 loss of agent  2 :  0.09490199387073517
episode:  4 training step:  107 loss of agent  3 :  0.1706646829843521
episode:  4 training step:  108 loss of agent  0 :  0.09863121807575226
episode:  4 training step:  108 loss of agent  1 :  0.1477835774421692
episode:  4 training step:  108 loss of agent  2 :  0.09390565752983093
episode:  4 training step:  108 loss of agent  3 :  0.21115648746490479
episode:  4 training step:  109 loss of agent  0 :  0.04205060005187988
episode:  4 training step:  109 loss of agent  1 :  0.20072771608829498
episode:  4 training step:  109 loss of agent  2 :  0.24609625339508057
episode:  4 training step:  109 loss of agent  3 :  0.19291828572750092
episode:  4 training step:  110 loss of agent  0 :  0.08952715992927551
episode:  4 training step:  110 loss of agent  1 :  0.20456033945083618
episode:  4 training step:  110 loss of agent  2 :  0.17021393775939941
episode:  4 training step:  110 loss of agent  3 :  0.245687335729599
Evaluation
env seed: 6 evaluation score at the training step:  110 :  {'adversary_0': -39.666491142075074, 'agent_0': 4.290680602146938, 'agent_1': 4.290680602146938, 'agent_2': 4.290680602146938}
model saving.................................
episode:  4 training step:  111 loss of agent  0 :  0.09469897300004959
episode:  4 training step:  111 loss of agent  1 :  0.22087031602859497
episode:  4 training step:  111 loss of agent  2 :  0.15354010462760925
episode:  4 training step:  111 loss of agent  3 :  0.11068405210971832
episode:  4 training step:  112 loss of agent  0 :  0.06691566109657288
episode:  4 training step:  112 loss of agent  1 :  0.14818038046360016
episode:  4 training step:  112 loss of agent  2 :  0.19852271676063538
episode:  4 training step:  112 loss of agent  3 :  0.19415614008903503
episode:  4 training step:  113 loss of agent  0 :  0.06754296272993088
episode:  4 training step:  113 loss of agent  1 :  0.14065200090408325
episode:  4 training step:  113 loss of agent  2 :  0.13907204568386078
episode:  4 training step:  113 loss of agent  3 :  0.20482972264289856
episode:  4 training step:  114 loss of agent  0 :  0.0943240225315094
episode:  4 training step:  114 loss of agent  1 :  0.22534233331680298
episode:  4 training step:  114 loss of agent  2 :  0.1683666706085205
episode:  4 training step:  114 loss of agent  3 :  0.15245437622070312
episode:  4 training step:  115 loss of agent  0 :  0.05460527911782265
episode:  4 training step:  115 loss of agent  1 :  0.16993831098079681
episode:  4 training step:  115 loss of agent  2 :  0.19686411321163177
episode:  4 training step:  115 loss of agent  3 :  0.18483330309391022
Evaluation
env seed: 6 evaluation score at the training step:  115 :  {'adversary_0': -40.28099991542951, 'agent_0': 4.565830754626255, 'agent_1': 4.565830754626255, 'agent_2': 4.565830754626255}
episode:  4 training step:  116 loss of agent  0 :  0.11226587742567062
episode:  4 training step:  116 loss of agent  1 :  0.08630827814340591
episode:  4 training step:  116 loss of agent  2 :  0.17507806420326233
episode:  4 training step:  116 loss of agent  3 :  0.20983532071113586
episode:  4 training step:  117 loss of agent  0 :  0.12159566581249237
episode:  4 training step:  117 loss of agent  1 :  0.14036381244659424
episode:  4 training step:  117 loss of agent  2 :  0.16947361826896667
episode:  4 training step:  117 loss of agent  3 :  0.09085453301668167
episode 4 terminated at 225
epoch: 2
episode:  4 training step:  118 loss of agent  0 :  0.10011813044548035
episode:  4 training step:  118 loss of agent  1 :  0.15469050407409668
episode:  4 training step:  118 loss of agent  2 :  0.1526152342557907
episode:  4 training step:  118 loss of agent  3 :  0.17559222877025604
episode:  4 training step:  119 loss of agent  0 :  0.07431159913539886
episode:  4 training step:  119 loss of agent  1 :  0.11000299453735352
episode:  4 training step:  119 loss of agent  2 :  0.1891157031059265
episode:  4 training step:  119 loss of agent  3 :  0.13909707963466644
episode:  4 training step:  120 loss of agent  0 :  0.06437574326992035
episode:  4 training step:  120 loss of agent  1 :  0.15901991724967957
episode:  4 training step:  120 loss of agent  2 :  0.11036324501037598
episode:  4 training step:  120 loss of agent  3 :  0.22449907660484314
Evaluation
env seed: 6 evaluation score at the training step:  120 :  {'adversary_0': -40.92309058668127, 'agent_0': 6.3417868802283754, 'agent_1': 6.3417868802283754, 'agent_2': 6.3417868802283754}
model saving.................................
episode:  4 training step:  121 loss of agent  0 :  0.06026499718427658
episode:  4 training step:  121 loss of agent  1 :  0.1467682421207428
episode:  4 training step:  121 loss of agent  2 :  0.18248224258422852
episode:  4 training step:  121 loss of agent  3 :  0.19010357558727264
episode:  4 training step:  122 loss of agent  0 :  0.049313709139823914
episode:  4 training step:  122 loss of agent  1 :  0.13540075719356537
episode:  4 training step:  122 loss of agent  2 :  0.10295748710632324
episode:  4 training step:  122 loss of agent  3 :  0.14799708127975464
episode:  4 training step:  123 loss of agent  0 :  0.10270418226718903
episode:  4 training step:  123 loss of agent  1 :  0.16122101247310638
episode:  4 training step:  123 loss of agent  2 :  0.1645027995109558
episode:  4 training step:  123 loss of agent  3 :  0.18046030402183533
episode:  4 training step:  124 loss of agent  0 :  0.044799644500017166
episode:  4 training step:  124 loss of agent  1 :  0.19689761102199554
episode:  4 training step:  124 loss of agent  2 :  0.15426066517829895
episode:  4 training step:  124 loss of agent  3 :  0.1774352788925171
episode:  4 training step:  125 loss of agent  0 :  0.06900841742753983
episode:  4 training step:  125 loss of agent  1 :  0.15551665425300598
episode:  4 training step:  125 loss of agent  2 :  0.10344820469617844
episode:  4 training step:  125 loss of agent  3 :  0.20956169068813324
Evaluation
env seed: 6 evaluation score at the training step:  125 :  {'adversary_0': -47.82422395531308, 'agent_0': 10.506924967318373, 'agent_1': 10.506924967318373, 'agent_2': 10.506924967318373}
episode:  4 training step:  126 loss of agent  0 :  0.10258032381534576
episode:  4 training step:  126 loss of agent  1 :  0.2172176092863083
episode:  4 training step:  126 loss of agent  2 :  0.11663291603326797
episode:  4 training step:  126 loss of agent  3 :  0.171530082821846
episode:  4 training step:  127 loss of agent  0 :  0.09841067343950272
episode:  4 training step:  127 loss of agent  1 :  0.2095814049243927
episode:  4 training step:  127 loss of agent  2 :  0.11245133727788925
episode:  4 training step:  127 loss of agent  3 :  0.14911013841629028
episode:  4 training step:  128 loss of agent  0 :  0.07045716792345047
episode:  4 training step:  128 loss of agent  1 :  0.21457839012145996
episode:  4 training step:  128 loss of agent  2 :  0.1516692340373993
episode:  4 training step:  128 loss of agent  3 :  0.18115384876728058
episode:  4 training step:  129 loss of agent  0 :  0.05069095268845558
episode:  4 training step:  129 loss of agent  1 :  0.1650562882423401
episode:  4 training step:  129 loss of agent  2 :  0.12430053949356079
episode:  4 training step:  129 loss of agent  3 :  0.13762390613555908
episode:  4 training step:  130 loss of agent  0 :  0.06412520259618759
episode:  4 training step:  130 loss of agent  1 :  0.13726197183132172
episode:  4 training step:  130 loss of agent  2 :  0.1150459349155426
episode:  4 training step:  130 loss of agent  3 :  0.14023904502391815
Evaluation
env seed: 6 evaluation score at the training step:  130 :  {'adversary_0': -48.198785284797495, 'agent_0': 10.855585652366589, 'agent_1': 10.855585652366589, 'agent_2': 10.855585652366589}
model saving.................................
episode:  4 training step:  131 loss of agent  0 :  0.07580413669347763
episode:  4 training step:  131 loss of agent  1 :  0.20455336570739746
episode:  4 training step:  131 loss of agent  2 :  0.23304641246795654
episode:  4 training step:  131 loss of agent  3 :  0.21388275921344757
episode:  4 training step:  132 loss of agent  0 :  0.09874667227268219
episode:  4 training step:  132 loss of agent  1 :  0.13472089171409607
episode:  4 training step:  132 loss of agent  2 :  0.16814419627189636
episode:  4 training step:  132 loss of agent  3 :  0.2074788510799408
episode:  4 training step:  133 loss of agent  0 :  0.05255540460348129
episode:  4 training step:  133 loss of agent  1 :  0.1599692404270172
episode:  4 training step:  133 loss of agent  2 :  0.17324575781822205
episode:  4 training step:  133 loss of agent  3 :  0.1518547534942627
episode:  4 training step:  134 loss of agent  0 :  0.05461686849594116
episode:  4 training step:  134 loss of agent  1 :  0.21427534520626068
episode:  4 training step:  134 loss of agent  2 :  0.11434607207775116
episode:  4 training step:  134 loss of agent  3 :  0.23162047564983368
episode:  4 training step:  135 loss of agent  0 :  0.08723714202642441
episode:  4 training step:  135 loss of agent  1 :  0.18163201212882996
episode:  4 training step:  135 loss of agent  2 :  0.12823310494422913
episode:  4 training step:  135 loss of agent  3 :  0.15875452756881714
Evaluation
env seed: 6 evaluation score at the training step:  135 :  {'adversary_0': -59.02612085721605, 'agent_0': 21.66449960992689, 'agent_1': 21.66449960992689, 'agent_2': 21.66449960992689}
episode:  4 training step:  136 loss of agent  0 :  0.04949541389942169
episode:  4 training step:  136 loss of agent  1 :  0.17297644913196564
episode:  4 training step:  136 loss of agent  2 :  0.12393075972795486
episode:  4 training step:  136 loss of agent  3 :  0.14079804718494415
episode:  4 training step:  137 loss of agent  0 :  0.0897892639040947
episode:  4 training step:  137 loss of agent  1 :  0.18235811591148376
episode:  4 training step:  137 loss of agent  2 :  0.13261505961418152
episode:  4 training step:  137 loss of agent  3 :  0.1888994425535202
episode:  4 training step:  138 loss of agent  0 :  0.0822959840297699
episode:  4 training step:  138 loss of agent  1 :  0.09737325459718704
episode:  4 training step:  138 loss of agent  2 :  0.1336279958486557
episode:  4 training step:  138 loss of agent  3 :  0.14235800504684448
episode:  4 training step:  139 loss of agent  0 :  0.05761440470814705
episode:  4 training step:  139 loss of agent  1 :  0.19438625872135162
episode:  4 training step:  139 loss of agent  2 :  0.13837336003780365
episode:  4 training step:  139 loss of agent  3 :  0.15282249450683594
episode:  4 training step:  140 loss of agent  0 :  0.06158166751265526
episode:  4 training step:  140 loss of agent  1 :  0.21346968412399292
episode:  4 training step:  140 loss of agent  2 :  0.17987218499183655
episode:  4 training step:  140 loss of agent  3 :  0.17914173007011414
Evaluation
env seed: 6 evaluation score at the training step:  140 :  {'adversary_0': -58.47479228862179, 'agent_0': 21.916532176164058, 'agent_1': 21.916532176164058, 'agent_2': 21.916532176164058}
model saving.................................
episode:  4 training step:  141 loss of agent  0 :  0.0886293277144432
episode:  4 training step:  141 loss of agent  1 :  0.20520921051502228
episode:  4 training step:  141 loss of agent  2 :  0.13924376666545868
episode:  4 training step:  141 loss of agent  3 :  0.1918235719203949
episode 4 terminated at 250
episode: 5
epoch: 1
episode:  5 training step:  142 loss of agent  0 :  0.11494698375463486
episode:  5 training step:  142 loss of agent  1 :  0.18102967739105225
episode:  5 training step:  142 loss of agent  2 :  0.14857901632785797
episode:  5 training step:  142 loss of agent  3 :  0.27385061979293823
episode:  5 training step:  143 loss of agent  0 :  0.05414487421512604
episode:  5 training step:  143 loss of agent  1 :  0.14237147569656372
episode:  5 training step:  143 loss of agent  2 :  0.19176514446735382
episode:  5 training step:  143 loss of agent  3 :  0.18804220855236053
episode:  5 training step:  144 loss of agent  0 :  0.06482121348381042
episode:  5 training step:  144 loss of agent  1 :  0.16470956802368164
episode:  5 training step:  144 loss of agent  2 :  0.16117854416370392
episode:  5 training step:  144 loss of agent  3 :  0.25574588775634766
episode:  5 training step:  145 loss of agent  0 :  0.07842637598514557
episode:  5 training step:  145 loss of agent  1 :  0.14747124910354614
episode:  5 training step:  145 loss of agent  2 :  0.16122445464134216
episode:  5 training step:  145 loss of agent  3 :  0.2140069305896759
Evaluation
env seed: 6 evaluation score at the training step:  145 :  {'adversary_0': -58.83175797262379, 'agent_0': 22.535955108821884, 'agent_1': 22.535955108821884, 'agent_2': 22.535955108821884}
episode:  5 training step:  146 loss of agent  0 :  0.10182606428861618
episode:  5 training step:  146 loss of agent  1 :  0.19579929113388062
episode:  5 training step:  146 loss of agent  2 :  0.15404507517814636
episode:  5 training step:  146 loss of agent  3 :  0.14807896316051483
episode:  5 training step:  147 loss of agent  0 :  0.04799212887883186
episode:  5 training step:  147 loss of agent  1 :  0.26129043102264404
episode:  5 training step:  147 loss of agent  2 :  0.09516153484582901
episode:  5 training step:  147 loss of agent  3 :  0.1440533548593521
episode:  5 training step:  148 loss of agent  0 :  0.1307556927204132
episode:  5 training step:  148 loss of agent  1 :  0.28666263818740845
episode:  5 training step:  148 loss of agent  2 :  0.20635151863098145
episode:  5 training step:  148 loss of agent  3 :  0.16514062881469727
episode:  5 training step:  149 loss of agent  0 :  0.05889282748103142
episode:  5 training step:  149 loss of agent  1 :  0.20431384444236755
episode:  5 training step:  149 loss of agent  2 :  0.11327315121889114
episode:  5 training step:  149 loss of agent  3 :  0.15548989176750183
episode:  5 training step:  150 loss of agent  0 :  0.061960943043231964
episode:  5 training step:  150 loss of agent  1 :  0.18156138062477112
episode:  5 training step:  150 loss of agent  2 :  0.18742991983890533
episode:  5 training step:  150 loss of agent  3 :  0.12828941643238068
Evaluation
env seed: 6 evaluation score at the training step:  150 :  {'adversary_0': -58.3839337873561, 'agent_0': 22.257465871469055, 'agent_1': 22.257465871469055, 'agent_2': 22.257465871469055}
model saving.................................
episode:  5 training step:  151 loss of agent  0 :  0.03576132655143738
episode:  5 training step:  151 loss of agent  1 :  0.1368408501148224
episode:  5 training step:  151 loss of agent  2 :  0.14795956015586853
episode:  5 training step:  151 loss of agent  3 :  0.2168271243572235
episode:  5 training step:  152 loss of agent  0 :  0.12571105360984802
episode:  5 training step:  152 loss of agent  1 :  0.16160255670547485
episode:  5 training step:  152 loss of agent  2 :  0.08838698267936707
episode:  5 training step:  152 loss of agent  3 :  0.1231594979763031
episode:  5 training step:  153 loss of agent  0 :  0.05112888664007187
episode:  5 training step:  153 loss of agent  1 :  0.12254992872476578
episode:  5 training step:  153 loss of agent  2 :  0.18370047211647034
episode:  5 training step:  153 loss of agent  3 :  0.21004649996757507
episode:  5 training step:  154 loss of agent  0 :  0.06306322664022446
episode:  5 training step:  154 loss of agent  1 :  0.2346852421760559
episode:  5 training step:  154 loss of agent  2 :  0.17050236463546753
episode:  5 training step:  154 loss of agent  3 :  0.13366340100765228
episode:  5 training step:  155 loss of agent  0 :  0.05372493714094162
episode:  5 training step:  155 loss of agent  1 :  0.1467612385749817
episode:  5 training step:  155 loss of agent  2 :  0.17639705538749695
episode:  5 training step:  155 loss of agent  3 :  0.15562736988067627
Evaluation
env seed: 6 evaluation score at the training step:  155 :  {'adversary_0': -58.92257598744203, 'agent_0': 23.23875909176076, 'agent_1': 23.23875909176076, 'agent_2': 23.23875909176076}
episode:  5 training step:  156 loss of agent  0 :  0.08648909628391266
episode:  5 training step:  156 loss of agent  1 :  0.11565771698951721
episode:  5 training step:  156 loss of agent  2 :  0.1568068414926529
episode:  5 training step:  156 loss of agent  3 :  0.18791066110134125
episode:  5 training step:  157 loss of agent  0 :  0.07580797374248505
episode:  5 training step:  157 loss of agent  1 :  0.14331676065921783
episode:  5 training step:  157 loss of agent  2 :  0.14876511693000793
episode:  5 training step:  157 loss of agent  3 :  0.17089322209358215
episode:  5 training step:  158 loss of agent  0 :  0.07395483553409576
episode:  5 training step:  158 loss of agent  1 :  0.12312435358762741
episode:  5 training step:  158 loss of agent  2 :  0.1501971334218979
episode:  5 training step:  158 loss of agent  3 :  0.20733103156089783
episode:  5 training step:  159 loss of agent  0 :  0.09564753621816635
episode:  5 training step:  159 loss of agent  1 :  0.20672507584095
episode:  5 training step:  159 loss of agent  2 :  0.16645292937755585
episode:  5 training step:  159 loss of agent  3 :  0.2659261226654053
episode:  5 training step:  160 loss of agent  0 :  0.07455344498157501
episode:  5 training step:  160 loss of agent  1 :  0.11778553575277328
episode:  5 training step:  160 loss of agent  2 :  0.16726356744766235
episode:  5 training step:  160 loss of agent  3 :  0.14410671591758728
Evaluation
env seed: 6 evaluation score at the training step:  160 :  {'adversary_0': -58.81469717919723, 'agent_0': 23.452053268737714, 'agent_1': 23.452053268737714, 'agent_2': 23.452053268737714}
model saving.................................
episode:  5 training step:  161 loss of agent  0 :  0.04632166028022766
episode:  5 training step:  161 loss of agent  1 :  0.16116341948509216
episode:  5 training step:  161 loss of agent  2 :  0.14730733633041382
episode:  5 training step:  161 loss of agent  3 :  0.1453470140695572
episode:  5 training step:  162 loss of agent  0 :  0.07227206230163574
episode:  5 training step:  162 loss of agent  1 :  0.20062759518623352
episode:  5 training step:  162 loss of agent  2 :  0.12730622291564941
episode:  5 training step:  162 loss of agent  3 :  0.25085997581481934
episode:  5 training step:  163 loss of agent  0 :  0.09575802087783813
episode:  5 training step:  163 loss of agent  1 :  0.15455573797225952
episode:  5 training step:  163 loss of agent  2 :  0.18580013513565063
episode:  5 training step:  163 loss of agent  3 :  0.22293445467948914
episode:  5 training step:  164 loss of agent  0 :  0.07855857908725739
episode:  5 training step:  164 loss of agent  1 :  0.14069455862045288
episode:  5 training step:  164 loss of agent  2 :  0.18855363130569458
episode:  5 training step:  164 loss of agent  3 :  0.18917357921600342
episode:  5 training step:  165 loss of agent  0 :  0.059805937111377716
episode:  5 training step:  165 loss of agent  1 :  0.12373064458370209
episode:  5 training step:  165 loss of agent  2 :  0.16573600471019745
episode:  5 training step:  165 loss of agent  3 :  0.1670592576265335
Evaluation
env seed: 6 evaluation score at the training step:  165 :  {'adversary_0': -58.55514947744324, 'agent_0': 23.415873357704406, 'agent_1': 23.415873357704406, 'agent_2': 23.415873357704406}
episode 5 terminated at 275
epoch: 2
episode:  5 training step:  166 loss of agent  0 :  0.06876463443040848
episode:  5 training step:  166 loss of agent  1 :  0.1698286533355713
episode:  5 training step:  166 loss of agent  2 :  0.19011983275413513
episode:  5 training step:  166 loss of agent  3 :  0.17113959789276123
episode:  5 training step:  167 loss of agent  0 :  0.06752176582813263
episode:  5 training step:  167 loss of agent  1 :  0.13951809704303741
episode:  5 training step:  167 loss of agent  2 :  0.12970902025699615
episode:  5 training step:  167 loss of agent  3 :  0.2408709079027176
episode:  5 training step:  168 loss of agent  0 :  0.10040709376335144
episode:  5 training step:  168 loss of agent  1 :  0.2456294447183609
episode:  5 training step:  168 loss of agent  2 :  0.17033720016479492
episode:  5 training step:  168 loss of agent  3 :  0.19097086787223816
episode:  5 training step:  169 loss of agent  0 :  0.08858442306518555
episode:  5 training step:  169 loss of agent  1 :  0.1447654366493225
episode:  5 training step:  169 loss of agent  2 :  0.15147890150547028
episode:  5 training step:  169 loss of agent  3 :  0.13229919970035553
episode:  5 training step:  170 loss of agent  0 :  0.11489039659500122
episode:  5 training step:  170 loss of agent  1 :  0.19813409447669983
episode:  5 training step:  170 loss of agent  2 :  0.1287713646888733
episode:  5 training step:  170 loss of agent  3 :  0.13957175612449646
Evaluation
env seed: 6 evaluation score at the training step:  170 :  {'adversary_0': -57.23396372711202, 'agent_0': 22.3618552389984, 'agent_1': 22.3618552389984, 'agent_2': 22.3618552389984}
model saving.................................
episode:  5 training step:  171 loss of agent  0 :  0.10411231219768524
episode:  5 training step:  171 loss of agent  1 :  0.20733995735645294
episode:  5 training step:  171 loss of agent  2 :  0.13014864921569824
episode:  5 training step:  171 loss of agent  3 :  0.1797971874475479
episode:  5 training step:  172 loss of agent  0 :  0.07993662357330322
episode:  5 training step:  172 loss of agent  1 :  0.21118316054344177
episode:  5 training step:  172 loss of agent  2 :  0.16065919399261475
episode:  5 training step:  172 loss of agent  3 :  0.1682189404964447
episode:  5 training step:  173 loss of agent  0 :  0.07405467331409454
episode:  5 training step:  173 loss of agent  1 :  0.08782745897769928
episode:  5 training step:  173 loss of agent  2 :  0.1781500279903412
episode:  5 training step:  173 loss of agent  3 :  0.11499565839767456
episode:  5 training step:  174 loss of agent  0 :  0.03953535109758377
episode:  5 training step:  174 loss of agent  1 :  0.21037641167640686
episode:  5 training step:  174 loss of agent  2 :  0.17528092861175537
episode:  5 training step:  174 loss of agent  3 :  0.13251912593841553
episode:  5 training step:  175 loss of agent  0 :  0.06834808737039566
episode:  5 training step:  175 loss of agent  1 :  0.15400223433971405
episode:  5 training step:  175 loss of agent  2 :  0.16542834043502808
episode:  5 training step:  175 loss of agent  3 :  0.24356050789356232
Evaluation
env seed: 6 evaluation score at the training step:  175 :  {'adversary_0': -58.599914363974804, 'agent_0': 23.835773854623028, 'agent_1': 23.835773854623028, 'agent_2': 23.835773854623028}
episode:  5 training step:  176 loss of agent  0 :  0.06642528623342514
episode:  5 training step:  176 loss of agent  1 :  0.14146491885185242
episode:  5 training step:  176 loss of agent  2 :  0.1602785885334015
episode:  5 training step:  176 loss of agent  3 :  0.13528001308441162
episode:  5 training step:  177 loss of agent  0 :  0.05915340036153793
episode:  5 training step:  177 loss of agent  1 :  0.10115163773298264
episode:  5 training step:  177 loss of agent  2 :  0.16742172837257385
episode:  5 training step:  177 loss of agent  3 :  0.06466168165206909
episode:  5 training step:  178 loss of agent  0 :  0.04094166308641434
episode:  5 training step:  178 loss of agent  1 :  0.09496653079986572
episode:  5 training step:  178 loss of agent  2 :  0.10627251863479614
episode:  5 training step:  178 loss of agent  3 :  0.09099376946687698
episode:  5 training step:  179 loss of agent  0 :  0.07940420508384705
episode:  5 training step:  179 loss of agent  1 :  0.2931576073169708
episode:  5 training step:  179 loss of agent  2 :  0.21828031539916992
episode:  5 training step:  179 loss of agent  3 :  0.11692330241203308
episode:  5 training step:  180 loss of agent  0 :  0.04285731911659241
episode:  5 training step:  180 loss of agent  1 :  0.1417456865310669
episode:  5 training step:  180 loss of agent  2 :  0.12223520129919052
episode:  5 training step:  180 loss of agent  3 :  0.18877249956130981
Evaluation
env seed: 6 evaluation score at the training step:  180 :  {'adversary_0': -41.62977610985051, 'agent_0': 7.776136101551596, 'agent_1': 7.776136101551596, 'agent_2': 7.776136101551596}
model saving.................................
episode:  5 training step:  181 loss of agent  0 :  0.10476456582546234
episode:  5 training step:  181 loss of agent  1 :  0.21563729643821716
episode:  5 training step:  181 loss of agent  2 :  0.23403246700763702
episode:  5 training step:  181 loss of agent  3 :  0.15886889398097992
episode:  5 training step:  182 loss of agent  0 :  0.07165338099002838
episode:  5 training step:  182 loss of agent  1 :  0.14506259560585022
episode:  5 training step:  182 loss of agent  2 :  0.1965913474559784
episode:  5 training step:  182 loss of agent  3 :  0.3034854829311371
episode:  5 training step:  183 loss of agent  0 :  0.04792008921504021
episode:  5 training step:  183 loss of agent  1 :  0.1493712216615677
episode:  5 training step:  183 loss of agent  2 :  0.21122518181800842
episode:  5 training step:  183 loss of agent  3 :  0.173355832695961
episode:  5 training step:  184 loss of agent  0 :  0.06730307638645172
episode:  5 training step:  184 loss of agent  1 :  0.17988784611225128
episode:  5 training step:  184 loss of agent  2 :  0.1592227816581726
episode:  5 training step:  184 loss of agent  3 :  0.2622615098953247
episode:  5 training step:  185 loss of agent  0 :  0.07337897270917892
episode:  5 training step:  185 loss of agent  1 :  0.16857151687145233
episode:  5 training step:  185 loss of agent  2 :  0.14997489750385284
episode:  5 training step:  185 loss of agent  3 :  0.14656579494476318
Evaluation
env seed: 6 evaluation score at the training step:  185 :  {'adversary_0': -33.46339860835789, 'agent_0': -3.389082409380239, 'agent_1': -3.389082409380239, 'agent_2': -3.389082409380239}
episode:  5 training step:  186 loss of agent  0 :  0.05577901378273964
episode:  5 training step:  186 loss of agent  1 :  0.2054217904806137
episode:  5 training step:  186 loss of agent  2 :  0.19123201072216034
episode:  5 training step:  186 loss of agent  3 :  0.14887374639511108
episode:  5 training step:  187 loss of agent  0 :  0.057431332767009735
episode:  5 training step:  187 loss of agent  1 :  0.14331333339214325
episode:  5 training step:  187 loss of agent  2 :  0.1779865026473999
episode:  5 training step:  187 loss of agent  3 :  0.09257246553897858
episode:  5 training step:  188 loss of agent  0 :  0.03578950837254524
episode:  5 training step:  188 loss of agent  1 :  0.09314802289009094
episode:  5 training step:  188 loss of agent  2 :  0.11805938929319382
episode:  5 training step:  188 loss of agent  3 :  0.24052280187606812
episode:  5 training step:  189 loss of agent  0 :  0.05656738579273224
episode:  5 training step:  189 loss of agent  1 :  0.22786185145378113
episode:  5 training step:  189 loss of agent  2 :  0.1651347279548645
episode:  5 training step:  189 loss of agent  3 :  0.2155223786830902
episode 5 terminated at 300
episode: 6
epoch: 1
episode:  6 training step:  190 loss of agent  0 :  0.08461910486221313
episode:  6 training step:  190 loss of agent  1 :  0.1734270602464676
episode:  6 training step:  190 loss of agent  2 :  0.20498432219028473
episode:  6 training step:  190 loss of agent  3 :  0.15939070284366608
Evaluation
env seed: 6 evaluation score at the training step:  190 :  {'adversary_0': -27.28630003442052, 'agent_0': -9.789667776192518, 'agent_1': -9.789667776192518, 'agent_2': -9.789667776192518}
model saving.................................
episode:  6 training step:  191 loss of agent  0 :  0.09703056514263153
episode:  6 training step:  191 loss of agent  1 :  0.20710402727127075
episode:  6 training step:  191 loss of agent  2 :  0.22761109471321106
episode:  6 training step:  191 loss of agent  3 :  0.14853604137897491
episode:  6 training step:  192 loss of agent  0 :  0.0706922635436058
episode:  6 training step:  192 loss of agent  1 :  0.18111231923103333
episode:  6 training step:  192 loss of agent  2 :  0.18582001328468323
episode:  6 training step:  192 loss of agent  3 :  0.23494020104408264
episode:  6 training step:  193 loss of agent  0 :  0.04776683449745178
episode:  6 training step:  193 loss of agent  1 :  0.13793785870075226
episode:  6 training step:  193 loss of agent  2 :  0.16833505034446716
episode:  6 training step:  193 loss of agent  3 :  0.1464657336473465
episode:  6 training step:  194 loss of agent  0 :  0.06672961264848709
episode:  6 training step:  194 loss of agent  1 :  0.22706711292266846
episode:  6 training step:  194 loss of agent  2 :  0.14098647236824036
episode:  6 training step:  194 loss of agent  3 :  0.18738269805908203
episode:  6 training step:  195 loss of agent  0 :  0.06350577622652054
episode:  6 training step:  195 loss of agent  1 :  0.09372101724147797
episode:  6 training step:  195 loss of agent  2 :  0.23079337179660797
episode:  6 training step:  195 loss of agent  3 :  0.15929646790027618
Evaluation
env seed: 6 evaluation score at the training step:  195 :  {'adversary_0': -32.98940419405002, 'agent_0': -6.7401157708825465, 'agent_1': -6.7401157708825465, 'agent_2': -6.7401157708825465}
episode:  6 training step:  196 loss of agent  0 :  0.08299455046653748
episode:  6 training step:  196 loss of agent  1 :  0.17464080452919006
episode:  6 training step:  196 loss of agent  2 :  0.13394223153591156
episode:  6 training step:  196 loss of agent  3 :  0.19009491801261902
episode:  6 training step:  197 loss of agent  0 :  0.054807815700769424
episode:  6 training step:  197 loss of agent  1 :  0.31764328479766846
episode:  6 training step:  197 loss of agent  2 :  0.1351984739303589
episode:  6 training step:  197 loss of agent  3 :  0.13588236272335052
episode:  6 training step:  198 loss of agent  0 :  0.0693340003490448
episode:  6 training step:  198 loss of agent  1 :  0.2194996327161789
episode:  6 training step:  198 loss of agent  2 :  0.1933416873216629
episode:  6 training step:  198 loss of agent  3 :  0.1235395297408104
episode:  6 training step:  199 loss of agent  0 :  0.06569638848304749
episode:  6 training step:  199 loss of agent  1 :  0.25712037086486816
episode:  6 training step:  199 loss of agent  2 :  0.1185702532529831
episode:  6 training step:  199 loss of agent  3 :  0.17240720987319946
episode:  6 training step:  200 loss of agent  0 :  0.08199094235897064
episode:  6 training step:  200 loss of agent  1 :  0.17751957476139069
episode:  6 training step:  200 loss of agent  2 :  0.15516909956932068
episode:  6 training step:  200 loss of agent  3 :  0.13176213204860687
Evaluation
env seed: 6 evaluation score at the training step:  200 :  {'adversary_0': -34.80044226501162, 'agent_0': -5.868988081580516, 'agent_1': -5.868988081580516, 'agent_2': -5.868988081580516}
model saving.................................
episode:  6 training step:  201 loss of agent  0 :  0.04958668351173401
episode:  6 training step:  201 loss of agent  1 :  0.1840517669916153
episode:  6 training step:  201 loss of agent  2 :  0.22109177708625793
episode:  6 training step:  201 loss of agent  3 :  0.15691815316677094
episode:  6 training step:  202 loss of agent  0 :  0.07280497252941132
episode:  6 training step:  202 loss of agent  1 :  0.1789470911026001
episode:  6 training step:  202 loss of agent  2 :  0.19921261072158813
episode:  6 training step:  202 loss of agent  3 :  0.24147173762321472
episode:  6 training step:  203 loss of agent  0 :  0.07219931483268738
episode:  6 training step:  203 loss of agent  1 :  0.22606703639030457
episode:  6 training step:  203 loss of agent  2 :  0.13752849400043488
episode:  6 training step:  203 loss of agent  3 :  0.16078703105449677
episode:  6 training step:  204 loss of agent  0 :  0.06192208454012871
episode:  6 training step:  204 loss of agent  1 :  0.28063759207725525
episode:  6 training step:  204 loss of agent  2 :  0.16259562969207764
episode:  6 training step:  204 loss of agent  3 :  0.1801253855228424
episode:  6 training step:  205 loss of agent  0 :  0.06633656471967697
episode:  6 training step:  205 loss of agent  1 :  0.189528688788414
episode:  6 training step:  205 loss of agent  2 :  0.1559547632932663
episode:  6 training step:  205 loss of agent  3 :  0.15598164498806
Evaluation
env seed: 6 evaluation score at the training step:  205 :  {'adversary_0': -37.527591829037874, 'agent_0': -4.494156859258072, 'agent_1': -4.494156859258072, 'agent_2': -4.494156859258072}
episode:  6 training step:  206 loss of agent  0 :  0.06629978865385056
episode:  6 training step:  206 loss of agent  1 :  0.2082158625125885
episode:  6 training step:  206 loss of agent  2 :  0.15354543924331665
episode:  6 training step:  206 loss of agent  3 :  0.1298382580280304
episode:  6 training step:  207 loss of agent  0 :  0.04382932931184769
episode:  6 training step:  207 loss of agent  1 :  0.1190088614821434
episode:  6 training step:  207 loss of agent  2 :  0.2036043107509613
episode:  6 training step:  207 loss of agent  3 :  0.14476148784160614
episode:  6 training step:  208 loss of agent  0 :  0.05763592571020126
episode:  6 training step:  208 loss of agent  1 :  0.13301730155944824
episode:  6 training step:  208 loss of agent  2 :  0.2149881273508072
episode:  6 training step:  208 loss of agent  3 :  0.10629761964082718
episode:  6 training step:  209 loss of agent  0 :  0.0512395016849041
episode:  6 training step:  209 loss of agent  1 :  0.1384030133485794
episode:  6 training step:  209 loss of agent  2 :  0.1930544078350067
episode:  6 training step:  209 loss of agent  3 :  0.18332837522029877
episode:  6 training step:  210 loss of agent  0 :  0.05909552425146103
episode:  6 training step:  210 loss of agent  1 :  0.15922346711158752
episode:  6 training step:  210 loss of agent  2 :  0.20137567818164825
episode:  6 training step:  210 loss of agent  3 :  0.11520208418369293
Evaluation
env seed: 6 evaluation score at the training step:  210 :  {'adversary_0': -39.92829745866253, 'agent_0': -2.395598573683773, 'agent_1': -2.395598573683773, 'agent_2': -2.395598573683773}
model saving.................................
episode:  6 training step:  211 loss of agent  0 :  0.034654855728149414
episode:  6 training step:  211 loss of agent  1 :  0.15882371366024017
episode:  6 training step:  211 loss of agent  2 :  0.16913104057312012
episode:  6 training step:  211 loss of agent  3 :  0.2292821705341339
episode:  6 training step:  212 loss of agent  0 :  0.06450393050909042
episode:  6 training step:  212 loss of agent  1 :  0.18374545872211456
episode:  6 training step:  212 loss of agent  2 :  0.19729559123516083
episode:  6 training step:  212 loss of agent  3 :  0.18698212504386902
episode:  6 training step:  213 loss of agent  0 :  0.06835408508777618
episode:  6 training step:  213 loss of agent  1 :  0.10831318795681
episode:  6 training step:  213 loss of agent  2 :  0.1587989181280136
episode:  6 training step:  213 loss of agent  3 :  0.13785815238952637
episode 6 terminated at 325
epoch: 2
episode:  6 training step:  214 loss of agent  0 :  0.09155307710170746
episode:  6 training step:  214 loss of agent  1 :  0.10655568540096283
episode:  6 training step:  214 loss of agent  2 :  0.14122650027275085
episode:  6 training step:  214 loss of agent  3 :  0.15558379888534546
episode:  6 training step:  215 loss of agent  0 :  0.08108730614185333
episode:  6 training step:  215 loss of agent  1 :  0.16814085841178894
episode:  6 training step:  215 loss of agent  2 :  0.13883160054683685
episode:  6 training step:  215 loss of agent  3 :  0.1192815899848938
Evaluation
env seed: 6 evaluation score at the training step:  215 :  {'adversary_0': -41.13141808797563, 'agent_0': -0.956215719620739, 'agent_1': -0.956215719620739, 'agent_2': -0.956215719620739}
episode:  6 training step:  216 loss of agent  0 :  0.11920537054538727
episode:  6 training step:  216 loss of agent  1 :  0.22652019560337067
episode:  6 training step:  216 loss of agent  2 :  0.20672161877155304
episode:  6 training step:  216 loss of agent  3 :  0.11476843059062958
episode:  6 training step:  217 loss of agent  0 :  0.11881078034639359
episode:  6 training step:  217 loss of agent  1 :  0.2938171625137329
episode:  6 training step:  217 loss of agent  2 :  0.18261432647705078
episode:  6 training step:  217 loss of agent  3 :  0.1773027628660202
episode:  6 training step:  218 loss of agent  0 :  0.09675828367471695
episode:  6 training step:  218 loss of agent  1 :  0.18952050805091858
episode:  6 training step:  218 loss of agent  2 :  0.21531470119953156
episode:  6 training step:  218 loss of agent  3 :  0.12390917539596558
episode:  6 training step:  219 loss of agent  0 :  0.05567310377955437
episode:  6 training step:  219 loss of agent  1 :  0.17494748532772064
episode:  6 training step:  219 loss of agent  2 :  0.22326217591762543
episode:  6 training step:  219 loss of agent  3 :  0.1328275352716446
episode:  6 training step:  220 loss of agent  0 :  0.05983327329158783
episode:  6 training step:  220 loss of agent  1 :  0.16422221064567566
episode:  6 training step:  220 loss of agent  2 :  0.13565276563167572
episode:  6 training step:  220 loss of agent  3 :  0.13420546054840088
Evaluation
env seed: 6 evaluation score at the training step:  220 :  {'adversary_0': -39.223941859121744, 'agent_0': -6.7424756226896205, 'agent_1': -6.7424756226896205, 'agent_2': -6.7424756226896205}
model saving.................................
episode:  6 training step:  221 loss of agent  0 :  0.07488762587308884
episode:  6 training step:  221 loss of agent  1 :  0.16548845171928406
episode:  6 training step:  221 loss of agent  2 :  0.1577116847038269
episode:  6 training step:  221 loss of agent  3 :  0.2176777571439743
episode:  6 training step:  222 loss of agent  0 :  0.07051192224025726
episode:  6 training step:  222 loss of agent  1 :  0.19453394412994385
episode:  6 training step:  222 loss of agent  2 :  0.1707705706357956
episode:  6 training step:  222 loss of agent  3 :  0.0648883655667305
episode:  6 training step:  223 loss of agent  0 :  0.041696466505527496
episode:  6 training step:  223 loss of agent  1 :  0.17998197674751282
episode:  6 training step:  223 loss of agent  2 :  0.21855640411376953
episode:  6 training step:  223 loss of agent  3 :  0.2141733169555664
episode:  6 training step:  224 loss of agent  0 :  0.06428701430559158
episode:  6 training step:  224 loss of agent  1 :  0.10250701010227203
episode:  6 training step:  224 loss of agent  2 :  0.1174955889582634
episode:  6 training step:  224 loss of agent  3 :  0.1747170090675354
episode:  6 training step:  225 loss of agent  0 :  0.078678660094738
episode:  6 training step:  225 loss of agent  1 :  0.1795336753129959
episode:  6 training step:  225 loss of agent  2 :  0.12500721216201782
episode:  6 training step:  225 loss of agent  3 :  0.17811143398284912
Evaluation
env seed: 6 evaluation score at the training step:  225 :  {'adversary_0': -57.012494457695524, 'agent_0': 23.156078269364468, 'agent_1': 23.156078269364468, 'agent_2': 23.156078269364468}
episode:  6 training step:  226 loss of agent  0 :  0.04282422736287117
episode:  6 training step:  226 loss of agent  1 :  0.14109280705451965
episode:  6 training step:  226 loss of agent  2 :  0.11284956336021423
episode:  6 training step:  226 loss of agent  3 :  0.13231204450130463
episode:  6 training step:  227 loss of agent  0 :  0.08380401134490967
episode:  6 training step:  227 loss of agent  1 :  0.15432104468345642
episode:  6 training step:  227 loss of agent  2 :  0.10848072171211243
episode:  6 training step:  227 loss of agent  3 :  0.13985852897167206
episode:  6 training step:  228 loss of agent  0 :  0.05490056425333023
episode:  6 training step:  228 loss of agent  1 :  0.14851133525371552
episode:  6 training step:  228 loss of agent  2 :  0.1506790816783905
episode:  6 training step:  228 loss of agent  3 :  0.18236017227172852
episode:  6 training step:  229 loss of agent  0 :  0.06166286766529083
episode:  6 training step:  229 loss of agent  1 :  0.09166307002305984
episode:  6 training step:  229 loss of agent  2 :  0.2080422192811966
episode:  6 training step:  229 loss of agent  3 :  0.1644924432039261
episode:  6 training step:  230 loss of agent  0 :  0.06411037594079971
episode:  6 training step:  230 loss of agent  1 :  0.17682239413261414
episode:  6 training step:  230 loss of agent  2 :  0.12791922688484192
episode:  6 training step:  230 loss of agent  3 :  0.06906306743621826
Evaluation
env seed: 6 evaluation score at the training step:  230 :  {'adversary_0': -55.35761198617124, 'agent_0': 21.924545190977753, 'agent_1': 21.924545190977753, 'agent_2': 21.924545190977753}
model saving.................................
episode:  6 training step:  231 loss of agent  0 :  0.06197139248251915
episode:  6 training step:  231 loss of agent  1 :  0.13995812833309174
episode:  6 training step:  231 loss of agent  2 :  0.0859847292304039
episode:  6 training step:  231 loss of agent  3 :  0.1586083173751831
episode:  6 training step:  232 loss of agent  0 :  0.07378854602575302
episode:  6 training step:  232 loss of agent  1 :  0.19753344357013702
episode:  6 training step:  232 loss of agent  2 :  0.11207703500986099
episode:  6 training step:  232 loss of agent  3 :  0.21428744494915009
episode:  6 training step:  233 loss of agent  0 :  0.061483606696128845
episode:  6 training step:  233 loss of agent  1 :  0.2184796929359436
episode:  6 training step:  233 loss of agent  2 :  0.2017839252948761
episode:  6 training step:  233 loss of agent  3 :  0.16872437298297882
episode:  6 training step:  234 loss of agent  0 :  0.08224030584096909
episode:  6 training step:  234 loss of agent  1 :  0.2887503504753113
episode:  6 training step:  234 loss of agent  2 :  0.12087750434875488
episode:  6 training step:  234 loss of agent  3 :  0.09253431856632233
episode:  6 training step:  235 loss of agent  0 :  0.05198283493518829
episode:  6 training step:  235 loss of agent  1 :  0.2580849826335907
episode:  6 training step:  235 loss of agent  2 :  0.11819612979888916
episode:  6 training step:  235 loss of agent  3 :  0.17655697464942932
Evaluation
env seed: 6 evaluation score at the training step:  235 :  {'adversary_0': -51.26945662233817, 'agent_0': 17.784737640847958, 'agent_1': 17.784737640847958, 'agent_2': 17.784737640847958}
episode:  6 training step:  236 loss of agent  0 :  0.035847049206495285
episode:  6 training step:  236 loss of agent  1 :  0.11796758323907852
episode:  6 training step:  236 loss of agent  2 :  0.24140521883964539
episode:  6 training step:  236 loss of agent  3 :  0.11609110236167908
episode:  6 training step:  237 loss of agent  0 :  0.09998653829097748
episode:  6 training step:  237 loss of agent  1 :  0.14528819918632507
episode:  6 training step:  237 loss of agent  2 :  0.11254613101482391
episode:  6 training step:  237 loss of agent  3 :  0.17704561352729797
episode 6 terminated at 350
episode: 7
epoch: 1
episode:  7 training step:  238 loss of agent  0 :  0.07801049202680588
episode:  7 training step:  238 loss of agent  1 :  0.1702616959810257
episode:  7 training step:  238 loss of agent  2 :  0.13130106031894684
episode:  7 training step:  238 loss of agent  3 :  0.2018202245235443
episode:  7 training step:  239 loss of agent  0 :  0.055306583642959595
episode:  7 training step:  239 loss of agent  1 :  0.16334635019302368
episode:  7 training step:  239 loss of agent  2 :  0.21074961125850677
episode:  7 training step:  239 loss of agent  3 :  0.13905279338359833
episode:  7 training step:  240 loss of agent  0 :  0.05279984325170517
episode:  7 training step:  240 loss of agent  1 :  0.1474456489086151
episode:  7 training step:  240 loss of agent  2 :  0.16721272468566895
episode:  7 training step:  240 loss of agent  3 :  0.15686951577663422
Evaluation
env seed: 6 evaluation score at the training step:  240 :  {'adversary_0': -50.36171967283421, 'agent_0': 16.61312973878171, 'agent_1': 16.61312973878171, 'agent_2': 16.61312973878171}
model saving.................................
episode:  7 training step:  241 loss of agent  0 :  0.05896788090467453
episode:  7 training step:  241 loss of agent  1 :  0.22490790486335754
episode:  7 training step:  241 loss of agent  2 :  0.20870116353034973
episode:  7 training step:  241 loss of agent  3 :  0.09306881576776505
episode:  7 training step:  242 loss of agent  0 :  0.07441063970327377
episode:  7 training step:  242 loss of agent  1 :  0.2317436784505844
episode:  7 training step:  242 loss of agent  2 :  0.11509329080581665
episode:  7 training step:  242 loss of agent  3 :  0.20566636323928833
episode:  7 training step:  243 loss of agent  0 :  0.10011372715234756
episode:  7 training step:  243 loss of agent  1 :  0.15192322432994843
episode:  7 training step:  243 loss of agent  2 :  0.13075056672096252
episode:  7 training step:  243 loss of agent  3 :  0.09124991297721863
episode:  7 training step:  244 loss of agent  0 :  0.054677724838256836
episode:  7 training step:  244 loss of agent  1 :  0.27951595187187195
episode:  7 training step:  244 loss of agent  2 :  0.13301974534988403
episode:  7 training step:  244 loss of agent  3 :  0.17740121483802795
episode:  7 training step:  245 loss of agent  0 :  0.03983493894338608
episode:  7 training step:  245 loss of agent  1 :  0.20036965608596802
episode:  7 training step:  245 loss of agent  2 :  0.12935039401054382
episode:  7 training step:  245 loss of agent  3 :  0.11715147644281387
Evaluation
env seed: 6 evaluation score at the training step:  245 :  {'adversary_0': -27.602256716445147, 'agent_0': -19.173568443253526, 'agent_1': -19.173568443253526, 'agent_2': -19.173568443253526}
episode:  7 training step:  246 loss of agent  0 :  0.05944248288869858
episode:  7 training step:  246 loss of agent  1 :  0.2611556351184845
episode:  7 training step:  246 loss of agent  2 :  0.24745586514472961
episode:  7 training step:  246 loss of agent  3 :  0.16749566793441772
episode:  7 training step:  247 loss of agent  0 :  0.08588292449712753
episode:  7 training step:  247 loss of agent  1 :  0.17997068166732788
episode:  7 training step:  247 loss of agent  2 :  0.1512761414051056
episode:  7 training step:  247 loss of agent  3 :  0.21296820044517517
episode:  7 training step:  248 loss of agent  0 :  0.07261291891336441
episode:  7 training step:  248 loss of agent  1 :  0.19205743074417114
episode:  7 training step:  248 loss of agent  2 :  0.134491428732872
episode:  7 training step:  248 loss of agent  3 :  0.16876454651355743
episode:  7 training step:  249 loss of agent  0 :  0.04454103857278824
episode:  7 training step:  249 loss of agent  1 :  0.10842141509056091
episode:  7 training step:  249 loss of agent  2 :  0.1036832332611084
episode:  7 training step:  249 loss of agent  3 :  0.23933462798595428
episode:  7 training step:  250 loss of agent  0 :  0.056852806359529495
episode:  7 training step:  250 loss of agent  1 :  0.24040569365024567
episode:  7 training step:  250 loss of agent  2 :  0.19790887832641602
episode:  7 training step:  250 loss of agent  3 :  0.1871730387210846
Evaluation
env seed: 6 evaluation score at the training step:  250 :  {'adversary_0': -29.16587564144303, 'agent_0': -17.352330318462812, 'agent_1': -17.352330318462812, 'agent_2': -17.352330318462812}
model saving.................................
episode:  7 training step:  251 loss of agent  0 :  0.052085377275943756
episode:  7 training step:  251 loss of agent  1 :  0.18934404850006104
episode:  7 training step:  251 loss of agent  2 :  0.11201030015945435
episode:  7 training step:  251 loss of agent  3 :  0.21096324920654297
episode:  7 training step:  252 loss of agent  0 :  0.035895392298698425
episode:  7 training step:  252 loss of agent  1 :  0.19262942671775818
episode:  7 training step:  252 loss of agent  2 :  0.17677147686481476
episode:  7 training step:  252 loss of agent  3 :  0.2288723886013031
episode:  7 training step:  253 loss of agent  0 :  0.04642251133918762
episode:  7 training step:  253 loss of agent  1 :  0.17167189717292786
episode:  7 training step:  253 loss of agent  2 :  0.15425963699817657
episode:  7 training step:  253 loss of agent  3 :  0.15597419440746307
episode:  7 training step:  254 loss of agent  0 :  0.0642770379781723
episode:  7 training step:  254 loss of agent  1 :  0.18649734556674957
episode:  7 training step:  254 loss of agent  2 :  0.23102663457393646
episode:  7 training step:  254 loss of agent  3 :  0.09674399346113205
episode:  7 training step:  255 loss of agent  0 :  0.06133776530623436
episode:  7 training step:  255 loss of agent  1 :  0.19443154335021973
episode:  7 training step:  255 loss of agent  2 :  0.13960054516792297
episode:  7 training step:  255 loss of agent  3 :  0.28505194187164307
Evaluation
env seed: 6 evaluation score at the training step:  255 :  {'adversary_0': -27.42160620757981, 'agent_0': -19.114146857086503, 'agent_1': -19.114146857086503, 'agent_2': -19.114146857086503}
episode:  7 training step:  256 loss of agent  0 :  0.05921488627791405
episode:  7 training step:  256 loss of agent  1 :  0.28253448009490967
episode:  7 training step:  256 loss of agent  2 :  0.1718187928199768
episode:  7 training step:  256 loss of agent  3 :  0.14721304178237915
episode:  7 training step:  257 loss of agent  0 :  0.05414295941591263
episode:  7 training step:  257 loss of agent  1 :  0.21848154067993164
episode:  7 training step:  257 loss of agent  2 :  0.20793622732162476
episode:  7 training step:  257 loss of agent  3 :  0.14491811394691467
episode:  7 training step:  258 loss of agent  0 :  0.07878834754228592
episode:  7 training step:  258 loss of agent  1 :  0.16105115413665771
episode:  7 training step:  258 loss of agent  2 :  0.19879493117332458
episode:  7 training step:  258 loss of agent  3 :  0.12009221315383911
episode:  7 training step:  259 loss of agent  0 :  0.05715790390968323
episode:  7 training step:  259 loss of agent  1 :  0.3083484470844269
episode:  7 training step:  259 loss of agent  2 :  0.1297556310892105
episode:  7 training step:  259 loss of agent  3 :  0.1374897062778473
episode:  7 training step:  260 loss of agent  0 :  0.08231464773416519
episode:  7 training step:  260 loss of agent  1 :  0.3319914638996124
episode:  7 training step:  260 loss of agent  2 :  0.1752084642648697
episode:  7 training step:  260 loss of agent  3 :  0.1361137181520462
Evaluation
env seed: 6 evaluation score at the training step:  260 :  {'adversary_0': -29.41376237014531, 'agent_0': -16.109692608877726, 'agent_1': -16.109692608877726, 'agent_2': -16.109692608877726}
model saving.................................
episode:  7 training step:  261 loss of agent  0 :  0.05681183934211731
episode:  7 training step:  261 loss of agent  1 :  0.10927505046129227
episode:  7 training step:  261 loss of agent  2 :  0.10846380889415741
episode:  7 training step:  261 loss of agent  3 :  0.1560094654560089
episode 7 terminated at 375
epoch: 2
episode:  7 training step:  262 loss of agent  0 :  0.051411692053079605
episode:  7 training step:  262 loss of agent  1 :  0.23191645741462708
episode:  7 training step:  262 loss of agent  2 :  0.11788321286439896
episode:  7 training step:  262 loss of agent  3 :  0.16274350881576538
episode:  7 training step:  263 loss of agent  0 :  0.04099093750119209
episode:  7 training step:  263 loss of agent  1 :  0.20174968242645264
episode:  7 training step:  263 loss of agent  2 :  0.14376910030841827
episode:  7 training step:  263 loss of agent  3 :  0.14895132184028625
episode:  7 training step:  264 loss of agent  0 :  0.04902348294854164
episode:  7 training step:  264 loss of agent  1 :  0.1962938755750656
episode:  7 training step:  264 loss of agent  2 :  0.18904492259025574
episode:  7 training step:  264 loss of agent  3 :  0.13793587684631348
episode:  7 training step:  265 loss of agent  0 :  0.051813773810863495
episode:  7 training step:  265 loss of agent  1 :  0.16603641211986542
episode:  7 training step:  265 loss of agent  2 :  0.16408425569534302
episode:  7 training step:  265 loss of agent  3 :  0.1935870200395584
Evaluation
env seed: 6 evaluation score at the training step:  265 :  {'adversary_0': -32.81056073368539, 'agent_0': -12.34581890399706, 'agent_1': -12.34581890399706, 'agent_2': -12.34581890399706}
episode:  7 training step:  266 loss of agent  0 :  0.07362375408411026
episode:  7 training step:  266 loss of agent  1 :  0.2009260654449463
episode:  7 training step:  266 loss of agent  2 :  0.12447234988212585
episode:  7 training step:  266 loss of agent  3 :  0.13272437453269958
episode:  7 training step:  267 loss of agent  0 :  0.05619046837091446
episode:  7 training step:  267 loss of agent  1 :  0.1912110149860382
episode:  7 training step:  267 loss of agent  2 :  0.10098867118358612
episode:  7 training step:  267 loss of agent  3 :  0.15111547708511353
episode:  7 training step:  268 loss of agent  0 :  0.05729129910469055
episode:  7 training step:  268 loss of agent  1 :  0.15183362364768982
episode:  7 training step:  268 loss of agent  2 :  0.22400133311748505
episode:  7 training step:  268 loss of agent  3 :  0.20910848677158356
episode:  7 training step:  269 loss of agent  0 :  0.04449991509318352
episode:  7 training step:  269 loss of agent  1 :  0.20788373053073883
episode:  7 training step:  269 loss of agent  2 :  0.12703374028205872
episode:  7 training step:  269 loss of agent  3 :  0.11804569512605667
episode:  7 training step:  270 loss of agent  0 :  0.08631093055009842
episode:  7 training step:  270 loss of agent  1 :  0.13638344407081604
episode:  7 training step:  270 loss of agent  2 :  0.17891307175159454
episode:  7 training step:  270 loss of agent  3 :  0.13591931760311127
Evaluation
env seed: 6 evaluation score at the training step:  270 :  {'adversary_0': -33.243589426472795, 'agent_0': -12.51070471587903, 'agent_1': -12.51070471587903, 'agent_2': -12.51070471587903}
model saving.................................
episode:  7 training step:  271 loss of agent  0 :  0.06424137949943542
episode:  7 training step:  271 loss of agent  1 :  0.16949640214443207
episode:  7 training step:  271 loss of agent  2 :  0.10319264978170395
episode:  7 training step:  271 loss of agent  3 :  0.15489505231380463
episode:  7 training step:  272 loss of agent  0 :  0.046083174645900726
episode:  7 training step:  272 loss of agent  1 :  0.19571542739868164
episode:  7 training step:  272 loss of agent  2 :  0.12469478696584702
episode:  7 training step:  272 loss of agent  3 :  0.14986297488212585
episode:  7 training step:  273 loss of agent  0 :  0.06783551722764969
episode:  7 training step:  273 loss of agent  1 :  0.19372490048408508
episode:  7 training step:  273 loss of agent  2 :  0.10263723880052567
episode:  7 training step:  273 loss of agent  3 :  0.10648497939109802
episode:  7 training step:  274 loss of agent  0 :  0.050652291625738144
episode:  7 training step:  274 loss of agent  1 :  0.2354591339826584
episode:  7 training step:  274 loss of agent  2 :  0.15282461047172546
episode:  7 training step:  274 loss of agent  3 :  0.10676415264606476
episode:  7 training step:  275 loss of agent  0 :  0.06028808653354645
episode:  7 training step:  275 loss of agent  1 :  0.22789181768894196
episode:  7 training step:  275 loss of agent  2 :  0.13986168801784515
episode:  7 training step:  275 loss of agent  3 :  0.09821310639381409
Evaluation
env seed: 6 evaluation score at the training step:  275 :  {'adversary_0': -31.518806276308414, 'agent_0': -15.11875416458152, 'agent_1': -15.11875416458152, 'agent_2': -15.11875416458152}
episode:  7 training step:  276 loss of agent  0 :  0.07947876304388046
episode:  7 training step:  276 loss of agent  1 :  0.18294355273246765
episode:  7 training step:  276 loss of agent  2 :  0.17577184736728668
episode:  7 training step:  276 loss of agent  3 :  0.20030604302883148
episode:  7 training step:  277 loss of agent  0 :  0.051481880247592926
episode:  7 training step:  277 loss of agent  1 :  0.28981152176856995
episode:  7 training step:  277 loss of agent  2 :  0.15021973848342896
episode:  7 training step:  277 loss of agent  3 :  0.1753854751586914
episode:  7 training step:  278 loss of agent  0 :  0.07726817578077316
episode:  7 training step:  278 loss of agent  1 :  0.17492006719112396
episode:  7 training step:  278 loss of agent  2 :  0.08046706765890121
episode:  7 training step:  278 loss of agent  3 :  0.11928004771471024
episode:  7 training step:  279 loss of agent  0 :  0.06510883569717407
episode:  7 training step:  279 loss of agent  1 :  0.21968190371990204
episode:  7 training step:  279 loss of agent  2 :  0.21084709465503693
episode:  7 training step:  279 loss of agent  3 :  0.19655446708202362
episode:  7 training step:  280 loss of agent  0 :  0.047594718635082245
episode:  7 training step:  280 loss of agent  1 :  0.19524671137332916
episode:  7 training step:  280 loss of agent  2 :  0.1523294448852539
episode:  7 training step:  280 loss of agent  3 :  0.11357858031988144
Evaluation
env seed: 6 evaluation score at the training step:  280 :  {'adversary_0': -53.56749161976031, 'agent_0': 20.981342816778884, 'agent_1': 20.981342816778884, 'agent_2': 20.981342816778884}
model saving.................................
episode:  7 training step:  281 loss of agent  0 :  0.07207579910755157
episode:  7 training step:  281 loss of agent  1 :  0.13387660682201385
episode:  7 training step:  281 loss of agent  2 :  0.11396720260381699
episode:  7 training step:  281 loss of agent  3 :  0.1554223746061325
episode:  7 training step:  282 loss of agent  0 :  0.045579444617033005
episode:  7 training step:  282 loss of agent  1 :  0.16099393367767334
episode:  7 training step:  282 loss of agent  2 :  0.20050115883350372
episode:  7 training step:  282 loss of agent  3 :  0.13339364528656006
episode:  7 training step:  283 loss of agent  0 :  0.11351648718118668
episode:  7 training step:  283 loss of agent  1 :  0.17668704688549042
episode:  7 training step:  283 loss of agent  2 :  0.15521635115146637
episode:  7 training step:  283 loss of agent  3 :  0.14076998829841614
episode:  7 training step:  284 loss of agent  0 :  0.06622841954231262
episode:  7 training step:  284 loss of agent  1 :  0.3479154706001282
episode:  7 training step:  284 loss of agent  2 :  0.15704545378684998
episode:  7 training step:  284 loss of agent  3 :  0.2391660362482071
episode:  7 training step:  285 loss of agent  0 :  0.08843392878770828
episode:  7 training step:  285 loss of agent  1 :  0.1166255921125412
episode:  7 training step:  285 loss of agent  2 :  0.12293912470340729
episode:  7 training step:  285 loss of agent  3 :  0.15665674209594727
Evaluation
env seed: 6 evaluation score at the training step:  285 :  {'adversary_0': -51.289653997840915, 'agent_0': 16.829069368537795, 'agent_1': 16.829069368537795, 'agent_2': 16.829069368537795}
episode 7 terminated at 400
episode: 8
epoch: 1
episode:  8 training step:  286 loss of agent  0 :  0.052632976323366165
episode:  8 training step:  286 loss of agent  1 :  0.1520141363143921
episode:  8 training step:  286 loss of agent  2 :  0.14222636818885803
episode:  8 training step:  286 loss of agent  3 :  0.119624063372612
episode:  8 training step:  287 loss of agent  0 :  0.11030492186546326
episode:  8 training step:  287 loss of agent  1 :  0.20581474900245667
episode:  8 training step:  287 loss of agent  2 :  0.12321137636899948
episode:  8 training step:  287 loss of agent  3 :  0.1505088359117508
episode:  8 training step:  288 loss of agent  0 :  0.06352344155311584
episode:  8 training step:  288 loss of agent  1 :  0.15249216556549072
episode:  8 training step:  288 loss of agent  2 :  0.18543358147144318
episode:  8 training step:  288 loss of agent  3 :  0.17720523476600647
episode:  8 training step:  289 loss of agent  0 :  0.0651090070605278
episode:  8 training step:  289 loss of agent  1 :  0.27461472153663635
episode:  8 training step:  289 loss of agent  2 :  0.17931842803955078
episode:  8 training step:  289 loss of agent  3 :  0.18772807717323303
episode:  8 training step:  290 loss of agent  0 :  0.06359846889972687
episode:  8 training step:  290 loss of agent  1 :  0.140689417719841
episode:  8 training step:  290 loss of agent  2 :  0.1312231719493866
episode:  8 training step:  290 loss of agent  3 :  0.09772976487874985
Evaluation
env seed: 6 evaluation score at the training step:  290 :  {'adversary_0': -49.13708584964133, 'agent_0': 15.66077077027452, 'agent_1': 15.66077077027452, 'agent_2': 15.66077077027452}
model saving.................................
episode:  8 training step:  291 loss of agent  0 :  0.05569080263376236
episode:  8 training step:  291 loss of agent  1 :  0.3009128272533417
episode:  8 training step:  291 loss of agent  2 :  0.1710158884525299
episode:  8 training step:  291 loss of agent  3 :  0.1280098855495453
episode:  8 training step:  292 loss of agent  0 :  0.07467974722385406
episode:  8 training step:  292 loss of agent  1 :  0.23608505725860596
episode:  8 training step:  292 loss of agent  2 :  0.15644747018814087
episode:  8 training step:  292 loss of agent  3 :  0.11554812639951706
episode:  8 training step:  293 loss of agent  0 :  0.07286234945058823
episode:  8 training step:  293 loss of agent  1 :  0.17448261380195618
episode:  8 training step:  293 loss of agent  2 :  0.20387046039104462
episode:  8 training step:  293 loss of agent  3 :  0.09030429273843765
episode:  8 training step:  294 loss of agent  0 :  0.06139093264937401
episode:  8 training step:  294 loss of agent  1 :  0.24566355347633362
episode:  8 training step:  294 loss of agent  2 :  0.16328240931034088
episode:  8 training step:  294 loss of agent  3 :  0.15584413707256317
episode:  8 training step:  295 loss of agent  0 :  0.04937747120857239
episode:  8 training step:  295 loss of agent  1 :  0.21379071474075317
episode:  8 training step:  295 loss of agent  2 :  0.1349356472492218
episode:  8 training step:  295 loss of agent  3 :  0.1244017481803894
Evaluation
env seed: 6 evaluation score at the training step:  295 :  {'adversary_0': -48.914195973680776, 'agent_0': 16.194291243694714, 'agent_1': 16.194291243694714, 'agent_2': 16.194291243694714}
episode:  8 training step:  296 loss of agent  0 :  0.06051625311374664
episode:  8 training step:  296 loss of agent  1 :  0.10045906156301498
episode:  8 training step:  296 loss of agent  2 :  0.13990475237369537
episode:  8 training step:  296 loss of agent  3 :  0.11271153390407562
episode:  8 training step:  297 loss of agent  0 :  0.1046200543642044
episode:  8 training step:  297 loss of agent  1 :  0.210643470287323
episode:  8 training step:  297 loss of agent  2 :  0.13909626007080078
episode:  8 training step:  297 loss of agent  3 :  0.14069804549217224
episode:  8 training step:  298 loss of agent  0 :  0.06276737153530121
episode:  8 training step:  298 loss of agent  1 :  0.12164205312728882
episode:  8 training step:  298 loss of agent  2 :  0.176717609167099
episode:  8 training step:  298 loss of agent  3 :  0.10239896923303604
episode:  8 training step:  299 loss of agent  0 :  0.08448527753353119
episode:  8 training step:  299 loss of agent  1 :  0.09753518551588058
episode:  8 training step:  299 loss of agent  2 :  0.12462679296731949
episode:  8 training step:  299 loss of agent  3 :  0.15326063334941864
episode:  8 training step:  300 loss of agent  0 :  0.06975916773080826
episode:  8 training step:  300 loss of agent  1 :  0.10894586145877838
episode:  8 training step:  300 loss of agent  2 :  0.12992864847183228
episode:  8 training step:  300 loss of agent  3 :  0.18995584547519684
Evaluation
env seed: 6 evaluation score at the training step:  300 :  {'adversary_0': -24.4373805012413, 'agent_0': -9.226248039391805, 'agent_1': -9.226248039391805, 'agent_2': -9.226248039391805}
model saving.................................
episode:  8 training step:  301 loss of agent  0 :  0.050971418619155884
episode:  8 training step:  301 loss of agent  1 :  0.15610840916633606
episode:  8 training step:  301 loss of agent  2 :  0.1455867886543274
episode:  8 training step:  301 loss of agent  3 :  0.0860188901424408
episode:  8 training step:  302 loss of agent  0 :  0.05041218549013138
episode:  8 training step:  302 loss of agent  1 :  0.21261388063430786
episode:  8 training step:  302 loss of agent  2 :  0.24183346331119537
episode:  8 training step:  302 loss of agent  3 :  0.13792145252227783
episode:  8 training step:  303 loss of agent  0 :  0.05544448271393776
episode:  8 training step:  303 loss of agent  1 :  0.26701584458351135
episode:  8 training step:  303 loss of agent  2 :  0.07639773190021515
episode:  8 training step:  303 loss of agent  3 :  0.17645704746246338
episode:  8 training step:  304 loss of agent  0 :  0.07110486179590225
episode:  8 training step:  304 loss of agent  1 :  0.1672949641942978
episode:  8 training step:  304 loss of agent  2 :  0.1630483716726303
episode:  8 training step:  304 loss of agent  3 :  0.14268378913402557
episode:  8 training step:  305 loss of agent  0 :  0.06285583227872849
episode:  8 training step:  305 loss of agent  1 :  0.17023470997810364
episode:  8 training step:  305 loss of agent  2 :  0.20675179362297058
episode:  8 training step:  305 loss of agent  3 :  0.09022010862827301
Evaluation
env seed: 6 evaluation score at the training step:  305 :  {'adversary_0': -27.169751317098466, 'agent_0': -6.446172308386323, 'agent_1': -6.446172308386323, 'agent_2': -6.446172308386323}
episode:  8 training step:  306 loss of agent  0 :  0.03792427107691765
episode:  8 training step:  306 loss of agent  1 :  0.217962846159935
episode:  8 training step:  306 loss of agent  2 :  0.193389892578125
episode:  8 training step:  306 loss of agent  3 :  0.16054947674274445
episode:  8 training step:  307 loss of agent  0 :  0.07507754862308502
episode:  8 training step:  307 loss of agent  1 :  0.24367037415504456
episode:  8 training step:  307 loss of agent  2 :  0.1730293333530426
episode:  8 training step:  307 loss of agent  3 :  0.1454090029001236
episode:  8 training step:  308 loss of agent  0 :  0.06598050892353058
episode:  8 training step:  308 loss of agent  1 :  0.302889347076416
episode:  8 training step:  308 loss of agent  2 :  0.1393314003944397
episode:  8 training step:  308 loss of agent  3 :  0.17975527048110962
episode:  8 training step:  309 loss of agent  0 :  0.05730874091386795
episode:  8 training step:  309 loss of agent  1 :  0.10640938580036163
episode:  8 training step:  309 loss of agent  2 :  0.13660599291324615
episode:  8 training step:  309 loss of agent  3 :  0.2302168309688568
episode 8 terminated at 425
epoch: 2
episode:  8 training step:  310 loss of agent  0 :  0.07821028679609299
episode:  8 training step:  310 loss of agent  1 :  0.14112171530723572
episode:  8 training step:  310 loss of agent  2 :  0.1318647265434265
episode:  8 training step:  310 loss of agent  3 :  0.12353164702653885
Evaluation
env seed: 6 evaluation score at the training step:  310 :  {'adversary_0': -31.00879307906406, 'agent_0': -2.5936960056401306, 'agent_1': -2.5936960056401306, 'agent_2': -2.5936960056401306}
model saving.................................
episode:  8 training step:  311 loss of agent  0 :  0.048743363469839096
episode:  8 training step:  311 loss of agent  1 :  0.23980212211608887
episode:  8 training step:  311 loss of agent  2 :  0.290053129196167
episode:  8 training step:  311 loss of agent  3 :  0.1434873342514038
episode:  8 training step:  312 loss of agent  0 :  0.04872702434659004
episode:  8 training step:  312 loss of agent  1 :  0.17064644396305084
episode:  8 training step:  312 loss of agent  2 :  0.17263641953468323
episode:  8 training step:  312 loss of agent  3 :  0.09089843928813934
episode:  8 training step:  313 loss of agent  0 :  0.05326327681541443
episode:  8 training step:  313 loss of agent  1 :  0.19851209223270416
episode:  8 training step:  313 loss of agent  2 :  0.1919981986284256
episode:  8 training step:  313 loss of agent  3 :  0.12303829193115234
episode:  8 training step:  314 loss of agent  0 :  0.06103094294667244
episode:  8 training step:  314 loss of agent  1 :  0.1964157670736313
episode:  8 training step:  314 loss of agent  2 :  0.10564570128917694
episode:  8 training step:  314 loss of agent  3 :  0.21899022161960602
episode:  8 training step:  315 loss of agent  0 :  0.06477785855531693
episode:  8 training step:  315 loss of agent  1 :  0.2715398073196411
episode:  8 training step:  315 loss of agent  2 :  0.16041241586208344
episode:  8 training step:  315 loss of agent  3 :  0.08683177828788757
Evaluation
env seed: 6 evaluation score at the training step:  315 :  {'adversary_0': -30.949628631615106, 'agent_0': -2.6514477620928263, 'agent_1': -2.6514477620928263, 'agent_2': -2.6514477620928263}
episode:  8 training step:  316 loss of agent  0 :  0.06142880767583847
episode:  8 training step:  316 loss of agent  1 :  0.23488998413085938
episode:  8 training step:  316 loss of agent  2 :  0.10034813731908798
episode:  8 training step:  316 loss of agent  3 :  0.19284984469413757
episode:  8 training step:  317 loss of agent  0 :  0.045067500323057175
episode:  8 training step:  317 loss of agent  1 :  0.1695864200592041
episode:  8 training step:  317 loss of agent  2 :  0.2007702887058258
episode:  8 training step:  317 loss of agent  3 :  0.1648196130990982
episode:  8 training step:  318 loss of agent  0 :  0.09608931839466095
episode:  8 training step:  318 loss of agent  1 :  0.24934661388397217
episode:  8 training step:  318 loss of agent  2 :  0.18144488334655762
episode:  8 training step:  318 loss of agent  3 :  0.17986537516117096
episode:  8 training step:  319 loss of agent  0 :  0.0632980465888977
episode:  8 training step:  319 loss of agent  1 :  0.14997468888759613
episode:  8 training step:  319 loss of agent  2 :  0.15524396300315857
episode:  8 training step:  319 loss of agent  3 :  0.14078731834888458
episode:  8 training step:  320 loss of agent  0 :  0.0464356392621994
episode:  8 training step:  320 loss of agent  1 :  0.14770713448524475
episode:  8 training step:  320 loss of agent  2 :  0.20191775262355804
episode:  8 training step:  320 loss of agent  3 :  0.1562119722366333
Evaluation
env seed: 6 evaluation score at the training step:  320 :  {'adversary_0': -33.59537829687072, 'agent_0': -16.065576810016697, 'agent_1': -16.065576810016697, 'agent_2': -16.065576810016697}
model saving.................................
episode:  8 training step:  321 loss of agent  0 :  0.054565466940402985
episode:  8 training step:  321 loss of agent  1 :  0.15868568420410156
episode:  8 training step:  321 loss of agent  2 :  0.10814254730939865
episode:  8 training step:  321 loss of agent  3 :  0.16649256646633148
episode:  8 training step:  322 loss of agent  0 :  0.04822193458676338
episode:  8 training step:  322 loss of agent  1 :  0.18374542891979218
episode:  8 training step:  322 loss of agent  2 :  0.17211641371250153
episode:  8 training step:  322 loss of agent  3 :  0.11795906722545624
episode:  8 training step:  323 loss of agent  0 :  0.05222603678703308
episode:  8 training step:  323 loss of agent  1 :  0.23615436255931854
episode:  8 training step:  323 loss of agent  2 :  0.12635980546474457
episode:  8 training step:  323 loss of agent  3 :  0.1727200597524643
episode:  8 training step:  324 loss of agent  0 :  0.06541834771633148
episode:  8 training step:  324 loss of agent  1 :  0.24259087443351746
episode:  8 training step:  324 loss of agent  2 :  0.17764338850975037
episode:  8 training step:  324 loss of agent  3 :  0.12771011888980865
episode:  8 training step:  325 loss of agent  0 :  0.07821571826934814
episode:  8 training step:  325 loss of agent  1 :  0.224310502409935
episode:  8 training step:  325 loss of agent  2 :  0.17506743967533112
episode:  8 training step:  325 loss of agent  3 :  0.1806650012731552
Evaluation
env seed: 6 evaluation score at the training step:  325 :  {'adversary_0': -37.069781718966375, 'agent_0': -14.34480192947091, 'agent_1': -14.34480192947091, 'agent_2': -14.34480192947091}
episode:  8 training step:  326 loss of agent  0 :  0.057109396904706955
episode:  8 training step:  326 loss of agent  1 :  0.18457457423210144
episode:  8 training step:  326 loss of agent  2 :  0.11082247644662857
episode:  8 training step:  326 loss of agent  3 :  0.1438944935798645
episode:  8 training step:  327 loss of agent  0 :  0.05885031074285507
episode:  8 training step:  327 loss of agent  1 :  0.2233656495809555
episode:  8 training step:  327 loss of agent  2 :  0.10881546884775162
episode:  8 training step:  327 loss of agent  3 :  0.1367575079202652
episode:  8 training step:  328 loss of agent  0 :  0.05816865712404251
episode:  8 training step:  328 loss of agent  1 :  0.12596395611763
episode:  8 training step:  328 loss of agent  2 :  0.15408994257450104
episode:  8 training step:  328 loss of agent  3 :  0.12501397728919983
episode:  8 training step:  329 loss of agent  0 :  0.04476545751094818
episode:  8 training step:  329 loss of agent  1 :  0.15835672616958618
episode:  8 training step:  329 loss of agent  2 :  0.08618991822004318
episode:  8 training step:  329 loss of agent  3 :  0.12160637974739075
episode:  8 training step:  330 loss of agent  0 :  0.11252803355455399
episode:  8 training step:  330 loss of agent  1 :  0.20216034352779388
episode:  8 training step:  330 loss of agent  2 :  0.11606759577989578
episode:  8 training step:  330 loss of agent  3 :  0.21664832532405853
Evaluation
env seed: 6 evaluation score at the training step:  330 :  {'adversary_0': -37.97172078571152, 'agent_0': -16.184219553064317, 'agent_1': -16.184219553064317, 'agent_2': -16.184219553064317}
model saving.................................
episode:  8 training step:  331 loss of agent  0 :  0.07846614718437195
episode:  8 training step:  331 loss of agent  1 :  0.11288724094629288
episode:  8 training step:  331 loss of agent  2 :  0.1080847680568695
episode:  8 training step:  331 loss of agent  3 :  0.10197797417640686
episode:  8 training step:  332 loss of agent  0 :  0.05615374445915222
episode:  8 training step:  332 loss of agent  1 :  0.10844634473323822
episode:  8 training step:  332 loss of agent  2 :  0.1474486142396927
episode:  8 training step:  332 loss of agent  3 :  0.18708881735801697
episode:  8 training step:  333 loss of agent  0 :  0.05651731789112091
episode:  8 training step:  333 loss of agent  1 :  0.2654413878917694
episode:  8 training step:  333 loss of agent  2 :  0.14353293180465698
episode:  8 training step:  333 loss of agent  3 :  0.1537775993347168
episode 8 terminated at 450
episode: 9
epoch: 1
episode:  9 training step:  334 loss of agent  0 :  0.046276312321424484
episode:  9 training step:  334 loss of agent  1 :  0.18473748862743378
episode:  9 training step:  334 loss of agent  2 :  0.09760414063930511
episode:  9 training step:  334 loss of agent  3 :  0.15841273963451385
episode:  9 training step:  335 loss of agent  0 :  0.07298348098993301
episode:  9 training step:  335 loss of agent  1 :  0.22366608679294586
episode:  9 training step:  335 loss of agent  2 :  0.06538081914186478
episode:  9 training step:  335 loss of agent  3 :  0.1138162612915039
Evaluation
env seed: 6 evaluation score at the training step:  335 :  {'adversary_0': -34.75679420982492, 'agent_0': -18.54133996623569, 'agent_1': -18.54133996623569, 'agent_2': -18.54133996623569}
episode:  9 training step:  336 loss of agent  0 :  0.038608599454164505
episode:  9 training step:  336 loss of agent  1 :  0.21587726473808289
episode:  9 training step:  336 loss of agent  2 :  0.17481164634227753
episode:  9 training step:  336 loss of agent  3 :  0.060755155980587006
episode:  9 training step:  337 loss of agent  0 :  0.06232811138033867
episode:  9 training step:  337 loss of agent  1 :  0.28366631269454956
episode:  9 training step:  337 loss of agent  2 :  0.20988281071186066
episode:  9 training step:  337 loss of agent  3 :  0.177435964345932
episode:  9 training step:  338 loss of agent  0 :  0.08179481327533722
episode:  9 training step:  338 loss of agent  1 :  0.2316044420003891
episode:  9 training step:  338 loss of agent  2 :  0.13669124245643616
episode:  9 training step:  338 loss of agent  3 :  0.17394299805164337
episode:  9 training step:  339 loss of agent  0 :  0.05077482387423515
episode:  9 training step:  339 loss of agent  1 :  0.14480406045913696
episode:  9 training step:  339 loss of agent  2 :  0.09382259100675583
episode:  9 training step:  339 loss of agent  3 :  0.10627122968435287
episode:  9 training step:  340 loss of agent  0 :  0.06173507869243622
episode:  9 training step:  340 loss of agent  1 :  0.19636909663677216
episode:  9 training step:  340 loss of agent  2 :  0.114451564848423
episode:  9 training step:  340 loss of agent  3 :  0.12496395409107208
Evaluation
env seed: 6 evaluation score at the training step:  340 :  {'adversary_0': -29.449096458751747, 'agent_0': -24.502676095568546, 'agent_1': -24.502676095568546, 'agent_2': -24.502676095568546}
model saving.................................
episode:  9 training step:  341 loss of agent  0 :  0.06655607372522354
episode:  9 training step:  341 loss of agent  1 :  0.1287810504436493
episode:  9 training step:  341 loss of agent  2 :  0.14537368714809418
episode:  9 training step:  341 loss of agent  3 :  0.06944362074136734
episode:  9 training step:  342 loss of agent  0 :  0.06342736631631851
episode:  9 training step:  342 loss of agent  1 :  0.13943475484848022
episode:  9 training step:  342 loss of agent  2 :  0.12549911439418793
episode:  9 training step:  342 loss of agent  3 :  0.17428931593894958
episode:  9 training step:  343 loss of agent  0 :  0.0452348031103611
episode:  9 training step:  343 loss of agent  1 :  0.22535818815231323
episode:  9 training step:  343 loss of agent  2 :  0.1450514942407608
episode:  9 training step:  343 loss of agent  3 :  0.2031528800725937
episode:  9 training step:  344 loss of agent  0 :  0.08756422996520996
episode:  9 training step:  344 loss of agent  1 :  0.16754016280174255
episode:  9 training step:  344 loss of agent  2 :  0.1366647183895111
episode:  9 training step:  344 loss of agent  3 :  0.11312297731637955
episode:  9 training step:  345 loss of agent  0 :  0.08207890391349792
episode:  9 training step:  345 loss of agent  1 :  0.29681599140167236
episode:  9 training step:  345 loss of agent  2 :  0.12208843976259232
episode:  9 training step:  345 loss of agent  3 :  0.09454775601625443
Evaluation
env seed: 6 evaluation score at the training step:  345 :  {'adversary_0': -25.33476554486669, 'agent_0': -25.7028919962974, 'agent_1': -25.7028919962974, 'agent_2': -25.7028919962974}
episode:  9 training step:  346 loss of agent  0 :  0.0786060094833374
episode:  9 training step:  346 loss of agent  1 :  0.17303627729415894
episode:  9 training step:  346 loss of agent  2 :  0.11897498369216919
episode:  9 training step:  346 loss of agent  3 :  0.24031443893909454
episode:  9 training step:  347 loss of agent  0 :  0.0803314596414566
episode:  9 training step:  347 loss of agent  1 :  0.0829220712184906
episode:  9 training step:  347 loss of agent  2 :  0.10713830590248108
episode:  9 training step:  347 loss of agent  3 :  0.13451458513736725
episode:  9 training step:  348 loss of agent  0 :  0.06294717639684677
episode:  9 training step:  348 loss of agent  1 :  0.15778574347496033
episode:  9 training step:  348 loss of agent  2 :  0.07881810516119003
episode:  9 training step:  348 loss of agent  3 :  0.09653107821941376
episode:  9 training step:  349 loss of agent  0 :  0.061381690204143524
episode:  9 training step:  349 loss of agent  1 :  0.15141446888446808
episode:  9 training step:  349 loss of agent  2 :  0.17367011308670044
episode:  9 training step:  349 loss of agent  3 :  0.19388553500175476
episode:  9 training step:  350 loss of agent  0 :  0.08037982136011124
episode:  9 training step:  350 loss of agent  1 :  0.19360710680484772
episode:  9 training step:  350 loss of agent  2 :  0.09395995736122131
episode:  9 training step:  350 loss of agent  3 :  0.15591081976890564
Evaluation
env seed: 6 evaluation score at the training step:  350 :  {'adversary_0': -22.876561588306664, 'agent_0': -10.725927496397537, 'agent_1': -10.725927496397537, 'agent_2': -10.725927496397537}
model saving.................................
episode:  9 training step:  351 loss of agent  0 :  0.06404987722635269
episode:  9 training step:  351 loss of agent  1 :  0.19585514068603516
episode:  9 training step:  351 loss of agent  2 :  0.12326148897409439
episode:  9 training step:  351 loss of agent  3 :  0.1447729766368866
episode:  9 training step:  352 loss of agent  0 :  0.08755850046873093
episode:  9 training step:  352 loss of agent  1 :  0.1498134881258011
episode:  9 training step:  352 loss of agent  2 :  0.11220458149909973
episode:  9 training step:  352 loss of agent  3 :  0.11021606624126434
episode:  9 training step:  353 loss of agent  0 :  0.10042088478803635
episode:  9 training step:  353 loss of agent  1 :  0.23081587255001068
episode:  9 training step:  353 loss of agent  2 :  0.1546538770198822
episode:  9 training step:  353 loss of agent  3 :  0.12125655263662338
episode:  9 training step:  354 loss of agent  0 :  0.052567437291145325
episode:  9 training step:  354 loss of agent  1 :  0.15790215134620667
episode:  9 training step:  354 loss of agent  2 :  0.1501147449016571
episode:  9 training step:  354 loss of agent  3 :  0.08073358237743378
episode:  9 training step:  355 loss of agent  0 :  0.04835183545947075
episode:  9 training step:  355 loss of agent  1 :  0.2569831907749176
episode:  9 training step:  355 loss of agent  2 :  0.12569481134414673
episode:  9 training step:  355 loss of agent  3 :  0.13036635518074036
Evaluation
env seed: 6 evaluation score at the training step:  355 :  {'adversary_0': -23.382044133477933, 'agent_0': -10.296427895020702, 'agent_1': -10.296427895020702, 'agent_2': -10.296427895020702}
episode:  9 training step:  356 loss of agent  0 :  0.027837717905640602
episode:  9 training step:  356 loss of agent  1 :  0.26361459493637085
episode:  9 training step:  356 loss of agent  2 :  0.21925780177116394
episode:  9 training step:  356 loss of agent  3 :  0.15690866112709045
episode:  9 training step:  357 loss of agent  0 :  0.05790431424975395
episode:  9 training step:  357 loss of agent  1 :  0.17751893401145935
episode:  9 training step:  357 loss of agent  2 :  0.17386029660701752
episode:  9 training step:  357 loss of agent  3 :  0.17741341888904572
episode 9 terminated at 475
epoch: 2
episode:  9 training step:  358 loss of agent  0 :  0.07635700702667236
episode:  9 training step:  358 loss of agent  1 :  0.21753305196762085
episode:  9 training step:  358 loss of agent  2 :  0.13475389778614044
episode:  9 training step:  358 loss of agent  3 :  0.10840564966201782
episode:  9 training step:  359 loss of agent  0 :  0.041646454483270645
episode:  9 training step:  359 loss of agent  1 :  0.21952936053276062
episode:  9 training step:  359 loss of agent  2 :  0.1999659240245819
episode:  9 training step:  359 loss of agent  3 :  0.13081105053424835
episode:  9 training step:  360 loss of agent  0 :  0.06629963964223862
episode:  9 training step:  360 loss of agent  1 :  0.2436559796333313
episode:  9 training step:  360 loss of agent  2 :  0.12278477847576141
episode:  9 training step:  360 loss of agent  3 :  0.10668151080608368
Evaluation
env seed: 6 evaluation score at the training step:  360 :  {'adversary_0': -27.2755602620985, 'agent_0': -5.939358974432595, 'agent_1': -5.939358974432595, 'agent_2': -5.939358974432595}
model saving.................................
episode:  9 training step:  361 loss of agent  0 :  0.02757767215371132
episode:  9 training step:  361 loss of agent  1 :  0.15205442905426025
episode:  9 training step:  361 loss of agent  2 :  0.08444234728813171
episode:  9 training step:  361 loss of agent  3 :  0.19376295804977417
episode:  9 training step:  362 loss of agent  0 :  0.041595667600631714
episode:  9 training step:  362 loss of agent  1 :  0.2349122315645218
episode:  9 training step:  362 loss of agent  2 :  0.10785286873579025
episode:  9 training step:  362 loss of agent  3 :  0.16227595508098602
episode:  9 training step:  363 loss of agent  0 :  0.06120835989713669
episode:  9 training step:  363 loss of agent  1 :  0.21860666573047638
episode:  9 training step:  363 loss of agent  2 :  0.09483704715967178
episode:  9 training step:  363 loss of agent  3 :  0.14096298813819885
episode:  9 training step:  364 loss of agent  0 :  0.03876851126551628
episode:  9 training step:  364 loss of agent  1 :  0.28062915802001953
episode:  9 training step:  364 loss of agent  2 :  0.08743835240602493
episode:  9 training step:  364 loss of agent  3 :  0.13516347110271454
episode:  9 training step:  365 loss of agent  0 :  0.06711050122976303
episode:  9 training step:  365 loss of agent  1 :  0.20542378723621368
episode:  9 training step:  365 loss of agent  2 :  0.16534902155399323
episode:  9 training step:  365 loss of agent  3 :  0.11127900332212448
Evaluation
env seed: 6 evaluation score at the training step:  365 :  {'adversary_0': -31.13517671460483, 'agent_0': -2.4542793837917953, 'agent_1': -2.4542793837917953, 'agent_2': -2.4542793837917953}
episode:  9 training step:  366 loss of agent  0 :  0.06838363409042358
episode:  9 training step:  366 loss of agent  1 :  0.21173447370529175
episode:  9 training step:  366 loss of agent  2 :  0.10871561616659164
episode:  9 training step:  366 loss of agent  3 :  0.17645913362503052
episode:  9 training step:  367 loss of agent  0 :  0.05740366876125336
episode:  9 training step:  367 loss of agent  1 :  0.1601693332195282
episode:  9 training step:  367 loss of agent  2 :  0.16076579689979553
episode:  9 training step:  367 loss of agent  3 :  0.11876968294382095
episode:  9 training step:  368 loss of agent  0 :  0.05307333916425705
episode:  9 training step:  368 loss of agent  1 :  0.20989418029785156
episode:  9 training step:  368 loss of agent  2 :  0.12322156131267548
episode:  9 training step:  368 loss of agent  3 :  0.11843112856149673
episode:  9 training step:  369 loss of agent  0 :  0.06367825716733932
episode:  9 training step:  369 loss of agent  1 :  0.18444764614105225
episode:  9 training step:  369 loss of agent  2 :  0.17264136672019958
episode:  9 training step:  369 loss of agent  3 :  0.11100750416517258
episode:  9 training step:  370 loss of agent  0 :  0.04183853417634964
episode:  9 training step:  370 loss of agent  1 :  0.15124215185642242
episode:  9 training step:  370 loss of agent  2 :  0.1021742895245552
episode:  9 training step:  370 loss of agent  3 :  0.11754334717988968
Evaluation
env seed: 6 evaluation score at the training step:  370 :  {'adversary_0': -21.595182596428394, 'agent_0': -12.00730648827583, 'agent_1': -12.00730648827583, 'agent_2': -12.00730648827583}
model saving.................................
episode:  9 training step:  371 loss of agent  0 :  0.05913370102643967
episode:  9 training step:  371 loss of agent  1 :  0.24374240636825562
episode:  9 training step:  371 loss of agent  2 :  0.09987317025661469
episode:  9 training step:  371 loss of agent  3 :  0.11213722825050354
episode:  9 training step:  372 loss of agent  0 :  0.08145498484373093
episode:  9 training step:  372 loss of agent  1 :  0.12682369351387024
episode:  9 training step:  372 loss of agent  2 :  0.10791698098182678
episode:  9 training step:  372 loss of agent  3 :  0.23137199878692627
episode:  9 training step:  373 loss of agent  0 :  0.056546650826931
episode:  9 training step:  373 loss of agent  1 :  0.3412550091743469
episode:  9 training step:  373 loss of agent  2 :  0.15938881039619446
episode:  9 training step:  373 loss of agent  3 :  0.18838560581207275
episode:  9 training step:  374 loss of agent  0 :  0.03502309322357178
episode:  9 training step:  374 loss of agent  1 :  0.16039718687534332
episode:  9 training step:  374 loss of agent  2 :  0.11458273977041245
episode:  9 training step:  374 loss of agent  3 :  0.14633871614933014
episode:  9 training step:  375 loss of agent  0 :  0.06497710198163986
episode:  9 training step:  375 loss of agent  1 :  0.31242308020591736
episode:  9 training step:  375 loss of agent  2 :  0.11760324984788895
episode:  9 training step:  375 loss of agent  3 :  0.16885310411453247
Evaluation
env seed: 6 evaluation score at the training step:  375 :  {'adversary_0': -25.740751993033946, 'agent_0': -7.838478521454529, 'agent_1': -7.838478521454529, 'agent_2': -7.838478521454529}
episode:  9 training step:  376 loss of agent  0 :  0.04519900307059288
episode:  9 training step:  376 loss of agent  1 :  0.18208572268486023
episode:  9 training step:  376 loss of agent  2 :  0.14518330991268158
episode:  9 training step:  376 loss of agent  3 :  0.11555535346269608
episode:  9 training step:  377 loss of agent  0 :  0.06914109736680984
episode:  9 training step:  377 loss of agent  1 :  0.10969530791044235
episode:  9 training step:  377 loss of agent  2 :  0.14318251609802246
episode:  9 training step:  377 loss of agent  3 :  0.23513956367969513
episode:  9 training step:  378 loss of agent  0 :  0.0657770112156868
episode:  9 training step:  378 loss of agent  1 :  0.22142329812049866
episode:  9 training step:  378 loss of agent  2 :  0.19016733765602112
episode:  9 training step:  378 loss of agent  3 :  0.1688651144504547
episode:  9 training step:  379 loss of agent  0 :  0.07669026404619217
episode:  9 training step:  379 loss of agent  1 :  0.13841384649276733
episode:  9 training step:  379 loss of agent  2 :  0.1420307457447052
episode:  9 training step:  379 loss of agent  3 :  0.18097499012947083
episode:  9 training step:  380 loss of agent  0 :  0.022655310109257698
episode:  9 training step:  380 loss of agent  1 :  0.15149807929992676
episode:  9 training step:  380 loss of agent  2 :  0.1408933699131012
episode:  9 training step:  380 loss of agent  3 :  0.08482194691896439
Evaluation
env seed: 6 evaluation score at the training step:  380 :  {'adversary_0': -25.629920687065795, 'agent_0': -7.972568397638471, 'agent_1': -7.972568397638471, 'agent_2': -7.972568397638471}
model saving.................................
episode:  9 training step:  381 loss of agent  0 :  0.055103953927755356
episode:  9 training step:  381 loss of agent  1 :  0.233849436044693
episode:  9 training step:  381 loss of agent  2 :  0.12786680459976196
episode:  9 training step:  381 loss of agent  3 :  0.14018867909908295
episode 9 terminated at 500
episode: 10
epoch: 1
episode:  10 training step:  382 loss of agent  0 :  0.0411364808678627
episode:  10 training step:  382 loss of agent  1 :  0.21554818749427795
episode:  10 training step:  382 loss of agent  2 :  0.17783279716968536
episode:  10 training step:  382 loss of agent  3 :  0.13782203197479248
episode:  10 training step:  383 loss of agent  0 :  0.08438567072153091
episode:  10 training step:  383 loss of agent  1 :  0.17779985070228577
episode:  10 training step:  383 loss of agent  2 :  0.09104836732149124
episode:  10 training step:  383 loss of agent  3 :  0.14634576439857483
episode:  10 training step:  384 loss of agent  0 :  0.067088283598423
episode:  10 training step:  384 loss of agent  1 :  0.18008196353912354
episode:  10 training step:  384 loss of agent  2 :  0.1897822469472885
episode:  10 training step:  384 loss of agent  3 :  0.10166484117507935
episode:  10 training step:  385 loss of agent  0 :  0.11942396312952042
episode:  10 training step:  385 loss of agent  1 :  0.21023505926132202
episode:  10 training step:  385 loss of agent  2 :  0.11123832315206528
episode:  10 training step:  385 loss of agent  3 :  0.1565956473350525
Evaluation
env seed: 6 evaluation score at the training step:  385 :  {'adversary_0': -27.17391023934901, 'agent_0': -6.641502639366934, 'agent_1': -6.641502639366934, 'agent_2': -6.641502639366934}
episode:  10 training step:  386 loss of agent  0 :  0.06041640788316727
episode:  10 training step:  386 loss of agent  1 :  0.1410524696111679
episode:  10 training step:  386 loss of agent  2 :  0.14312013983726501
episode:  10 training step:  386 loss of agent  3 :  0.08996732532978058
episode:  10 training step:  387 loss of agent  0 :  0.05589922517538071
episode:  10 training step:  387 loss of agent  1 :  0.1008296012878418
episode:  10 training step:  387 loss of agent  2 :  0.11862257868051529
episode:  10 training step:  387 loss of agent  3 :  0.14214205741882324
episode:  10 training step:  388 loss of agent  0 :  0.07327139377593994
episode:  10 training step:  388 loss of agent  1 :  0.2703816294670105
episode:  10 training step:  388 loss of agent  2 :  0.19820716977119446
episode:  10 training step:  388 loss of agent  3 :  0.16599556803703308
episode:  10 training step:  389 loss of agent  0 :  0.0853075236082077
episode:  10 training step:  389 loss of agent  1 :  0.15346364676952362
episode:  10 training step:  389 loss of agent  2 :  0.11859946697950363
episode:  10 training step:  389 loss of agent  3 :  0.12314513325691223
episode:  10 training step:  390 loss of agent  0 :  0.04894068092107773
episode:  10 training step:  390 loss of agent  1 :  0.149086594581604
episode:  10 training step:  390 loss of agent  2 :  0.1777319610118866
episode:  10 training step:  390 loss of agent  3 :  0.17132021486759186
Evaluation
env seed: 6 evaluation score at the training step:  390 :  {'adversary_0': -27.20528263010247, 'agent_0': -6.416103231206984, 'agent_1': -6.416103231206984, 'agent_2': -6.416103231206984}
model saving.................................
episode:  10 training step:  391 loss of agent  0 :  0.0763900950551033
episode:  10 training step:  391 loss of agent  1 :  0.1531737744808197
episode:  10 training step:  391 loss of agent  2 :  0.11340554058551788
episode:  10 training step:  391 loss of agent  3 :  0.10003435611724854
episode:  10 training step:  392 loss of agent  0 :  0.04754137620329857
episode:  10 training step:  392 loss of agent  1 :  0.16653458774089813
episode:  10 training step:  392 loss of agent  2 :  0.14224962890148163
episode:  10 training step:  392 loss of agent  3 :  0.07881882786750793
episode:  10 training step:  393 loss of agent  0 :  0.11457023024559021
episode:  10 training step:  393 loss of agent  1 :  0.22355660796165466
episode:  10 training step:  393 loss of agent  2 :  0.17018873989582062
episode:  10 training step:  393 loss of agent  3 :  0.09683896601200104
episode:  10 training step:  394 loss of agent  0 :  0.05941254273056984
episode:  10 training step:  394 loss of agent  1 :  0.1660027801990509
episode:  10 training step:  394 loss of agent  2 :  0.12327712774276733
episode:  10 training step:  394 loss of agent  3 :  0.08620411157608032
episode:  10 training step:  395 loss of agent  0 :  0.1504298448562622
episode:  10 training step:  395 loss of agent  1 :  0.2990272045135498
episode:  10 training step:  395 loss of agent  2 :  0.1614687591791153
episode:  10 training step:  395 loss of agent  3 :  0.14091089367866516
Evaluation
env seed: 6 evaluation score at the training step:  395 :  {'adversary_0': -25.11624411179276, 'agent_0': -8.895544904493672, 'agent_1': -8.895544904493672, 'agent_2': -8.895544904493672}
episode:  10 training step:  396 loss of agent  0 :  0.13746827840805054
episode:  10 training step:  396 loss of agent  1 :  0.1738831251859665
episode:  10 training step:  396 loss of agent  2 :  0.1476752609014511
episode:  10 training step:  396 loss of agent  3 :  0.21431219577789307
episode:  10 training step:  397 loss of agent  0 :  0.11557091027498245
episode:  10 training step:  397 loss of agent  1 :  0.20946671068668365
episode:  10 training step:  397 loss of agent  2 :  0.1350308656692505
episode:  10 training step:  397 loss of agent  3 :  0.15838512778282166
episode:  10 training step:  398 loss of agent  0 :  0.06531652063131332
episode:  10 training step:  398 loss of agent  1 :  0.12288866937160492
episode:  10 training step:  398 loss of agent  2 :  0.12187950313091278
episode:  10 training step:  398 loss of agent  3 :  0.11026102304458618
episode:  10 training step:  399 loss of agent  0 :  0.06758399307727814
episode:  10 training step:  399 loss of agent  1 :  0.2805788815021515
episode:  10 training step:  399 loss of agent  2 :  0.15132662653923035
episode:  10 training step:  399 loss of agent  3 :  0.1251722276210785
episode:  10 training step:  400 loss of agent  0 :  0.05397825688123703
episode:  10 training step:  400 loss of agent  1 :  0.19570329785346985
episode:  10 training step:  400 loss of agent  2 :  0.13757549226284027
episode:  10 training step:  400 loss of agent  3 :  0.10057681798934937
Evaluation
env seed: 6 evaluation score at the training step:  400 :  {'adversary_0': -44.037323800645815, 'agent_0': 10.434834715941594, 'agent_1': 10.434834715941594, 'agent_2': 10.434834715941594}
model saving.................................
episode:  10 training step:  401 loss of agent  0 :  0.042208701372146606
episode:  10 training step:  401 loss of agent  1 :  0.18137536942958832
episode:  10 training step:  401 loss of agent  2 :  0.14625748991966248
episode:  10 training step:  401 loss of agent  3 :  0.12859272956848145
episode:  10 training step:  402 loss of agent  0 :  0.0698542520403862
episode:  10 training step:  402 loss of agent  1 :  0.21528756618499756
episode:  10 training step:  402 loss of agent  2 :  0.15814894437789917
episode:  10 training step:  402 loss of agent  3 :  0.1449221819639206
episode:  10 training step:  403 loss of agent  0 :  0.06809405982494354
episode:  10 training step:  403 loss of agent  1 :  0.15556101500988007
episode:  10 training step:  403 loss of agent  2 :  0.10939353704452515
episode:  10 training step:  403 loss of agent  3 :  0.10281845927238464
episode:  10 training step:  404 loss of agent  0 :  0.05004534870386124
episode:  10 training step:  404 loss of agent  1 :  0.20381252467632294
episode:  10 training step:  404 loss of agent  2 :  0.12219016999006271
episode:  10 training step:  404 loss of agent  3 :  0.1487986147403717
episode:  10 training step:  405 loss of agent  0 :  0.054089389741420746
episode:  10 training step:  405 loss of agent  1 :  0.14924517273902893
episode:  10 training step:  405 loss of agent  2 :  0.11702816188335419
episode:  10 training step:  405 loss of agent  3 :  0.18749381601810455
Evaluation
env seed: 6 evaluation score at the training step:  405 :  {'adversary_0': -53.25466067488526, 'agent_0': 19.47834499108405, 'agent_1': 19.47834499108405, 'agent_2': 19.47834499108405}
episode 10 terminated at 525
epoch: 2
episode:  10 training step:  406 loss of agent  0 :  0.08989758044481277
episode:  10 training step:  406 loss of agent  1 :  0.14574694633483887
episode:  10 training step:  406 loss of agent  2 :  0.09309253841638565
episode:  10 training step:  406 loss of agent  3 :  0.18452878296375275
episode:  10 training step:  407 loss of agent  0 :  0.06829246878623962
episode:  10 training step:  407 loss of agent  1 :  0.2924121618270874
episode:  10 training step:  407 loss of agent  2 :  0.13638032972812653
episode:  10 training step:  407 loss of agent  3 :  0.15373672544956207
episode:  10 training step:  408 loss of agent  0 :  0.09199385344982147
episode:  10 training step:  408 loss of agent  1 :  0.20607562363147736
episode:  10 training step:  408 loss of agent  2 :  0.10020392388105392
episode:  10 training step:  408 loss of agent  3 :  0.09818603843450546
episode:  10 training step:  409 loss of agent  0 :  0.04167966544628143
episode:  10 training step:  409 loss of agent  1 :  0.16081294417381287
episode:  10 training step:  409 loss of agent  2 :  0.14786845445632935
episode:  10 training step:  409 loss of agent  3 :  0.1191508024930954
episode:  10 training step:  410 loss of agent  0 :  0.03201207146048546
episode:  10 training step:  410 loss of agent  1 :  0.1545599400997162
episode:  10 training step:  410 loss of agent  2 :  0.17581388354301453
episode:  10 training step:  410 loss of agent  3 :  0.1192232295870781
Evaluation
env seed: 6 evaluation score at the training step:  410 :  {'adversary_0': -47.76221666056811, 'agent_0': 14.159727575863872, 'agent_1': 14.159727575863872, 'agent_2': 14.159727575863872}
model saving.................................
episode:  10 training step:  411 loss of agent  0 :  0.0743449330329895
episode:  10 training step:  411 loss of agent  1 :  0.1791059374809265
episode:  10 training step:  411 loss of agent  2 :  0.13007155060768127
episode:  10 training step:  411 loss of agent  3 :  0.13594719767570496
episode:  10 training step:  412 loss of agent  0 :  0.06669746339321136
episode:  10 training step:  412 loss of agent  1 :  0.21629220247268677
episode:  10 training step:  412 loss of agent  2 :  0.1687731146812439
episode:  10 training step:  412 loss of agent  3 :  0.1361105591058731
episode:  10 training step:  413 loss of agent  0 :  0.05231728404760361
episode:  10 training step:  413 loss of agent  1 :  0.17888513207435608
episode:  10 training step:  413 loss of agent  2 :  0.1468738317489624
episode:  10 training step:  413 loss of agent  3 :  0.1382327377796173
episode:  10 training step:  414 loss of agent  0 :  0.07823292911052704
episode:  10 training step:  414 loss of agent  1 :  0.12970124185085297
episode:  10 training step:  414 loss of agent  2 :  0.11978980898857117
episode:  10 training step:  414 loss of agent  3 :  0.13201335072517395
episode:  10 training step:  415 loss of agent  0 :  0.05174921080470085
episode:  10 training step:  415 loss of agent  1 :  0.1816648244857788
episode:  10 training step:  415 loss of agent  2 :  0.1310301572084427
episode:  10 training step:  415 loss of agent  3 :  0.13782808184623718
Evaluation
env seed: 6 evaluation score at the training step:  415 :  {'adversary_0': -27.836970477519497, 'agent_0': -5.900176967275555, 'agent_1': -5.900176967275555, 'agent_2': -5.900176967275555}
episode:  10 training step:  416 loss of agent  0 :  0.0751468613743782
episode:  10 training step:  416 loss of agent  1 :  0.2135116159915924
episode:  10 training step:  416 loss of agent  2 :  0.14503107964992523
episode:  10 training step:  416 loss of agent  3 :  0.08509962260723114
episode:  10 training step:  417 loss of agent  0 :  0.042686402797698975
episode:  10 training step:  417 loss of agent  1 :  0.1666332483291626
episode:  10 training step:  417 loss of agent  2 :  0.10066357254981995
episode:  10 training step:  417 loss of agent  3 :  0.15673765540122986
episode:  10 training step:  418 loss of agent  0 :  0.0584573820233345
episode:  10 training step:  418 loss of agent  1 :  0.14790400862693787
episode:  10 training step:  418 loss of agent  2 :  0.21038976311683655
episode:  10 training step:  418 loss of agent  3 :  0.18987871706485748
episode:  10 training step:  419 loss of agent  0 :  0.05614248663187027
episode:  10 training step:  419 loss of agent  1 :  0.10657816380262375
episode:  10 training step:  419 loss of agent  2 :  0.21152743697166443
episode:  10 training step:  419 loss of agent  3 :  0.1306937038898468
episode:  10 training step:  420 loss of agent  0 :  0.07927028089761734
episode:  10 training step:  420 loss of agent  1 :  0.2797268033027649
episode:  10 training step:  420 loss of agent  2 :  0.19894622266292572
episode:  10 training step:  420 loss of agent  3 :  0.14118139445781708
Evaluation
env seed: 6 evaluation score at the training step:  420 :  {'adversary_0': -35.46761420206865, 'agent_0': 1.8978712690295274, 'agent_1': 1.8978712690295274, 'agent_2': 1.8978712690295274}
model saving.................................
episode:  10 training step:  421 loss of agent  0 :  0.061756521463394165
episode:  10 training step:  421 loss of agent  1 :  0.33662110567092896
episode:  10 training step:  421 loss of agent  2 :  0.16582880914211273
episode:  10 training step:  421 loss of agent  3 :  0.13529415428638458
episode:  10 training step:  422 loss of agent  0 :  0.03577325493097305
episode:  10 training step:  422 loss of agent  1 :  0.30478644371032715
episode:  10 training step:  422 loss of agent  2 :  0.10198670625686646
episode:  10 training step:  422 loss of agent  3 :  0.13190579414367676
episode:  10 training step:  423 loss of agent  0 :  0.08347601443529129
episode:  10 training step:  423 loss of agent  1 :  0.1910519301891327
episode:  10 training step:  423 loss of agent  2 :  0.15619143843650818
episode:  10 training step:  423 loss of agent  3 :  0.1918932944536209
episode:  10 training step:  424 loss of agent  0 :  0.13211064040660858
episode:  10 training step:  424 loss of agent  1 :  0.24508413672447205
episode:  10 training step:  424 loss of agent  2 :  0.09325606375932693
episode:  10 training step:  424 loss of agent  3 :  0.11798440665006638
episode:  10 training step:  425 loss of agent  0 :  0.06109977141022682
episode:  10 training step:  425 loss of agent  1 :  0.1533033400774002
episode:  10 training step:  425 loss of agent  2 :  0.18273065984249115
episode:  10 training step:  425 loss of agent  3 :  0.0802166536450386
Evaluation
env seed: 6 evaluation score at the training step:  425 :  {'adversary_0': -35.21474339271668, 'agent_0': 1.4913604771479148, 'agent_1': 1.4913604771479148, 'agent_2': 1.4913604771479148}
episode:  10 training step:  426 loss of agent  0 :  0.06228581443428993
episode:  10 training step:  426 loss of agent  1 :  0.15887731313705444
episode:  10 training step:  426 loss of agent  2 :  0.082583487033844
episode:  10 training step:  426 loss of agent  3 :  0.08868103474378586
episode:  10 training step:  427 loss of agent  0 :  0.06922624260187149
episode:  10 training step:  427 loss of agent  1 :  0.16941756010055542
episode:  10 training step:  427 loss of agent  2 :  0.15216754376888275
episode:  10 training step:  427 loss of agent  3 :  0.11747689545154572
episode:  10 training step:  428 loss of agent  0 :  0.08035670220851898
episode:  10 training step:  428 loss of agent  1 :  0.13241085410118103
episode:  10 training step:  428 loss of agent  2 :  0.09453197568655014
episode:  10 training step:  428 loss of agent  3 :  0.10290142893791199
episode:  10 training step:  429 loss of agent  0 :  0.07342296093702316
episode:  10 training step:  429 loss of agent  1 :  0.2504409849643707
episode:  10 training step:  429 loss of agent  2 :  0.1363399624824524
episode:  10 training step:  429 loss of agent  3 :  0.1582266390323639
episode 10 terminated at 550
episode: 11
epoch: 1
episode:  11 training step:  430 loss of agent  0 :  0.07150766253471375
episode:  11 training step:  430 loss of agent  1 :  0.22591489553451538
episode:  11 training step:  430 loss of agent  2 :  0.15185841917991638
episode:  11 training step:  430 loss of agent  3 :  0.09626477211713791
Evaluation
env seed: 6 evaluation score at the training step:  430 :  {'adversary_0': -25.96579722521319, 'agent_0': -7.63669185949108, 'agent_1': -7.63669185949108, 'agent_2': -7.63669185949108}
model saving.................................
episode:  11 training step:  431 loss of agent  0 :  0.111180879175663
episode:  11 training step:  431 loss of agent  1 :  0.17124436795711517
episode:  11 training step:  431 loss of agent  2 :  0.12561418116092682
episode:  11 training step:  431 loss of agent  3 :  0.2022663801908493
episode:  11 training step:  432 loss of agent  0 :  0.0563337542116642
episode:  11 training step:  432 loss of agent  1 :  0.11478263139724731
episode:  11 training step:  432 loss of agent  2 :  0.16624754667282104
episode:  11 training step:  432 loss of agent  3 :  0.16774868965148926
episode:  11 training step:  433 loss of agent  0 :  0.04441400244832039
episode:  11 training step:  433 loss of agent  1 :  0.1410801261663437
episode:  11 training step:  433 loss of agent  2 :  0.14219240844249725
episode:  11 training step:  433 loss of agent  3 :  0.12343516200780869
episode:  11 training step:  434 loss of agent  0 :  0.07020505517721176
episode:  11 training step:  434 loss of agent  1 :  0.19235101342201233
episode:  11 training step:  434 loss of agent  2 :  0.11304882913827896
episode:  11 training step:  434 loss of agent  3 :  0.09847486764192581
episode:  11 training step:  435 loss of agent  0 :  0.08631497621536255
episode:  11 training step:  435 loss of agent  1 :  0.2534560561180115
episode:  11 training step:  435 loss of agent  2 :  0.1971898078918457
episode:  11 training step:  435 loss of agent  3 :  0.20874880254268646
Evaluation
env seed: 6 evaluation score at the training step:  435 :  {'adversary_0': -36.15335056114789, 'agent_0': 2.5951484885811253, 'agent_1': 2.5951484885811253, 'agent_2': 2.5951484885811253}
episode:  11 training step:  436 loss of agent  0 :  0.07814651727676392
episode:  11 training step:  436 loss of agent  1 :  0.27562856674194336
episode:  11 training step:  436 loss of agent  2 :  0.1600429266691208
episode:  11 training step:  436 loss of agent  3 :  0.1942368447780609
episode:  11 training step:  437 loss of agent  0 :  0.09113109111785889
episode:  11 training step:  437 loss of agent  1 :  0.1289723515510559
episode:  11 training step:  437 loss of agent  2 :  0.2115757167339325
episode:  11 training step:  437 loss of agent  3 :  0.11426132917404175
episode:  11 training step:  438 loss of agent  0 :  0.049954090267419815
episode:  11 training step:  438 loss of agent  1 :  0.20005299150943756
episode:  11 training step:  438 loss of agent  2 :  0.13438093662261963
episode:  11 training step:  438 loss of agent  3 :  0.1418181210756302
episode:  11 training step:  439 loss of agent  0 :  0.05952548235654831
episode:  11 training step:  439 loss of agent  1 :  0.2258864939212799
episode:  11 training step:  439 loss of agent  2 :  0.15129026770591736
episode:  11 training step:  439 loss of agent  3 :  0.09694688767194748
episode:  11 training step:  440 loss of agent  0 :  0.06521059572696686
episode:  11 training step:  440 loss of agent  1 :  0.18283213675022125
episode:  11 training step:  440 loss of agent  2 :  0.13707900047302246
episode:  11 training step:  440 loss of agent  3 :  0.10332980006933212
Evaluation
env seed: 6 evaluation score at the training step:  440 :  {'adversary_0': -40.8326698190244, 'agent_0': 7.237267497469513, 'agent_1': 7.237267497469513, 'agent_2': 7.237267497469513}
model saving.................................
episode:  11 training step:  441 loss of agent  0 :  0.050653330981731415
episode:  11 training step:  441 loss of agent  1 :  0.21238863468170166
episode:  11 training step:  441 loss of agent  2 :  0.11552349478006363
episode:  11 training step:  441 loss of agent  3 :  0.09932870417833328
episode:  11 training step:  442 loss of agent  0 :  0.06119261309504509
episode:  11 training step:  442 loss of agent  1 :  0.10175158828496933
episode:  11 training step:  442 loss of agent  2 :  0.1541319638490677
episode:  11 training step:  442 loss of agent  3 :  0.19408808648586273
episode:  11 training step:  443 loss of agent  0 :  0.08691440522670746
episode:  11 training step:  443 loss of agent  1 :  0.18600916862487793
episode:  11 training step:  443 loss of agent  2 :  0.14916390180587769
episode:  11 training step:  443 loss of agent  3 :  0.09167298674583435
episode:  11 training step:  444 loss of agent  0 :  0.05507562682032585
episode:  11 training step:  444 loss of agent  1 :  0.28367358446121216
episode:  11 training step:  444 loss of agent  2 :  0.159041166305542
episode:  11 training step:  444 loss of agent  3 :  0.17046517133712769
episode:  11 training step:  445 loss of agent  0 :  0.06936158239841461
episode:  11 training step:  445 loss of agent  1 :  0.18685422837734222
episode:  11 training step:  445 loss of agent  2 :  0.15009477734565735
episode:  11 training step:  445 loss of agent  3 :  0.19066932797431946
Evaluation
env seed: 6 evaluation score at the training step:  445 :  {'adversary_0': -39.53619531253826, 'agent_0': 5.737431062524836, 'agent_1': 5.737431062524836, 'agent_2': 5.737431062524836}
episode:  11 training step:  446 loss of agent  0 :  0.04482778161764145
episode:  11 training step:  446 loss of agent  1 :  0.1620008796453476
episode:  11 training step:  446 loss of agent  2 :  0.1271553933620453
episode:  11 training step:  446 loss of agent  3 :  0.13472411036491394
episode:  11 training step:  447 loss of agent  0 :  0.04853510484099388
episode:  11 training step:  447 loss of agent  1 :  0.2102912962436676
episode:  11 training step:  447 loss of agent  2 :  0.20474626123905182
episode:  11 training step:  447 loss of agent  3 :  0.151442289352417
episode:  11 training step:  448 loss of agent  0 :  0.05028782784938812
episode:  11 training step:  448 loss of agent  1 :  0.21292105317115784
episode:  11 training step:  448 loss of agent  2 :  0.15016132593154907
episode:  11 training step:  448 loss of agent  3 :  0.1539422869682312
episode:  11 training step:  449 loss of agent  0 :  0.0534018836915493
episode:  11 training step:  449 loss of agent  1 :  0.28633278608322144
episode:  11 training step:  449 loss of agent  2 :  0.09861773252487183
episode:  11 training step:  449 loss of agent  3 :  0.16093391180038452
episode:  11 training step:  450 loss of agent  0 :  0.04415353760123253
episode:  11 training step:  450 loss of agent  1 :  0.20987127721309662
episode:  11 training step:  450 loss of agent  2 :  0.10543981939554214
episode:  11 training step:  450 loss of agent  3 :  0.16965845227241516
Evaluation
env seed: 6 evaluation score at the training step:  450 :  {'adversary_0': -39.209794654864005, 'agent_0': 5.790777105775767, 'agent_1': 5.790777105775767, 'agent_2': 5.790777105775767}
model saving.................................
episode:  11 training step:  451 loss of agent  0 :  0.05170215293765068
episode:  11 training step:  451 loss of agent  1 :  0.24547038972377777
episode:  11 training step:  451 loss of agent  2 :  0.13247375190258026
episode:  11 training step:  451 loss of agent  3 :  0.15374906361103058
episode:  11 training step:  452 loss of agent  0 :  0.08225614577531815
episode:  11 training step:  452 loss of agent  1 :  0.34891214966773987
episode:  11 training step:  452 loss of agent  2 :  0.16222485899925232
episode:  11 training step:  452 loss of agent  3 :  0.16126637160778046
episode:  11 training step:  453 loss of agent  0 :  0.06169432774186134
episode:  11 training step:  453 loss of agent  1 :  0.1742752194404602
episode:  11 training step:  453 loss of agent  2 :  0.189995676279068
episode:  11 training step:  453 loss of agent  3 :  0.15229107439517975
episode 11 terminated at 575
epoch: 2
episode:  11 training step:  454 loss of agent  0 :  0.04779044911265373
episode:  11 training step:  454 loss of agent  1 :  0.14178986847400665
episode:  11 training step:  454 loss of agent  2 :  0.15611490607261658
episode:  11 training step:  454 loss of agent  3 :  0.13413849472999573
episode:  11 training step:  455 loss of agent  0 :  0.07916989922523499
episode:  11 training step:  455 loss of agent  1 :  0.2018231898546219
episode:  11 training step:  455 loss of agent  2 :  0.06791739910840988
episode:  11 training step:  455 loss of agent  3 :  0.13614222407341003
Evaluation
env seed: 6 evaluation score at the training step:  455 :  {'adversary_0': -37.95206054202542, 'agent_0': 4.604067911341273, 'agent_1': 4.604067911341273, 'agent_2': 4.604067911341273}
episode:  11 training step:  456 loss of agent  0 :  0.055041927844285965
episode:  11 training step:  456 loss of agent  1 :  0.1994139552116394
episode:  11 training step:  456 loss of agent  2 :  0.14286965131759644
episode:  11 training step:  456 loss of agent  3 :  0.13219794631004333
episode:  11 training step:  457 loss of agent  0 :  0.04593411087989807
episode:  11 training step:  457 loss of agent  1 :  0.2652154266834259
episode:  11 training step:  457 loss of agent  2 :  0.14614127576351166
episode:  11 training step:  457 loss of agent  3 :  0.11321179568767548
episode:  11 training step:  458 loss of agent  0 :  0.06192957982420921
episode:  11 training step:  458 loss of agent  1 :  0.2007904350757599
episode:  11 training step:  458 loss of agent  2 :  0.10098916292190552
episode:  11 training step:  458 loss of agent  3 :  0.1416458785533905
episode:  11 training step:  459 loss of agent  0 :  0.032745350152254105
episode:  11 training step:  459 loss of agent  1 :  0.19473271071910858
episode:  11 training step:  459 loss of agent  2 :  0.11289270222187042
episode:  11 training step:  459 loss of agent  3 :  0.111982561647892
episode:  11 training step:  460 loss of agent  0 :  0.06676594167947769
episode:  11 training step:  460 loss of agent  1 :  0.16020862758159637
episode:  11 training step:  460 loss of agent  2 :  0.11328593641519547
episode:  11 training step:  460 loss of agent  3 :  0.11721730977296829
Evaluation
env seed: 6 evaluation score at the training step:  460 :  {'adversary_0': -33.229981385919096, 'agent_0': -0.48225436010172745, 'agent_1': -0.48225436010172745, 'agent_2': -0.48225436010172745}
model saving.................................
episode:  11 training step:  461 loss of agent  0 :  0.053258173167705536
episode:  11 training step:  461 loss of agent  1 :  0.1746220886707306
episode:  11 training step:  461 loss of agent  2 :  0.15563355386257172
episode:  11 training step:  461 loss of agent  3 :  0.15245577692985535
episode:  11 training step:  462 loss of agent  0 :  0.040066588670015335
episode:  11 training step:  462 loss of agent  1 :  0.17797285318374634
episode:  11 training step:  462 loss of agent  2 :  0.09439428895711899
episode:  11 training step:  462 loss of agent  3 :  0.17584240436553955
episode:  11 training step:  463 loss of agent  0 :  0.040136151015758514
episode:  11 training step:  463 loss of agent  1 :  0.17385666072368622
episode:  11 training step:  463 loss of agent  2 :  0.14841055870056152
episode:  11 training step:  463 loss of agent  3 :  0.1419241577386856
episode:  11 training step:  464 loss of agent  0 :  0.06360200047492981
episode:  11 training step:  464 loss of agent  1 :  0.29623812437057495
episode:  11 training step:  464 loss of agent  2 :  0.2759041488170624
episode:  11 training step:  464 loss of agent  3 :  0.1148444190621376
episode:  11 training step:  465 loss of agent  0 :  0.11771251261234283
episode:  11 training step:  465 loss of agent  1 :  0.15595142543315887
episode:  11 training step:  465 loss of agent  2 :  0.16711461544036865
episode:  11 training step:  465 loss of agent  3 :  0.11627494543790817
Evaluation
env seed: 6 evaluation score at the training step:  465 :  {'adversary_0': -29.449096458751747, 'agent_0': -4.116494265278119, 'agent_1': -4.116494265278119, 'agent_2': -4.116494265278119}
episode:  11 training step:  466 loss of agent  0 :  0.06770195811986923
episode:  11 training step:  466 loss of agent  1 :  0.1361241340637207
episode:  11 training step:  466 loss of agent  2 :  0.14369040727615356
episode:  11 training step:  466 loss of agent  3 :  0.09405229240655899
episode:  11 training step:  467 loss of agent  0 :  0.035099487751722336
episode:  11 training step:  467 loss of agent  1 :  0.2111407071352005
episode:  11 training step:  467 loss of agent  2 :  0.1224277913570404
episode:  11 training step:  467 loss of agent  3 :  0.14810824394226074
episode:  11 training step:  468 loss of agent  0 :  0.05620964616537094
episode:  11 training step:  468 loss of agent  1 :  0.17860150337219238
episode:  11 training step:  468 loss of agent  2 :  0.09369197487831116
episode:  11 training step:  468 loss of agent  3 :  0.09130652993917465
episode:  11 training step:  469 loss of agent  0 :  0.05393877625465393
episode:  11 training step:  469 loss of agent  1 :  0.20654723048210144
episode:  11 training step:  469 loss of agent  2 :  0.13099181652069092
episode:  11 training step:  469 loss of agent  3 :  0.1359477937221527
episode:  11 training step:  470 loss of agent  0 :  0.06120176240801811
episode:  11 training step:  470 loss of agent  1 :  0.19070471823215485
episode:  11 training step:  470 loss of agent  2 :  0.13085192441940308
episode:  11 training step:  470 loss of agent  3 :  0.17969588935375214
Evaluation
env seed: 6 evaluation score at the training step:  470 :  {'adversary_0': -29.58705139981845, 'agent_0': -3.9827822310793928, 'agent_1': -3.9827822310793928, 'agent_2': -3.9827822310793928}
model saving.................................
episode:  11 training step:  471 loss of agent  0 :  0.06920897960662842
episode:  11 training step:  471 loss of agent  1 :  0.19547170400619507
episode:  11 training step:  471 loss of agent  2 :  0.10221926867961884
episode:  11 training step:  471 loss of agent  3 :  0.1629531979560852
episode:  11 training step:  472 loss of agent  0 :  0.09471047669649124
episode:  11 training step:  472 loss of agent  1 :  0.23231418430805206
episode:  11 training step:  472 loss of agent  2 :  0.17502886056900024
episode:  11 training step:  472 loss of agent  3 :  0.11904970556497574
episode:  11 training step:  473 loss of agent  0 :  0.056156110018491745
episode:  11 training step:  473 loss of agent  1 :  0.2930152416229248
episode:  11 training step:  473 loss of agent  2 :  0.18344302475452423
episode:  11 training step:  473 loss of agent  3 :  0.14981919527053833
episode:  11 training step:  474 loss of agent  0 :  0.06454042345285416
episode:  11 training step:  474 loss of agent  1 :  0.1468353271484375
episode:  11 training step:  474 loss of agent  2 :  0.12200650572776794
episode:  11 training step:  474 loss of agent  3 :  0.10324835032224655
episode:  11 training step:  475 loss of agent  0 :  0.06161703169345856
episode:  11 training step:  475 loss of agent  1 :  0.24421426653862
episode:  11 training step:  475 loss of agent  2 :  0.14797422289848328
episode:  11 training step:  475 loss of agent  3 :  0.15793435275554657
Evaluation
env seed: 6 evaluation score at the training step:  475 :  {'adversary_0': -31.26123952855003, 'agent_0': -2.3412495561541626, 'agent_1': -2.3412495561541626, 'agent_2': -2.3412495561541626}
episode:  11 training step:  476 loss of agent  0 :  0.048626381903886795
episode:  11 training step:  476 loss of agent  1 :  0.16625259816646576
episode:  11 training step:  476 loss of agent  2 :  0.09385697543621063
episode:  11 training step:  476 loss of agent  3 :  0.1482783406972885
episode:  11 training step:  477 loss of agent  0 :  0.07403599470853806
episode:  11 training step:  477 loss of agent  1 :  0.21055519580841064
episode:  11 training step:  477 loss of agent  2 :  0.12444575130939484
episode:  11 training step:  477 loss of agent  3 :  0.14397333562374115
episode 11 terminated at 600
episode: 12
epoch: 1
episode:  12 training step:  478 loss of agent  0 :  0.051477815955877304
episode:  12 training step:  478 loss of agent  1 :  0.21232426166534424
episode:  12 training step:  478 loss of agent  2 :  0.12452460080385208
episode:  12 training step:  478 loss of agent  3 :  0.20670796930789948
episode:  12 training step:  479 loss of agent  0 :  0.07253334671258926
episode:  12 training step:  479 loss of agent  1 :  0.2045385241508484
episode:  12 training step:  479 loss of agent  2 :  0.14692409336566925
episode:  12 training step:  479 loss of agent  3 :  0.15933552384376526
episode:  12 training step:  480 loss of agent  0 :  0.046288277953863144
episode:  12 training step:  480 loss of agent  1 :  0.2328658401966095
episode:  12 training step:  480 loss of agent  2 :  0.11304262280464172
episode:  12 training step:  480 loss of agent  3 :  0.1038057804107666
Evaluation
env seed: 6 evaluation score at the training step:  480 :  {'adversary_0': -28.979818989480982, 'agent_0': -4.674180458937565, 'agent_1': -4.674180458937565, 'agent_2': -4.674180458937565}
model saving.................................
episode:  12 training step:  481 loss of agent  0 :  0.04717639088630676
episode:  12 training step:  481 loss of agent  1 :  0.1680659055709839
episode:  12 training step:  481 loss of agent  2 :  0.09257293492555618
episode:  12 training step:  481 loss of agent  3 :  0.1366066336631775
episode:  12 training step:  482 loss of agent  0 :  0.06393761932849884
episode:  12 training step:  482 loss of agent  1 :  0.18340818583965302
episode:  12 training step:  482 loss of agent  2 :  0.11689895391464233
episode:  12 training step:  482 loss of agent  3 :  0.12774217128753662
episode:  12 training step:  483 loss of agent  0 :  0.06173250451683998
episode:  12 training step:  483 loss of agent  1 :  0.22520877420902252
episode:  12 training step:  483 loss of agent  2 :  0.13861453533172607
episode:  12 training step:  483 loss of agent  3 :  0.13790084421634674
episode:  12 training step:  484 loss of agent  0 :  0.0755058079957962
episode:  12 training step:  484 loss of agent  1 :  0.1737149953842163
episode:  12 training step:  484 loss of agent  2 :  0.13234859704971313
episode:  12 training step:  484 loss of agent  3 :  0.1739061176776886
episode:  12 training step:  485 loss of agent  0 :  0.07149718701839447
episode:  12 training step:  485 loss of agent  1 :  0.37135663628578186
episode:  12 training step:  485 loss of agent  2 :  0.1297091543674469
episode:  12 training step:  485 loss of agent  3 :  0.15205377340316772
Evaluation
env seed: 6 evaluation score at the training step:  485 :  {'adversary_0': -31.044253154606622, 'agent_0': -2.4461349532236674, 'agent_1': -2.4461349532236674, 'agent_2': -2.4461349532236674}
episode:  12 training step:  486 loss of agent  0 :  0.047354985028505325
episode:  12 training step:  486 loss of agent  1 :  0.12527328729629517
episode:  12 training step:  486 loss of agent  2 :  0.13769273459911346
episode:  12 training step:  486 loss of agent  3 :  0.10138536989688873
episode:  12 training step:  487 loss of agent  0 :  0.03576292842626572
episode:  12 training step:  487 loss of agent  1 :  0.2357301115989685
episode:  12 training step:  487 loss of agent  2 :  0.2009686827659607
episode:  12 training step:  487 loss of agent  3 :  0.1965339481830597
episode:  12 training step:  488 loss of agent  0 :  0.034510254859924316
episode:  12 training step:  488 loss of agent  1 :  0.1866408735513687
episode:  12 training step:  488 loss of agent  2 :  0.1752140074968338
episode:  12 training step:  488 loss of agent  3 :  0.20830276608467102
episode:  12 training step:  489 loss of agent  0 :  0.07265423238277435
episode:  12 training step:  489 loss of agent  1 :  0.18630951642990112
episode:  12 training step:  489 loss of agent  2 :  0.17629027366638184
episode:  12 training step:  489 loss of agent  3 :  0.19684652984142303
episode:  12 training step:  490 loss of agent  0 :  0.06196056678891182
episode:  12 training step:  490 loss of agent  1 :  0.20700198411941528
episode:  12 training step:  490 loss of agent  2 :  0.13387328386306763
episode:  12 training step:  490 loss of agent  3 :  0.14945273101329803
Evaluation
env seed: 6 evaluation score at the training step:  490 :  {'adversary_0': -33.17973990144282, 'agent_0': -0.7980413910140144, 'agent_1': -0.7980413910140144, 'agent_2': -0.7980413910140144}
model saving.................................
episode:  12 training step:  491 loss of agent  0 :  0.04839609935879707
episode:  12 training step:  491 loss of agent  1 :  0.17365996539592743
episode:  12 training step:  491 loss of agent  2 :  0.1824066936969757
episode:  12 training step:  491 loss of agent  3 :  0.21224892139434814
episode:  12 training step:  492 loss of agent  0 :  0.05569059029221535
episode:  12 training step:  492 loss of agent  1 :  0.23230579495429993
episode:  12 training step:  492 loss of agent  2 :  0.18095456063747406
episode:  12 training step:  492 loss of agent  3 :  0.06982945650815964
episode:  12 training step:  493 loss of agent  0 :  0.06761888414621353
episode:  12 training step:  493 loss of agent  1 :  0.18879087269306183
episode:  12 training step:  493 loss of agent  2 :  0.15375101566314697
episode:  12 training step:  493 loss of agent  3 :  0.13425253331661224
episode:  12 training step:  494 loss of agent  0 :  0.05040637031197548
episode:  12 training step:  494 loss of agent  1 :  0.2909328043460846
episode:  12 training step:  494 loss of agent  2 :  0.10273326933383942
episode:  12 training step:  494 loss of agent  3 :  0.1473073661327362
episode:  12 training step:  495 loss of agent  0 :  0.05154796317219734
episode:  12 training step:  495 loss of agent  1 :  0.24462854862213135
episode:  12 training step:  495 loss of agent  2 :  0.17248259484767914
episode:  12 training step:  495 loss of agent  3 :  0.11019687354564667
Evaluation
env seed: 6 evaluation score at the training step:  495 :  {'adversary_0': -38.00300755758569, 'agent_0': 4.791188890925045, 'agent_1': 4.791188890925045, 'agent_2': 4.791188890925045}
episode:  12 training step:  496 loss of agent  0 :  0.07364694774150848
episode:  12 training step:  496 loss of agent  1 :  0.21517468988895416
episode:  12 training step:  496 loss of agent  2 :  0.10217975825071335
episode:  12 training step:  496 loss of agent  3 :  0.1335231065750122
episode:  12 training step:  497 loss of agent  0 :  0.067520372569561
episode:  12 training step:  497 loss of agent  1 :  0.13996700942516327
episode:  12 training step:  497 loss of agent  2 :  0.10686095803976059
episode:  12 training step:  497 loss of agent  3 :  0.18859268724918365
episode:  12 training step:  498 loss of agent  0 :  0.04483018070459366
episode:  12 training step:  498 loss of agent  1 :  0.22268417477607727
episode:  12 training step:  498 loss of agent  2 :  0.17708440124988556
episode:  12 training step:  498 loss of agent  3 :  0.15114803612232208
episode:  12 training step:  499 loss of agent  0 :  0.0503646656870842
episode:  12 training step:  499 loss of agent  1 :  0.13301968574523926
episode:  12 training step:  499 loss of agent  2 :  0.11031630635261536
episode:  12 training step:  499 loss of agent  3 :  0.14485490322113037
episode:  12 training step:  500 loss of agent  0 :  0.04541746899485588
episode:  12 training step:  500 loss of agent  1 :  0.22831501066684723
episode:  12 training step:  500 loss of agent  2 :  0.10522198677062988
episode:  12 training step:  500 loss of agent  3 :  0.1579912006855011
Evaluation
env seed: 6 evaluation score at the training step:  500 :  {'adversary_0': -32.07214170907529, 'agent_0': -0.0656463292737645, 'agent_1': -0.0656463292737645, 'agent_2': -0.0656463292737645}
model saving.................................
episode:  12 training step:  501 loss of agent  0 :  0.04658083990216255
episode:  12 training step:  501 loss of agent  1 :  0.14362123608589172
episode:  12 training step:  501 loss of agent  2 :  0.12088607996702194
episode:  12 training step:  501 loss of agent  3 :  0.07110081613063812
episode 12 terminated at 625
epoch: 2
episode:  12 training step:  502 loss of agent  0 :  0.03727182373404503
episode:  12 training step:  502 loss of agent  1 :  0.2989673614501953
episode:  12 training step:  502 loss of agent  2 :  0.1402043104171753
episode:  12 training step:  502 loss of agent  3 :  0.09382329881191254
episode:  12 training step:  503 loss of agent  0 :  0.045019134879112244
episode:  12 training step:  503 loss of agent  1 :  0.14230108261108398
episode:  12 training step:  503 loss of agent  2 :  0.18821807205677032
episode:  12 training step:  503 loss of agent  3 :  0.15715138614177704
episode:  12 training step:  504 loss of agent  0 :  0.07024987787008286
episode:  12 training step:  504 loss of agent  1 :  0.1607750654220581
episode:  12 training step:  504 loss of agent  2 :  0.21349939703941345
episode:  12 training step:  504 loss of agent  3 :  0.18708840012550354
episode:  12 training step:  505 loss of agent  0 :  0.08400069922208786
episode:  12 training step:  505 loss of agent  1 :  0.2258179783821106
episode:  12 training step:  505 loss of agent  2 :  0.1516234427690506
episode:  12 training step:  505 loss of agent  3 :  0.1154998317360878
Evaluation
env seed: 6 evaluation score at the training step:  505 :  {'adversary_0': -29.79747552508537, 'agent_0': -3.8736214850076593, 'agent_1': -3.8736214850076593, 'agent_2': -3.8736214850076593}
episode:  12 training step:  506 loss of agent  0 :  0.07060304284095764
episode:  12 training step:  506 loss of agent  1 :  0.20543016493320465
episode:  12 training step:  506 loss of agent  2 :  0.18359516561031342
episode:  12 training step:  506 loss of agent  3 :  0.12115368247032166
episode:  12 training step:  507 loss of agent  0 :  0.046552982181310654
episode:  12 training step:  507 loss of agent  1 :  0.18526002764701843
episode:  12 training step:  507 loss of agent  2 :  0.1157849133014679
episode:  12 training step:  507 loss of agent  3 :  0.11875409632921219
episode:  12 training step:  508 loss of agent  0 :  0.05257261544466019
episode:  12 training step:  508 loss of agent  1 :  0.2358412742614746
episode:  12 training step:  508 loss of agent  2 :  0.13779106736183167
episode:  12 training step:  508 loss of agent  3 :  0.11817969381809235
episode:  12 training step:  509 loss of agent  0 :  0.060418955981731415
episode:  12 training step:  509 loss of agent  1 :  0.13292226195335388
episode:  12 training step:  509 loss of agent  2 :  0.18507015705108643
episode:  12 training step:  509 loss of agent  3 :  0.11504609882831573
episode:  12 training step:  510 loss of agent  0 :  0.059015434235334396
episode:  12 training step:  510 loss of agent  1 :  0.23846298456192017
episode:  12 training step:  510 loss of agent  2 :  0.2159002423286438
episode:  12 training step:  510 loss of agent  3 :  0.13503357768058777
Evaluation
env seed: 6 evaluation score at the training step:  510 :  {'adversary_0': -29.716925642346194, 'agent_0': 2.17529727300166, 'agent_1': 2.17529727300166, 'agent_2': 2.17529727300166}
model saving.................................
episode:  12 training step:  511 loss of agent  0 :  0.07024461030960083
episode:  12 training step:  511 loss of agent  1 :  0.3293164372444153
episode:  12 training step:  511 loss of agent  2 :  0.12296368181705475
episode:  12 training step:  511 loss of agent  3 :  0.17277035117149353
episode:  12 training step:  512 loss of agent  0 :  0.0340227410197258
episode:  12 training step:  512 loss of agent  1 :  0.15671032667160034
episode:  12 training step:  512 loss of agent  2 :  0.12717804312705994
episode:  12 training step:  512 loss of agent  3 :  0.15923182666301727
episode:  12 training step:  513 loss of agent  0 :  0.06413503736257553
episode:  12 training step:  513 loss of agent  1 :  0.1934029757976532
episode:  12 training step:  513 loss of agent  2 :  0.15286262333393097
episode:  12 training step:  513 loss of agent  3 :  0.1257668435573578
episode:  12 training step:  514 loss of agent  0 :  0.05405798554420471
episode:  12 training step:  514 loss of agent  1 :  0.15528395771980286
episode:  12 training step:  514 loss of agent  2 :  0.11393719166517258
episode:  12 training step:  514 loss of agent  3 :  0.1123897060751915
episode:  12 training step:  515 loss of agent  0 :  0.050324756652116776
episode:  12 training step:  515 loss of agent  1 :  0.1714138686656952
episode:  12 training step:  515 loss of agent  2 :  0.167190283536911
episode:  12 training step:  515 loss of agent  3 :  0.13449794054031372
Evaluation
env seed: 6 evaluation score at the training step:  515 :  {'adversary_0': -29.735096477215325, 'agent_0': 2.0404991815133475, 'agent_1': 2.0404991815133475, 'agent_2': 2.0404991815133475}
episode:  12 training step:  516 loss of agent  0 :  0.055702053010463715
episode:  12 training step:  516 loss of agent  1 :  0.2758209705352783
episode:  12 training step:  516 loss of agent  2 :  0.17414836585521698
episode:  12 training step:  516 loss of agent  3 :  0.1225503459572792
episode:  12 training step:  517 loss of agent  0 :  0.05110638588666916
episode:  12 training step:  517 loss of agent  1 :  0.21821603178977966
episode:  12 training step:  517 loss of agent  2 :  0.1763969361782074
episode:  12 training step:  517 loss of agent  3 :  0.15045876801013947
episode:  12 training step:  518 loss of agent  0 :  0.0643560066819191
episode:  12 training step:  518 loss of agent  1 :  0.12489829212427139
episode:  12 training step:  518 loss of agent  2 :  0.13428138196468353
episode:  12 training step:  518 loss of agent  3 :  0.14216478168964386
episode:  12 training step:  519 loss of agent  0 :  0.05412725359201431
episode:  12 training step:  519 loss of agent  1 :  0.20825698971748352
episode:  12 training step:  519 loss of agent  2 :  0.18210220336914062
episode:  12 training step:  519 loss of agent  3 :  0.20495131611824036
episode:  12 training step:  520 loss of agent  0 :  0.052238769829273224
episode:  12 training step:  520 loss of agent  1 :  0.19004109501838684
episode:  12 training step:  520 loss of agent  2 :  0.14922931790351868
episode:  12 training step:  520 loss of agent  3 :  0.12026666849851608
Evaluation
env seed: 6 evaluation score at the training step:  520 :  {'adversary_0': -29.39452148982233, 'agent_0': 1.8005017334080846, 'agent_1': 1.8005017334080846, 'agent_2': 1.8005017334080846}
model saving.................................
episode:  12 training step:  521 loss of agent  0 :  0.08170466870069504
episode:  12 training step:  521 loss of agent  1 :  0.265382319688797
episode:  12 training step:  521 loss of agent  2 :  0.13236327469348907
episode:  12 training step:  521 loss of agent  3 :  0.09073388576507568
episode:  12 training step:  522 loss of agent  0 :  0.08105812221765518
episode:  12 training step:  522 loss of agent  1 :  0.17304223775863647
episode:  12 training step:  522 loss of agent  2 :  0.1251208484172821
episode:  12 training step:  522 loss of agent  3 :  0.11839395016431808
episode:  12 training step:  523 loss of agent  0 :  0.032244376838207245
episode:  12 training step:  523 loss of agent  1 :  0.2593439221382141
episode:  12 training step:  523 loss of agent  2 :  0.127354696393013
episode:  12 training step:  523 loss of agent  3 :  0.19630280137062073
episode:  12 training step:  524 loss of agent  0 :  0.05043527111411095
episode:  12 training step:  524 loss of agent  1 :  0.23378677666187286
episode:  12 training step:  524 loss of agent  2 :  0.1143585816025734
episode:  12 training step:  524 loss of agent  3 :  0.1078048050403595
episode:  12 training step:  525 loss of agent  0 :  0.034459128975868225
episode:  12 training step:  525 loss of agent  1 :  0.21350514888763428
episode:  12 training step:  525 loss of agent  2 :  0.10576163232326508
episode:  12 training step:  525 loss of agent  3 :  0.08663764595985413
Evaluation
env seed: 6 evaluation score at the training step:  525 :  {'adversary_0': -30.153685523893564, 'agent_0': 2.466527367370884, 'agent_1': 2.466527367370884, 'agent_2': 2.466527367370884}
episode 12 terminated at 650
episode: 13
epoch: 1
episode:  13 training step:  526 loss of agent  0 :  0.09014269709587097
episode:  13 training step:  526 loss of agent  1 :  0.18262116611003876
episode:  13 training step:  526 loss of agent  2 :  0.14612583816051483
episode:  13 training step:  526 loss of agent  3 :  0.13425004482269287
episode:  13 training step:  527 loss of agent  0 :  0.10758637636899948
episode:  13 training step:  527 loss of agent  1 :  0.14885450899600983
episode:  13 training step:  527 loss of agent  2 :  0.13367198407649994
episode:  13 training step:  527 loss of agent  3 :  0.1686261147260666
episode:  13 training step:  528 loss of agent  0 :  0.10586261004209518
episode:  13 training step:  528 loss of agent  1 :  0.152583047747612
episode:  13 training step:  528 loss of agent  2 :  0.15840056538581848
episode:  13 training step:  528 loss of agent  3 :  0.14919321238994598
episode:  13 training step:  529 loss of agent  0 :  0.0435306690633297
episode:  13 training step:  529 loss of agent  1 :  0.22639687359333038
episode:  13 training step:  529 loss of agent  2 :  0.16559316217899323
episode:  13 training step:  529 loss of agent  3 :  0.07137609273195267
episode:  13 training step:  530 loss of agent  0 :  0.0529203899204731
episode:  13 training step:  530 loss of agent  1 :  0.1962956041097641
episode:  13 training step:  530 loss of agent  2 :  0.12700064480304718
episode:  13 training step:  530 loss of agent  3 :  0.10303686559200287
Evaluation
env seed: 6 evaluation score at the training step:  530 :  {'adversary_0': -29.84858423866671, 'agent_0': 1.9875722385698904, 'agent_1': 1.9875722385698904, 'agent_2': 1.9875722385698904}
model saving.................................
episode:  13 training step:  531 loss of agent  0 :  0.06543821841478348
episode:  13 training step:  531 loss of agent  1 :  0.16577112674713135
episode:  13 training step:  531 loss of agent  2 :  0.13739068806171417
episode:  13 training step:  531 loss of agent  3 :  0.15607334673404694
episode:  13 training step:  532 loss of agent  0 :  0.03549406677484512
episode:  13 training step:  532 loss of agent  1 :  0.23462289571762085
episode:  13 training step:  532 loss of agent  2 :  0.1459057331085205
episode:  13 training step:  532 loss of agent  3 :  0.10655103623867035
episode:  13 training step:  533 loss of agent  0 :  0.06370574235916138
episode:  13 training step:  533 loss of agent  1 :  0.27497029304504395
episode:  13 training step:  533 loss of agent  2 :  0.10362738370895386
episode:  13 training step:  533 loss of agent  3 :  0.1648344248533249
episode:  13 training step:  534 loss of agent  0 :  0.05528312176465988
episode:  13 training step:  534 loss of agent  1 :  0.19730976223945618
episode:  13 training step:  534 loss of agent  2 :  0.15134797990322113
episode:  13 training step:  534 loss of agent  3 :  0.16569884121418
episode:  13 training step:  535 loss of agent  0 :  0.040805090218782425
episode:  13 training step:  535 loss of agent  1 :  0.267736554145813
episode:  13 training step:  535 loss of agent  2 :  0.1371999830007553
episode:  13 training step:  535 loss of agent  3 :  0.1093289852142334
Evaluation
env seed: 6 evaluation score at the training step:  535 :  {'adversary_0': -29.185564318833322, 'agent_0': 1.122401981046655, 'agent_1': 1.122401981046655, 'agent_2': 1.122401981046655}
episode:  13 training step:  536 loss of agent  0 :  0.06401605904102325
episode:  13 training step:  536 loss of agent  1 :  0.19096292555332184
episode:  13 training step:  536 loss of agent  2 :  0.12276428937911987
episode:  13 training step:  536 loss of agent  3 :  0.10940510779619217
episode:  13 training step:  537 loss of agent  0 :  0.0770796686410904
episode:  13 training step:  537 loss of agent  1 :  0.2250390648841858
episode:  13 training step:  537 loss of agent  2 :  0.12238024175167084
episode:  13 training step:  537 loss of agent  3 :  0.06426236033439636
episode:  13 training step:  538 loss of agent  0 :  0.058500152081251144
episode:  13 training step:  538 loss of agent  1 :  0.22960683703422546
episode:  13 training step:  538 loss of agent  2 :  0.11394495517015457
episode:  13 training step:  538 loss of agent  3 :  0.1169365793466568
episode:  13 training step:  539 loss of agent  0 :  0.04503883048892021
episode:  13 training step:  539 loss of agent  1 :  0.24115540087223053
episode:  13 training step:  539 loss of agent  2 :  0.07355457544326782
episode:  13 training step:  539 loss of agent  3 :  0.12038800120353699
episode:  13 training step:  540 loss of agent  0 :  0.06338360905647278
episode:  13 training step:  540 loss of agent  1 :  0.1284186989068985
episode:  13 training step:  540 loss of agent  2 :  0.1293228715658188
episode:  13 training step:  540 loss of agent  3 :  0.1960580050945282
Evaluation
env seed: 6 evaluation score at the training step:  540 :  {'adversary_0': -29.97355738288989, 'agent_0': -0.20397411787770398, 'agent_1': -0.20397411787770398, 'agent_2': -0.20397411787770398}
model saving.................................
episode:  13 training step:  541 loss of agent  0 :  0.059698157012462616
episode:  13 training step:  541 loss of agent  1 :  0.1786838322877884
episode:  13 training step:  541 loss of agent  2 :  0.15185479819774628
episode:  13 training step:  541 loss of agent  3 :  0.1284428983926773
episode:  13 training step:  542 loss of agent  0 :  0.06623398512601852
episode:  13 training step:  542 loss of agent  1 :  0.1632891297340393
episode:  13 training step:  542 loss of agent  2 :  0.11352253705263138
episode:  13 training step:  542 loss of agent  3 :  0.1281389594078064
episode:  13 training step:  543 loss of agent  0 :  0.0686415284872055
episode:  13 training step:  543 loss of agent  1 :  0.16845181584358215
episode:  13 training step:  543 loss of agent  2 :  0.10700669139623642
episode:  13 training step:  543 loss of agent  3 :  0.10943792760372162
episode:  13 training step:  544 loss of agent  0 :  0.05381358414888382
episode:  13 training step:  544 loss of agent  1 :  0.2669566869735718
episode:  13 training step:  544 loss of agent  2 :  0.10272250324487686
episode:  13 training step:  544 loss of agent  3 :  0.11027723550796509
episode:  13 training step:  545 loss of agent  0 :  0.04477566108107567
episode:  13 training step:  545 loss of agent  1 :  0.19867895543575287
episode:  13 training step:  545 loss of agent  2 :  0.11062502861022949
episode:  13 training step:  545 loss of agent  3 :  0.14007967710494995
Evaluation
env seed: 6 evaluation score at the training step:  545 :  {'adversary_0': -29.91526697507794, 'agent_0': -1.1188049277248777, 'agent_1': -1.1188049277248777, 'agent_2': -1.1188049277248777}
episode:  13 training step:  546 loss of agent  0 :  0.08786651492118835
episode:  13 training step:  546 loss of agent  1 :  0.30873751640319824
episode:  13 training step:  546 loss of agent  2 :  0.19866372644901276
episode:  13 training step:  546 loss of agent  3 :  0.13701120018959045
episode:  13 training step:  547 loss of agent  0 :  0.06362161785364151
episode:  13 training step:  547 loss of agent  1 :  0.3119428753852844
episode:  13 training step:  547 loss of agent  2 :  0.12297599017620087
episode:  13 training step:  547 loss of agent  3 :  0.10393080860376358
episode:  13 training step:  548 loss of agent  0 :  0.11154567450284958
episode:  13 training step:  548 loss of agent  1 :  0.24880175292491913
episode:  13 training step:  548 loss of agent  2 :  0.10712112486362457
episode:  13 training step:  548 loss of agent  3 :  0.1501249372959137
episode:  13 training step:  549 loss of agent  0 :  0.09971843659877777
episode:  13 training step:  549 loss of agent  1 :  0.22810465097427368
episode:  13 training step:  549 loss of agent  2 :  0.13422055542469025
episode:  13 training step:  549 loss of agent  3 :  0.1416289210319519
episode 13 terminated at 675
epoch: 2
episode:  13 training step:  550 loss of agent  0 :  0.05756119638681412
episode:  13 training step:  550 loss of agent  1 :  0.2850359082221985
episode:  13 training step:  550 loss of agent  2 :  0.17045381665229797
episode:  13 training step:  550 loss of agent  3 :  0.12452767044305801
Evaluation
env seed: 6 evaluation score at the training step:  550 :  {'adversary_0': -57.03703290513711, 'agent_0': 23.413830858083152, 'agent_1': 23.413830858083152, 'agent_2': 23.413830858083152}
model saving.................................
episode:  13 training step:  551 loss of agent  0 :  0.05412262678146362
episode:  13 training step:  551 loss of agent  1 :  0.16078214347362518
episode:  13 training step:  551 loss of agent  2 :  0.08721035718917847
episode:  13 training step:  551 loss of agent  3 :  0.08457672595977783
episode:  13 training step:  552 loss of agent  0 :  0.06373028457164764
episode:  13 training step:  552 loss of agent  1 :  0.26407456398010254
episode:  13 training step:  552 loss of agent  2 :  0.1415327489376068
episode:  13 training step:  552 loss of agent  3 :  0.22088351845741272
episode:  13 training step:  553 loss of agent  0 :  0.07000164687633514
episode:  13 training step:  553 loss of agent  1 :  0.1754721999168396
episode:  13 training step:  553 loss of agent  2 :  0.10378030687570572
episode:  13 training step:  553 loss of agent  3 :  0.14003878831863403
episode:  13 training step:  554 loss of agent  0 :  0.10849682986736298
episode:  13 training step:  554 loss of agent  1 :  0.2581268846988678
episode:  13 training step:  554 loss of agent  2 :  0.16060768067836761
episode:  13 training step:  554 loss of agent  3 :  0.1669025868177414
episode:  13 training step:  555 loss of agent  0 :  0.05725998058915138
episode:  13 training step:  555 loss of agent  1 :  0.2835659384727478
episode:  13 training step:  555 loss of agent  2 :  0.18800130486488342
episode:  13 training step:  555 loss of agent  3 :  0.16638106107711792
Evaluation
env seed: 6 evaluation score at the training step:  555 :  {'adversary_0': -50.98395249124847, 'agent_0': 17.381463406544288, 'agent_1': 17.381463406544288, 'agent_2': 17.381463406544288}
episode:  13 training step:  556 loss of agent  0 :  0.05821627005934715
episode:  13 training step:  556 loss of agent  1 :  0.1678217351436615
episode:  13 training step:  556 loss of agent  2 :  0.14470702409744263
episode:  13 training step:  556 loss of agent  3 :  0.1833013892173767
episode:  13 training step:  557 loss of agent  0 :  0.0766114592552185
episode:  13 training step:  557 loss of agent  1 :  0.18253880739212036
episode:  13 training step:  557 loss of agent  2 :  0.10486955940723419
episode:  13 training step:  557 loss of agent  3 :  0.14471210539340973
episode:  13 training step:  558 loss of agent  0 :  0.042692091315984726
episode:  13 training step:  558 loss of agent  1 :  0.2771293520927429
episode:  13 training step:  558 loss of agent  2 :  0.11399921774864197
episode:  13 training step:  558 loss of agent  3 :  0.20148129761219025
episode:  13 training step:  559 loss of agent  0 :  0.07392104715108871
episode:  13 training step:  559 loss of agent  1 :  0.24005529284477234
episode:  13 training step:  559 loss of agent  2 :  0.17017313838005066
episode:  13 training step:  559 loss of agent  3 :  0.12531885504722595
episode:  13 training step:  560 loss of agent  0 :  0.04509369656443596
episode:  13 training step:  560 loss of agent  1 :  0.2547129988670349
episode:  13 training step:  560 loss of agent  2 :  0.09976817667484283
episode:  13 training step:  560 loss of agent  3 :  0.10479988157749176
Evaluation
env seed: 6 evaluation score at the training step:  560 :  {'adversary_0': -49.279054859791145, 'agent_0': 15.854708625267932, 'agent_1': 15.854708625267932, 'agent_2': 15.854708625267932}
model saving.................................
episode:  13 training step:  561 loss of agent  0 :  0.03061288222670555
episode:  13 training step:  561 loss of agent  1 :  0.27639806270599365
episode:  13 training step:  561 loss of agent  2 :  0.12342782318592072
episode:  13 training step:  561 loss of agent  3 :  0.16852286458015442
episode:  13 training step:  562 loss of agent  0 :  0.07632795721292496
episode:  13 training step:  562 loss of agent  1 :  0.2493983954191208
episode:  13 training step:  562 loss of agent  2 :  0.12638285756111145
episode:  13 training step:  562 loss of agent  3 :  0.11243182420730591
episode:  13 training step:  563 loss of agent  0 :  0.09945319592952728
episode:  13 training step:  563 loss of agent  1 :  0.2735852599143982
episode:  13 training step:  563 loss of agent  2 :  0.17074289917945862
episode:  13 training step:  563 loss of agent  3 :  0.10288585722446442
episode:  13 training step:  564 loss of agent  0 :  0.057374436408281326
episode:  13 training step:  564 loss of agent  1 :  0.1873810589313507
episode:  13 training step:  564 loss of agent  2 :  0.1304159164428711
episode:  13 training step:  564 loss of agent  3 :  0.14828330278396606
episode:  13 training step:  565 loss of agent  0 :  0.06256004422903061
episode:  13 training step:  565 loss of agent  1 :  0.144164577126503
episode:  13 training step:  565 loss of agent  2 :  0.1762598603963852
episode:  13 training step:  565 loss of agent  3 :  0.11754118651151657
Evaluation
env seed: 6 evaluation score at the training step:  565 :  {'adversary_0': -49.13791666106886, 'agent_0': 15.535427576364649, 'agent_1': 15.535427576364649, 'agent_2': 15.535427576364649}
episode:  13 training step:  566 loss of agent  0 :  0.07620453089475632
episode:  13 training step:  566 loss of agent  1 :  0.2795596420764923
episode:  13 training step:  566 loss of agent  2 :  0.1554431915283203
episode:  13 training step:  566 loss of agent  3 :  0.10558682680130005
episode:  13 training step:  567 loss of agent  0 :  0.034926868975162506
episode:  13 training step:  567 loss of agent  1 :  0.25641414523124695
episode:  13 training step:  567 loss of agent  2 :  0.14752280712127686
episode:  13 training step:  567 loss of agent  3 :  0.18101800978183746
episode:  13 training step:  568 loss of agent  0 :  0.05474185198545456
episode:  13 training step:  568 loss of agent  1 :  0.2634904682636261
episode:  13 training step:  568 loss of agent  2 :  0.12066337466239929
episode:  13 training step:  568 loss of agent  3 :  0.11736498028039932
episode:  13 training step:  569 loss of agent  0 :  0.05849539861083031
episode:  13 training step:  569 loss of agent  1 :  0.15099142491817474
episode:  13 training step:  569 loss of agent  2 :  0.10235760360956192
episode:  13 training step:  569 loss of agent  3 :  0.09052111208438873
episode:  13 training step:  570 loss of agent  0 :  0.06181969493627548
episode:  13 training step:  570 loss of agent  1 :  0.20924313366413116
episode:  13 training step:  570 loss of agent  2 :  0.21226465702056885
episode:  13 training step:  570 loss of agent  3 :  0.10580883175134659
Evaluation
env seed: 6 evaluation score at the training step:  570 :  {'adversary_0': -38.85935566477114, 'agent_0': 9.588925259779643, 'agent_1': 9.588925259779643, 'agent_2': 9.588925259779643}
model saving.................................
episode:  13 training step:  571 loss of agent  0 :  0.07917150855064392
episode:  13 training step:  571 loss of agent  1 :  0.11113664507865906
episode:  13 training step:  571 loss of agent  2 :  0.15335988998413086
episode:  13 training step:  571 loss of agent  3 :  0.12096180021762848
episode:  13 training step:  572 loss of agent  0 :  0.07252146303653717
episode:  13 training step:  572 loss of agent  1 :  0.22777006030082703
episode:  13 training step:  572 loss of agent  2 :  0.14497707784175873
episode:  13 training step:  572 loss of agent  3 :  0.06678418815135956
episode:  13 training step:  573 loss of agent  0 :  0.04972603917121887
episode:  13 training step:  573 loss of agent  1 :  0.19107487797737122
episode:  13 training step:  573 loss of agent  2 :  0.12464666366577148
episode:  13 training step:  573 loss of agent  3 :  0.11428648233413696
episode 13 terminated at 700
episode: 14
epoch: 1
episode:  14 training step:  574 loss of agent  0 :  0.05893845111131668
episode:  14 training step:  574 loss of agent  1 :  0.1933748424053192
episode:  14 training step:  574 loss of agent  2 :  0.09522183984518051
episode:  14 training step:  574 loss of agent  3 :  0.09512919187545776
episode:  14 training step:  575 loss of agent  0 :  0.05620945617556572
episode:  14 training step:  575 loss of agent  1 :  0.3106897473335266
episode:  14 training step:  575 loss of agent  2 :  0.09442459791898727
episode:  14 training step:  575 loss of agent  3 :  0.08152322471141815
Evaluation
env seed: 6 evaluation score at the training step:  575 :  {'adversary_0': -22.755957214458693, 'agent_0': -5.403042178389521, 'agent_1': -5.403042178389521, 'agent_2': -5.403042178389521}
episode:  14 training step:  576 loss of agent  0 :  0.08331151306629181
episode:  14 training step:  576 loss of agent  1 :  0.2770957946777344
episode:  14 training step:  576 loss of agent  2 :  0.15263500809669495
episode:  14 training step:  576 loss of agent  3 :  0.13552986085414886
episode:  14 training step:  577 loss of agent  0 :  0.032396797090768814
episode:  14 training step:  577 loss of agent  1 :  0.23424892127513885
episode:  14 training step:  577 loss of agent  2 :  0.139369398355484
episode:  14 training step:  577 loss of agent  3 :  0.12362786382436752
episode:  14 training step:  578 loss of agent  0 :  0.0773150846362114
episode:  14 training step:  578 loss of agent  1 :  0.18285664916038513
episode:  14 training step:  578 loss of agent  2 :  0.13830424845218658
episode:  14 training step:  578 loss of agent  3 :  0.170704185962677
episode:  14 training step:  579 loss of agent  0 :  0.04977460578083992
episode:  14 training step:  579 loss of agent  1 :  0.10326100885868073
episode:  14 training step:  579 loss of agent  2 :  0.2495754063129425
episode:  14 training step:  579 loss of agent  3 :  0.09032181650400162
episode:  14 training step:  580 loss of agent  0 :  0.0456705205142498
episode:  14 training step:  580 loss of agent  1 :  0.24876825511455536
episode:  14 training step:  580 loss of agent  2 :  0.16259591281414032
episode:  14 training step:  580 loss of agent  3 :  0.16978543996810913
Evaluation
env seed: 6 evaluation score at the training step:  580 :  {'adversary_0': -24.43094270001961, 'agent_0': -6.600257838332017, 'agent_1': -6.600257838332017, 'agent_2': -6.600257838332017}
model saving.................................
episode:  14 training step:  581 loss of agent  0 :  0.049383386969566345
episode:  14 training step:  581 loss of agent  1 :  0.28337135910987854
episode:  14 training step:  581 loss of agent  2 :  0.1639116406440735
episode:  14 training step:  581 loss of agent  3 :  0.11758159101009369
episode:  14 training step:  582 loss of agent  0 :  0.06985576450824738
episode:  14 training step:  582 loss of agent  1 :  0.17471837997436523
episode:  14 training step:  582 loss of agent  2 :  0.14080747961997986
episode:  14 training step:  582 loss of agent  3 :  0.14475548267364502
episode:  14 training step:  583 loss of agent  0 :  0.05790682137012482
episode:  14 training step:  583 loss of agent  1 :  0.2497606873512268
episode:  14 training step:  583 loss of agent  2 :  0.07981175184249878
episode:  14 training step:  583 loss of agent  3 :  0.11292318999767303
episode:  14 training step:  584 loss of agent  0 :  0.052996885031461716
episode:  14 training step:  584 loss of agent  1 :  0.23104114830493927
episode:  14 training step:  584 loss of agent  2 :  0.12267294526100159
episode:  14 training step:  584 loss of agent  3 :  0.106993168592453
episode:  14 training step:  585 loss of agent  0 :  0.07706498354673386
episode:  14 training step:  585 loss of agent  1 :  0.17502765357494354
episode:  14 training step:  585 loss of agent  2 :  0.09957718849182129
episode:  14 training step:  585 loss of agent  3 :  0.14884412288665771
Evaluation
env seed: 6 evaluation score at the training step:  585 :  {'adversary_0': -47.59561334577718, 'agent_0': 13.90908428741616, 'agent_1': 13.90908428741616, 'agent_2': 13.90908428741616}
episode:  14 training step:  586 loss of agent  0 :  0.04061456024646759
episode:  14 training step:  586 loss of agent  1 :  0.17875568568706512
episode:  14 training step:  586 loss of agent  2 :  0.12331093847751617
episode:  14 training step:  586 loss of agent  3 :  0.13833069801330566
episode:  14 training step:  587 loss of agent  0 :  0.03930462896823883
episode:  14 training step:  587 loss of agent  1 :  0.2662639319896698
episode:  14 training step:  587 loss of agent  2 :  0.11277187615633011
episode:  14 training step:  587 loss of agent  3 :  0.14618854224681854
episode:  14 training step:  588 loss of agent  0 :  0.05241218954324722
episode:  14 training step:  588 loss of agent  1 :  0.22490939497947693
episode:  14 training step:  588 loss of agent  2 :  0.1243399903178215
episode:  14 training step:  588 loss of agent  3 :  0.09016638994216919
episode:  14 training step:  589 loss of agent  0 :  0.0696532130241394
episode:  14 training step:  589 loss of agent  1 :  0.23345772922039032
episode:  14 training step:  589 loss of agent  2 :  0.17152699828147888
episode:  14 training step:  589 loss of agent  3 :  0.10439102351665497
episode:  14 training step:  590 loss of agent  0 :  0.03884942829608917
episode:  14 training step:  590 loss of agent  1 :  0.2059703916311264
episode:  14 training step:  590 loss of agent  2 :  0.11422470211982727
episode:  14 training step:  590 loss of agent  3 :  0.12703752517700195
Evaluation
env seed: 6 evaluation score at the training step:  590 :  {'adversary_0': -50.448341839950295, 'agent_0': 16.907035067781134, 'agent_1': 16.907035067781134, 'agent_2': 16.907035067781134}
model saving.................................
episode:  14 training step:  591 loss of agent  0 :  0.08626206964254379
episode:  14 training step:  591 loss of agent  1 :  0.15498560667037964
episode:  14 training step:  591 loss of agent  2 :  0.13434123992919922
episode:  14 training step:  591 loss of agent  3 :  0.15494683384895325
episode:  14 training step:  592 loss of agent  0 :  0.04654643312096596
episode:  14 training step:  592 loss of agent  1 :  0.18049296736717224
episode:  14 training step:  592 loss of agent  2 :  0.20000134408473969
episode:  14 training step:  592 loss of agent  3 :  0.08812643587589264
episode:  14 training step:  593 loss of agent  0 :  0.048546500504016876
episode:  14 training step:  593 loss of agent  1 :  0.15967662632465363
episode:  14 training step:  593 loss of agent  2 :  0.10175573825836182
episode:  14 training step:  593 loss of agent  3 :  0.13349415361881256
episode:  14 training step:  594 loss of agent  0 :  0.05674741789698601
episode:  14 training step:  594 loss of agent  1 :  0.2874339818954468
episode:  14 training step:  594 loss of agent  2 :  0.1606299877166748
episode:  14 training step:  594 loss of agent  3 :  0.12705513834953308
episode:  14 training step:  595 loss of agent  0 :  0.0834629014134407
episode:  14 training step:  595 loss of agent  1 :  0.18645179271697998
episode:  14 training step:  595 loss of agent  2 :  0.17621825635433197
episode:  14 training step:  595 loss of agent  3 :  0.14708071947097778
Evaluation
env seed: 6 evaluation score at the training step:  595 :  {'adversary_0': -47.58452209485581, 'agent_0': 15.224273963947322, 'agent_1': 15.224273963947322, 'agent_2': 15.224273963947322}
episode:  14 training step:  596 loss of agent  0 :  0.06700955331325531
episode:  14 training step:  596 loss of agent  1 :  0.24849556386470795
episode:  14 training step:  596 loss of agent  2 :  0.13105109333992004
episode:  14 training step:  596 loss of agent  3 :  0.0865863636136055
episode:  14 training step:  597 loss of agent  0 :  0.060700103640556335
episode:  14 training step:  597 loss of agent  1 :  0.2994338274002075
episode:  14 training step:  597 loss of agent  2 :  0.1162930354475975
episode:  14 training step:  597 loss of agent  3 :  0.15521854162216187
episode 14 terminated at 725
epoch: 2
episode:  14 training step:  598 loss of agent  0 :  0.06340595334768295
episode:  14 training step:  598 loss of agent  1 :  0.12821614742279053
episode:  14 training step:  598 loss of agent  2 :  0.14244425296783447
episode:  14 training step:  598 loss of agent  3 :  0.15175023674964905
episode:  14 training step:  599 loss of agent  0 :  0.0572572723031044
episode:  14 training step:  599 loss of agent  1 :  0.18779899179935455
episode:  14 training step:  599 loss of agent  2 :  0.14771786332130432
episode:  14 training step:  599 loss of agent  3 :  0.1375322937965393
episode:  14 training step:  600 loss of agent  0 :  0.057534266263246536
episode:  14 training step:  600 loss of agent  1 :  0.2796083688735962
episode:  14 training step:  600 loss of agent  2 :  0.09924978017807007
episode:  14 training step:  600 loss of agent  3 :  0.18699121475219727
Evaluation
env seed: 6 evaluation score at the training step:  600 :  {'adversary_0': -30.113504150935476, 'agent_0': 4.608938869817057, 'agent_1': 4.608938869817057, 'agent_2': 4.608938869817057}
model saving.................................
episode:  14 training step:  601 loss of agent  0 :  0.0769229382276535
episode:  14 training step:  601 loss of agent  1 :  0.24834086000919342
episode:  14 training step:  601 loss of agent  2 :  0.1637418121099472
episode:  14 training step:  601 loss of agent  3 :  0.10959775745868683
episode:  14 training step:  602 loss of agent  0 :  0.04248801991343498
episode:  14 training step:  602 loss of agent  1 :  0.21877992153167725
episode:  14 training step:  602 loss of agent  2 :  0.12856270372867584
episode:  14 training step:  602 loss of agent  3 :  0.13673599064350128
episode:  14 training step:  603 loss of agent  0 :  0.05671004205942154
episode:  14 training step:  603 loss of agent  1 :  0.1955375224351883
episode:  14 training step:  603 loss of agent  2 :  0.1550895720720291
episode:  14 training step:  603 loss of agent  3 :  0.13612431287765503
episode:  14 training step:  604 loss of agent  0 :  0.050884976983070374
episode:  14 training step:  604 loss of agent  1 :  0.30900803208351135
episode:  14 training step:  604 loss of agent  2 :  0.18144582211971283
episode:  14 training step:  604 loss of agent  3 :  0.16517247259616852
episode:  14 training step:  605 loss of agent  0 :  0.029929902404546738
episode:  14 training step:  605 loss of agent  1 :  0.2372376173734665
episode:  14 training step:  605 loss of agent  2 :  0.19135130941867828
episode:  14 training step:  605 loss of agent  3 :  0.08737565577030182
Evaluation
env seed: 6 evaluation score at the training step:  605 :  {'adversary_0': -43.3436690183035, 'agent_0': 18.391119389388262, 'agent_1': 18.391119389388262, 'agent_2': 18.391119389388262}
episode:  14 training step:  606 loss of agent  0 :  0.03330559283494949
episode:  14 training step:  606 loss of agent  1 :  0.19615906476974487
episode:  14 training step:  606 loss of agent  2 :  0.14479321241378784
episode:  14 training step:  606 loss of agent  3 :  0.1244189590215683
episode:  14 training step:  607 loss of agent  0 :  0.04148820415139198
episode:  14 training step:  607 loss of agent  1 :  0.22746485471725464
episode:  14 training step:  607 loss of agent  2 :  0.08377836644649506
episode:  14 training step:  607 loss of agent  3 :  0.10988536477088928
episode:  14 training step:  608 loss of agent  0 :  0.05521382391452789
episode:  14 training step:  608 loss of agent  1 :  0.20924076437950134
episode:  14 training step:  608 loss of agent  2 :  0.12348722666501999
episode:  14 training step:  608 loss of agent  3 :  0.17125937342643738
episode:  14 training step:  609 loss of agent  0 :  0.030895771458745003
episode:  14 training step:  609 loss of agent  1 :  0.15642307698726654
episode:  14 training step:  609 loss of agent  2 :  0.1272953599691391
episode:  14 training step:  609 loss of agent  3 :  0.18856751918792725
episode:  14 training step:  610 loss of agent  0 :  0.054548945277929306
episode:  14 training step:  610 loss of agent  1 :  0.1713525503873825
episode:  14 training step:  610 loss of agent  2 :  0.1500781774520874
episode:  14 training step:  610 loss of agent  3 :  0.1183319166302681
Evaluation
env seed: 6 evaluation score at the training step:  610 :  {'adversary_0': -42.73824094952915, 'agent_0': 17.381971978585657, 'agent_1': 17.381971978585657, 'agent_2': 17.381971978585657}
model saving.................................
episode:  14 training step:  611 loss of agent  0 :  0.06145410239696503
episode:  14 training step:  611 loss of agent  1 :  0.23896631598472595
episode:  14 training step:  611 loss of agent  2 :  0.12350724637508392
episode:  14 training step:  611 loss of agent  3 :  0.11285848170518875
episode:  14 training step:  612 loss of agent  0 :  0.06184261664748192
episode:  14 training step:  612 loss of agent  1 :  0.26327788829803467
episode:  14 training step:  612 loss of agent  2 :  0.17457365989685059
episode:  14 training step:  612 loss of agent  3 :  0.1312878131866455
episode:  14 training step:  613 loss of agent  0 :  0.0925348773598671
episode:  14 training step:  613 loss of agent  1 :  0.1500099152326584
episode:  14 training step:  613 loss of agent  2 :  0.12872053682804108
episode:  14 training step:  613 loss of agent  3 :  0.13244596123695374
episode:  14 training step:  614 loss of agent  0 :  0.05724257603287697
episode:  14 training step:  614 loss of agent  1 :  0.18412718176841736
episode:  14 training step:  614 loss of agent  2 :  0.15348312258720398
episode:  14 training step:  614 loss of agent  3 :  0.21679705381393433
episode:  14 training step:  615 loss of agent  0 :  0.04309504106640816
episode:  14 training step:  615 loss of agent  1 :  0.26169803738594055
episode:  14 training step:  615 loss of agent  2 :  0.1644619107246399
episode:  14 training step:  615 loss of agent  3 :  0.12243196368217468
Evaluation
env seed: 6 evaluation score at the training step:  615 :  {'adversary_0': -29.475016296005485, 'agent_0': 4.3268469537057035, 'agent_1': 4.3268469537057035, 'agent_2': 4.3268469537057035}
episode:  14 training step:  616 loss of agent  0 :  0.04340360313653946
episode:  14 training step:  616 loss of agent  1 :  0.23615510761737823
episode:  14 training step:  616 loss of agent  2 :  0.1190403625369072
episode:  14 training step:  616 loss of agent  3 :  0.11961676180362701
episode:  14 training step:  617 loss of agent  0 :  0.05102672427892685
episode:  14 training step:  617 loss of agent  1 :  0.1992393583059311
episode:  14 training step:  617 loss of agent  2 :  0.10508512705564499
episode:  14 training step:  617 loss of agent  3 :  0.15176743268966675
episode:  14 training step:  618 loss of agent  0 :  0.07597163319587708
episode:  14 training step:  618 loss of agent  1 :  0.27589020133018494
episode:  14 training step:  618 loss of agent  2 :  0.12212268263101578
episode:  14 training step:  618 loss of agent  3 :  0.0855180099606514
episode:  14 training step:  619 loss of agent  0 :  0.0572156086564064
episode:  14 training step:  619 loss of agent  1 :  0.12895455956459045
episode:  14 training step:  619 loss of agent  2 :  0.19122004508972168
episode:  14 training step:  619 loss of agent  3 :  0.19739925861358643
episode:  14 training step:  620 loss of agent  0 :  0.059543825685977936
episode:  14 training step:  620 loss of agent  1 :  0.2836354672908783
episode:  14 training step:  620 loss of agent  2 :  0.1384458839893341
episode:  14 training step:  620 loss of agent  3 :  0.09472226351499557
Evaluation
env seed: 6 evaluation score at the training step:  620 :  {'adversary_0': -26.172766817007595, 'agent_0': 0.9463883025561242, 'agent_1': 0.9463883025561242, 'agent_2': 0.9463883025561242}
model saving.................................
episode:  14 training step:  621 loss of agent  0 :  0.08525358140468597
episode:  14 training step:  621 loss of agent  1 :  0.2609485983848572
episode:  14 training step:  621 loss of agent  2 :  0.12754356861114502
episode:  14 training step:  621 loss of agent  3 :  0.13313394784927368
episode 14 terminated at 750
episode: 15
epoch: 1
episode:  15 training step:  622 loss of agent  0 :  0.04399794340133667
episode:  15 training step:  622 loss of agent  1 :  0.1815507709980011
episode:  15 training step:  622 loss of agent  2 :  0.14165276288986206
episode:  15 training step:  622 loss of agent  3 :  0.13140447437763214
episode:  15 training step:  623 loss of agent  0 :  0.07658834010362625
episode:  15 training step:  623 loss of agent  1 :  0.20332080125808716
episode:  15 training step:  623 loss of agent  2 :  0.2388988733291626
episode:  15 training step:  623 loss of agent  3 :  0.1449328064918518
episode:  15 training step:  624 loss of agent  0 :  0.07367795705795288
episode:  15 training step:  624 loss of agent  1 :  0.3469257354736328
episode:  15 training step:  624 loss of agent  2 :  0.1414562314748764
episode:  15 training step:  624 loss of agent  3 :  0.16582909226417542
episode:  15 training step:  625 loss of agent  0 :  0.052563831210136414
episode:  15 training step:  625 loss of agent  1 :  0.2547365725040436
episode:  15 training step:  625 loss of agent  2 :  0.13860562443733215
episode:  15 training step:  625 loss of agent  3 :  0.1904333382844925
Evaluation
env seed: 6 evaluation score at the training step:  625 :  {'adversary_0': -23.973964671252247, 'agent_0': -1.4263716154741075, 'agent_1': -1.4263716154741075, 'agent_2': -1.4263716154741075}
episode:  15 training step:  626 loss of agent  0 :  0.03487161919474602
episode:  15 training step:  626 loss of agent  1 :  0.32056042551994324
episode:  15 training step:  626 loss of agent  2 :  0.0847625657916069
episode:  15 training step:  626 loss of agent  3 :  0.1942080855369568
episode:  15 training step:  627 loss of agent  0 :  0.04715503379702568
episode:  15 training step:  627 loss of agent  1 :  0.2881752550601959
episode:  15 training step:  627 loss of agent  2 :  0.14854469895362854
episode:  15 training step:  627 loss of agent  3 :  0.0886370986700058
episode:  15 training step:  628 loss of agent  0 :  0.046359993517398834
episode:  15 training step:  628 loss of agent  1 :  0.1652047336101532
episode:  15 training step:  628 loss of agent  2 :  0.13710905611515045
episode:  15 training step:  628 loss of agent  3 :  0.13727189600467682
episode:  15 training step:  629 loss of agent  0 :  0.06691643595695496
episode:  15 training step:  629 loss of agent  1 :  0.21199774742126465
episode:  15 training step:  629 loss of agent  2 :  0.14688339829444885
episode:  15 training step:  629 loss of agent  3 :  0.10504746437072754
episode:  15 training step:  630 loss of agent  0 :  0.04295172542333603
episode:  15 training step:  630 loss of agent  1 :  0.20237572491168976
episode:  15 training step:  630 loss of agent  2 :  0.25328272581100464
episode:  15 training step:  630 loss of agent  3 :  0.09990094602108002
Evaluation
env seed: 6 evaluation score at the training step:  630 :  {'adversary_0': -22.827515797015828, 'agent_0': -2.4094320698190326, 'agent_1': -2.4094320698190326, 'agent_2': -2.4094320698190326}
model saving.................................
episode:  15 training step:  631 loss of agent  0 :  0.06594999879598618
episode:  15 training step:  631 loss of agent  1 :  0.22994093596935272
episode:  15 training step:  631 loss of agent  2 :  0.12166775017976761
episode:  15 training step:  631 loss of agent  3 :  0.13609760999679565
episode:  15 training step:  632 loss of agent  0 :  0.08185398578643799
episode:  15 training step:  632 loss of agent  1 :  0.19632098078727722
episode:  15 training step:  632 loss of agent  2 :  0.1463223397731781
episode:  15 training step:  632 loss of agent  3 :  0.22843559086322784
episode:  15 training step:  633 loss of agent  0 :  0.08752332627773285
episode:  15 training step:  633 loss of agent  1 :  0.2505640983581543
episode:  15 training step:  633 loss of agent  2 :  0.19002659618854523
episode:  15 training step:  633 loss of agent  3 :  0.2809374928474426
episode:  15 training step:  634 loss of agent  0 :  0.05117015913128853
episode:  15 training step:  634 loss of agent  1 :  0.29346945881843567
episode:  15 training step:  634 loss of agent  2 :  0.15009507536888123
episode:  15 training step:  634 loss of agent  3 :  0.146994486451149
episode:  15 training step:  635 loss of agent  0 :  0.04594780132174492
episode:  15 training step:  635 loss of agent  1 :  0.15982216596603394
episode:  15 training step:  635 loss of agent  2 :  0.1458510458469391
episode:  15 training step:  635 loss of agent  3 :  0.10267799347639084
Evaluation
env seed: 6 evaluation score at the training step:  635 :  {'adversary_0': -25.167934232811376, 'agent_0': -1.6455247545859137, 'agent_1': -1.6455247545859137, 'agent_2': -1.6455247545859137}
episode:  15 training step:  636 loss of agent  0 :  0.1131720095872879
episode:  15 training step:  636 loss of agent  1 :  0.36019712686538696
episode:  15 training step:  636 loss of agent  2 :  0.17439807951450348
episode:  15 training step:  636 loss of agent  3 :  0.10169091820716858
episode:  15 training step:  637 loss of agent  0 :  0.07307881861925125
episode:  15 training step:  637 loss of agent  1 :  0.15264439582824707
episode:  15 training step:  637 loss of agent  2 :  0.11822900921106339
episode:  15 training step:  637 loss of agent  3 :  0.14765752851963043
episode:  15 training step:  638 loss of agent  0 :  0.06883060932159424
episode:  15 training step:  638 loss of agent  1 :  0.2504231631755829
episode:  15 training step:  638 loss of agent  2 :  0.1551963984966278
episode:  15 training step:  638 loss of agent  3 :  0.13324615359306335
episode:  15 training step:  639 loss of agent  0 :  0.09631088376045227
episode:  15 training step:  639 loss of agent  1 :  0.20521017909049988
episode:  15 training step:  639 loss of agent  2 :  0.15872332453727722
episode:  15 training step:  639 loss of agent  3 :  0.13706514239311218
episode:  15 training step:  640 loss of agent  0 :  0.045457515865564346
episode:  15 training step:  640 loss of agent  1 :  0.1628868281841278
episode:  15 training step:  640 loss of agent  2 :  0.19666153192520142
episode:  15 training step:  640 loss of agent  3 :  0.22245976328849792
Evaluation
env seed: 6 evaluation score at the training step:  640 :  {'adversary_0': -50.447573351276276, 'agent_0': 16.84508426657207, 'agent_1': 16.84508426657207, 'agent_2': 16.84508426657207}
model saving.................................
episode:  15 training step:  641 loss of agent  0 :  0.0428721122443676
episode:  15 training step:  641 loss of agent  1 :  0.24716129899024963
episode:  15 training step:  641 loss of agent  2 :  0.1543765664100647
episode:  15 training step:  641 loss of agent  3 :  0.1587819904088974
episode:  15 training step:  642 loss of agent  0 :  0.0997127890586853
episode:  15 training step:  642 loss of agent  1 :  0.259663462638855
episode:  15 training step:  642 loss of agent  2 :  0.1714029461145401
episode:  15 training step:  642 loss of agent  3 :  0.12078875303268433
episode:  15 training step:  643 loss of agent  0 :  0.08166268467903137
episode:  15 training step:  643 loss of agent  1 :  0.29722440242767334
episode:  15 training step:  643 loss of agent  2 :  0.1399136781692505
episode:  15 training step:  643 loss of agent  3 :  0.13046155869960785
episode:  15 training step:  644 loss of agent  0 :  0.04932260513305664
episode:  15 training step:  644 loss of agent  1 :  0.290439635515213
episode:  15 training step:  644 loss of agent  2 :  0.16363246738910675
episode:  15 training step:  644 loss of agent  3 :  0.13087572157382965
episode:  15 training step:  645 loss of agent  0 :  0.1174178421497345
episode:  15 training step:  645 loss of agent  1 :  0.23972631990909576
episode:  15 training step:  645 loss of agent  2 :  0.15485121309757233
episode:  15 training step:  645 loss of agent  3 :  0.22881227731704712
Evaluation
env seed: 6 evaluation score at the training step:  645 :  {'adversary_0': -54.59325117595874, 'agent_0': 34.83359818033597, 'agent_1': 34.83359818033597, 'agent_2': 34.83359818033597}
episode 15 terminated at 775
epoch: 2
episode:  15 training step:  646 loss of agent  0 :  0.055892106145620346
episode:  15 training step:  646 loss of agent  1 :  0.18768981099128723
episode:  15 training step:  646 loss of agent  2 :  0.15177646279335022
episode:  15 training step:  646 loss of agent  3 :  0.20413586497306824
episode:  15 training step:  647 loss of agent  0 :  0.075113445520401
episode:  15 training step:  647 loss of agent  1 :  0.4397594928741455
episode:  15 training step:  647 loss of agent  2 :  0.14086341857910156
episode:  15 training step:  647 loss of agent  3 :  0.184434711933136
episode:  15 training step:  648 loss of agent  0 :  0.07950981706380844
episode:  15 training step:  648 loss of agent  1 :  0.2548048496246338
episode:  15 training step:  648 loss of agent  2 :  0.23762117326259613
episode:  15 training step:  648 loss of agent  3 :  0.19053035974502563
episode:  15 training step:  649 loss of agent  0 :  0.07191845774650574
episode:  15 training step:  649 loss of agent  1 :  0.28049492835998535
episode:  15 training step:  649 loss of agent  2 :  0.12258389592170715
episode:  15 training step:  649 loss of agent  3 :  0.1444401890039444
episode:  15 training step:  650 loss of agent  0 :  0.04786519333720207
episode:  15 training step:  650 loss of agent  1 :  0.2281387597322464
episode:  15 training step:  650 loss of agent  2 :  0.13711033761501312
episode:  15 training step:  650 loss of agent  3 :  0.1452166885137558
Evaluation
env seed: 6 evaluation score at the training step:  650 :  {'adversary_0': -24.320078560287307, 'agent_0': -5.904797113304516, 'agent_1': -5.904797113304516, 'agent_2': -5.904797113304516}
model saving.................................
episode:  15 training step:  651 loss of agent  0 :  0.0395740270614624
episode:  15 training step:  651 loss of agent  1 :  0.23587848246097565
episode:  15 training step:  651 loss of agent  2 :  0.1473938524723053
episode:  15 training step:  651 loss of agent  3 :  0.22612455487251282
episode:  15 training step:  652 loss of agent  0 :  0.07034362107515335
episode:  15 training step:  652 loss of agent  1 :  0.23924708366394043
episode:  15 training step:  652 loss of agent  2 :  0.19673600792884827
episode:  15 training step:  652 loss of agent  3 :  0.0859098806977272
episode:  15 training step:  653 loss of agent  0 :  0.04342084378004074
episode:  15 training step:  653 loss of agent  1 :  0.22135961055755615
episode:  15 training step:  653 loss of agent  2 :  0.06356648355722427
episode:  15 training step:  653 loss of agent  3 :  0.12657390534877777
episode:  15 training step:  654 loss of agent  0 :  0.0412420779466629
episode:  15 training step:  654 loss of agent  1 :  0.1245347410440445
episode:  15 training step:  654 loss of agent  2 :  0.13769008219242096
episode:  15 training step:  654 loss of agent  3 :  0.15073470771312714
episode:  15 training step:  655 loss of agent  0 :  0.06074133887887001
episode:  15 training step:  655 loss of agent  1 :  0.31972798705101013
episode:  15 training step:  655 loss of agent  2 :  0.15028516948223114
episode:  15 training step:  655 loss of agent  3 :  0.185353085398674
Evaluation
env seed: 6 evaluation score at the training step:  655 :  {'adversary_0': -27.602256716445147, 'agent_0': -2.391780347079487, 'agent_1': -2.391780347079487, 'agent_2': -2.391780347079487}
episode:  15 training step:  656 loss of agent  0 :  0.06735260039567947
episode:  15 training step:  656 loss of agent  1 :  0.21222370862960815
episode:  15 training step:  656 loss of agent  2 :  0.07343553751707077
episode:  15 training step:  656 loss of agent  3 :  0.10085947811603546
episode:  15 training step:  657 loss of agent  0 :  0.0422816202044487
episode:  15 training step:  657 loss of agent  1 :  0.3354331851005554
episode:  15 training step:  657 loss of agent  2 :  0.19978086650371552
episode:  15 training step:  657 loss of agent  3 :  0.12874256074428558
episode:  15 training step:  658 loss of agent  0 :  0.04292447119951248
episode:  15 training step:  658 loss of agent  1 :  0.19516150653362274
episode:  15 training step:  658 loss of agent  2 :  0.1585579514503479
episode:  15 training step:  658 loss of agent  3 :  0.13763414323329926
episode:  15 training step:  659 loss of agent  0 :  0.04351135343313217
episode:  15 training step:  659 loss of agent  1 :  0.3081754148006439
episode:  15 training step:  659 loss of agent  2 :  0.15537673234939575
episode:  15 training step:  659 loss of agent  3 :  0.14403554797172546
episode:  15 training step:  660 loss of agent  0 :  0.08722618967294693
episode:  15 training step:  660 loss of agent  1 :  0.29773324728012085
episode:  15 training step:  660 loss of agent  2 :  0.12864525616168976
episode:  15 training step:  660 loss of agent  3 :  0.08005256205797195
Evaluation
env seed: 6 evaluation score at the training step:  660 :  {'adversary_0': -29.425214088090932, 'agent_0': -0.8742737934539058, 'agent_1': -0.8742737934539058, 'agent_2': -0.8742737934539058}
model saving.................................
episode:  15 training step:  661 loss of agent  0 :  0.0531323216855526
episode:  15 training step:  661 loss of agent  1 :  0.13280415534973145
episode:  15 training step:  661 loss of agent  2 :  0.14797642827033997
episode:  15 training step:  661 loss of agent  3 :  0.1405121386051178
episode:  15 training step:  662 loss of agent  0 :  0.03940314054489136
episode:  15 training step:  662 loss of agent  1 :  0.11156246066093445
episode:  15 training step:  662 loss of agent  2 :  0.15836475789546967
episode:  15 training step:  662 loss of agent  3 :  0.10170652717351913
episode:  15 training step:  663 loss of agent  0 :  0.05795757845044136
episode:  15 training step:  663 loss of agent  1 :  0.31543415784835815
episode:  15 training step:  663 loss of agent  2 :  0.14269497990608215
episode:  15 training step:  663 loss of agent  3 :  0.1316477656364441
episode:  15 training step:  664 loss of agent  0 :  0.08332479000091553
episode:  15 training step:  664 loss of agent  1 :  0.2250930815935135
episode:  15 training step:  664 loss of agent  2 :  0.09760331362485886
episode:  15 training step:  664 loss of agent  3 :  0.21433041989803314
episode:  15 training step:  665 loss of agent  0 :  0.06857017427682877
episode:  15 training step:  665 loss of agent  1 :  0.3238057494163513
episode:  15 training step:  665 loss of agent  2 :  0.1415940672159195
episode:  15 training step:  665 loss of agent  3 :  0.18586008250713348
Evaluation
env seed: 6 evaluation score at the training step:  665 :  {'adversary_0': -23.747578336434017, 'agent_0': -6.501838633682661, 'agent_1': -6.501838633682661, 'agent_2': -6.501838633682661}
episode:  15 training step:  666 loss of agent  0 :  0.09007945656776428
episode:  15 training step:  666 loss of agent  1 :  0.2655123472213745
episode:  15 training step:  666 loss of agent  2 :  0.11654552817344666
episode:  15 training step:  666 loss of agent  3 :  0.16271904110908508
episode:  15 training step:  667 loss of agent  0 :  0.06425462663173676
episode:  15 training step:  667 loss of agent  1 :  0.23357358574867249
episode:  15 training step:  667 loss of agent  2 :  0.2273423969745636
episode:  15 training step:  667 loss of agent  3 :  0.22993353009223938
episode:  15 training step:  668 loss of agent  0 :  0.05689670890569687
episode:  15 training step:  668 loss of agent  1 :  0.22683781385421753
episode:  15 training step:  668 loss of agent  2 :  0.19436314702033997
episode:  15 training step:  668 loss of agent  3 :  0.18459855020046234
episode:  15 training step:  669 loss of agent  0 :  0.05527199059724808
episode:  15 training step:  669 loss of agent  1 :  0.3255532383918762
episode:  15 training step:  669 loss of agent  2 :  0.22320827841758728
episode:  15 training step:  669 loss of agent  3 :  0.10162968188524246
episode 15 terminated at 800
episode: 16
epoch: 1
episode:  16 training step:  670 loss of agent  0 :  0.1591871678829193
episode:  16 training step:  670 loss of agent  1 :  0.2316056191921234
episode:  16 training step:  670 loss of agent  2 :  0.25859305262565613
episode:  16 training step:  670 loss of agent  3 :  0.0930996686220169
Evaluation
env seed: 6 evaluation score at the training step:  670 :  {'adversary_0': -25.964563751611376, 'agent_0': -3.684279409301884, 'agent_1': -3.684279409301884, 'agent_2': -3.684279409301884}
model saving.................................
episode:  16 training step:  671 loss of agent  0 :  0.11145593971014023
episode:  16 training step:  671 loss of agent  1 :  0.3027167022228241
episode:  16 training step:  671 loss of agent  2 :  0.18732430040836334
episode:  16 training step:  671 loss of agent  3 :  0.19376492500305176
episode:  16 training step:  672 loss of agent  0 :  0.0943419337272644
episode:  16 training step:  672 loss of agent  1 :  0.2580876648426056
episode:  16 training step:  672 loss of agent  2 :  0.1672811061143875
episode:  16 training step:  672 loss of agent  3 :  0.2609297037124634
episode:  16 training step:  673 loss of agent  0 :  0.08428168296813965
episode:  16 training step:  673 loss of agent  1 :  0.3313443660736084
episode:  16 training step:  673 loss of agent  2 :  0.15083588659763336
episode:  16 training step:  673 loss of agent  3 :  0.15892361104488373
episode:  16 training step:  674 loss of agent  0 :  0.06569299846887589
episode:  16 training step:  674 loss of agent  1 :  0.21387022733688354
episode:  16 training step:  674 loss of agent  2 :  0.14764972031116486
episode:  16 training step:  674 loss of agent  3 :  0.11355788260698318
episode:  16 training step:  675 loss of agent  0 :  0.05613628402352333
episode:  16 training step:  675 loss of agent  1 :  0.19418436288833618
episode:  16 training step:  675 loss of agent  2 :  0.15227019786834717
episode:  16 training step:  675 loss of agent  3 :  0.16398875415325165
Evaluation
env seed: 6 evaluation score at the training step:  675 :  {'adversary_0': -26.62289206861495, 'agent_0': -6.843282962205302, 'agent_1': -6.843282962205302, 'agent_2': -6.843282962205302}
episode:  16 training step:  676 loss of agent  0 :  0.08301432430744171
episode:  16 training step:  676 loss of agent  1 :  0.3631245493888855
episode:  16 training step:  676 loss of agent  2 :  0.14494499564170837
episode:  16 training step:  676 loss of agent  3 :  0.1409783959388733
episode:  16 training step:  677 loss of agent  0 :  0.07271738350391388
episode:  16 training step:  677 loss of agent  1 :  0.20041465759277344
episode:  16 training step:  677 loss of agent  2 :  0.09263181686401367
episode:  16 training step:  677 loss of agent  3 :  0.14139890670776367
episode:  16 training step:  678 loss of agent  0 :  0.0978093296289444
episode:  16 training step:  678 loss of agent  1 :  0.14656919240951538
episode:  16 training step:  678 loss of agent  2 :  0.1750144064426422
episode:  16 training step:  678 loss of agent  3 :  0.1696719527244568
episode:  16 training step:  679 loss of agent  0 :  0.05379109084606171
episode:  16 training step:  679 loss of agent  1 :  0.26224300265312195
episode:  16 training step:  679 loss of agent  2 :  0.12452645599842072
episode:  16 training step:  679 loss of agent  3 :  0.11506406962871552
episode:  16 training step:  680 loss of agent  0 :  0.043590836226940155
episode:  16 training step:  680 loss of agent  1 :  0.3200700283050537
episode:  16 training step:  680 loss of agent  2 :  0.09168388694524765
episode:  16 training step:  680 loss of agent  3 :  0.18586407601833344
Evaluation
env seed: 6 evaluation score at the training step:  680 :  {'adversary_0': -25.83686006625602, 'agent_0': -6.9943432073564225, 'agent_1': -6.9943432073564225, 'agent_2': -6.9943432073564225}
model saving.................................
episode:  16 training step:  681 loss of agent  0 :  0.07254061102867126
episode:  16 training step:  681 loss of agent  1 :  0.23787301778793335
episode:  16 training step:  681 loss of agent  2 :  0.14987753331661224
episode:  16 training step:  681 loss of agent  3 :  0.1762557029724121
episode:  16 training step:  682 loss of agent  0 :  0.05355188250541687
episode:  16 training step:  682 loss of agent  1 :  0.2551785409450531
episode:  16 training step:  682 loss of agent  2 :  0.160226970911026
episode:  16 training step:  682 loss of agent  3 :  0.17351138591766357
episode:  16 training step:  683 loss of agent  0 :  0.1350347101688385
episode:  16 training step:  683 loss of agent  1 :  0.31995078921318054
episode:  16 training step:  683 loss of agent  2 :  0.08597993850708008
episode:  16 training step:  683 loss of agent  3 :  0.10412413626909256
episode:  16 training step:  684 loss of agent  0 :  0.09769774973392487
episode:  16 training step:  684 loss of agent  1 :  0.23829032480716705
episode:  16 training step:  684 loss of agent  2 :  0.21003161370754242
episode:  16 training step:  684 loss of agent  3 :  0.19402697682380676
episode:  16 training step:  685 loss of agent  0 :  0.040631163865327835
episode:  16 training step:  685 loss of agent  1 :  0.2849577069282532
episode:  16 training step:  685 loss of agent  2 :  0.1792704463005066
episode:  16 training step:  685 loss of agent  3 :  0.2295430302619934
Evaluation
env seed: 6 evaluation score at the training step:  685 :  {'adversary_0': -21.771285321489223, 'agent_0': -0.7951130814757467, 'agent_1': -0.7951130814757467, 'agent_2': -0.7951130814757467}
episode:  16 training step:  686 loss of agent  0 :  0.11114289611577988
episode:  16 training step:  686 loss of agent  1 :  0.09998802840709686
episode:  16 training step:  686 loss of agent  2 :  0.19264596700668335
episode:  16 training step:  686 loss of agent  3 :  0.16156290471553802
episode:  16 training step:  687 loss of agent  0 :  0.07164815813302994
episode:  16 training step:  687 loss of agent  1 :  0.22495277225971222
episode:  16 training step:  687 loss of agent  2 :  0.15885622799396515
episode:  16 training step:  687 loss of agent  3 :  0.16405507922172546
episode:  16 training step:  688 loss of agent  0 :  0.058760933578014374
episode:  16 training step:  688 loss of agent  1 :  0.30512115359306335
episode:  16 training step:  688 loss of agent  2 :  0.14013230800628662
episode:  16 training step:  688 loss of agent  3 :  0.1683187633752823
episode:  16 training step:  689 loss of agent  0 :  0.04450268670916557
episode:  16 training step:  689 loss of agent  1 :  0.18171577155590057
episode:  16 training step:  689 loss of agent  2 :  0.1731872260570526
episode:  16 training step:  689 loss of agent  3 :  0.13464874029159546
episode:  16 training step:  690 loss of agent  0 :  0.044742751866579056
episode:  16 training step:  690 loss of agent  1 :  0.19492799043655396
episode:  16 training step:  690 loss of agent  2 :  0.2578221559524536
episode:  16 training step:  690 loss of agent  3 :  0.2013101428747177
Evaluation
env seed: 6 evaluation score at the training step:  690 :  {'adversary_0': -60.455816251736415, 'agent_0': 40.55891584563106, 'agent_1': 40.55891584563106, 'agent_2': 40.55891584563106}
model saving.................................
episode:  16 training step:  691 loss of agent  0 :  0.05905057489871979
episode:  16 training step:  691 loss of agent  1 :  0.29648852348327637
episode:  16 training step:  691 loss of agent  2 :  0.1542195826768875
episode:  16 training step:  691 loss of agent  3 :  0.17608053982257843
episode:  16 training step:  692 loss of agent  0 :  0.06684465706348419
episode:  16 training step:  692 loss of agent  1 :  0.2649048864841461
episode:  16 training step:  692 loss of agent  2 :  0.1307358741760254
episode:  16 training step:  692 loss of agent  3 :  0.14436495304107666
episode:  16 training step:  693 loss of agent  0 :  0.037502966821193695
episode:  16 training step:  693 loss of agent  1 :  0.22240938246250153
episode:  16 training step:  693 loss of agent  2 :  0.18124592304229736
episode:  16 training step:  693 loss of agent  3 :  0.11358460783958435
episode 16 terminated at 825
epoch: 2
episode:  16 training step:  694 loss of agent  0 :  0.08847060799598694
episode:  16 training step:  694 loss of agent  1 :  0.3325966000556946
episode:  16 training step:  694 loss of agent  2 :  0.11862826347351074
episode:  16 training step:  694 loss of agent  3 :  0.1366281658411026
episode:  16 training step:  695 loss of agent  0 :  0.06896646320819855
episode:  16 training step:  695 loss of agent  1 :  0.3907190263271332
episode:  16 training step:  695 loss of agent  2 :  0.19446778297424316
episode:  16 training step:  695 loss of agent  3 :  0.11849623918533325
Evaluation
env seed: 6 evaluation score at the training step:  695 :  {'adversary_0': -60.40751200047714, 'agent_0': 30.18910877783722, 'agent_1': 30.18910877783722, 'agent_2': 30.18910877783722}
episode:  16 training step:  696 loss of agent  0 :  0.054765041917562485
episode:  16 training step:  696 loss of agent  1 :  0.20963813364505768
episode:  16 training step:  696 loss of agent  2 :  0.16063746809959412
episode:  16 training step:  696 loss of agent  3 :  0.20360037684440613
episode:  16 training step:  697 loss of agent  0 :  0.04101962596178055
episode:  16 training step:  697 loss of agent  1 :  0.24225454032421112
episode:  16 training step:  697 loss of agent  2 :  0.14993353188037872
episode:  16 training step:  697 loss of agent  3 :  0.1445823609828949
episode:  16 training step:  698 loss of agent  0 :  0.04612492769956589
episode:  16 training step:  698 loss of agent  1 :  0.19558992981910706
episode:  16 training step:  698 loss of agent  2 :  0.16479846835136414
episode:  16 training step:  698 loss of agent  3 :  0.09828650951385498
episode:  16 training step:  699 loss of agent  0 :  0.08362835645675659
episode:  16 training step:  699 loss of agent  1 :  0.26141825318336487
episode:  16 training step:  699 loss of agent  2 :  0.18079474568367004
episode:  16 training step:  699 loss of agent  3 :  0.15915700793266296
episode:  16 training step:  700 loss of agent  0 :  0.058305561542510986
episode:  16 training step:  700 loss of agent  1 :  0.2662760615348816
episode:  16 training step:  700 loss of agent  2 :  0.15940114855766296
episode:  16 training step:  700 loss of agent  3 :  0.2447841316461563
Evaluation
env seed: 6 evaluation score at the training step:  700 :  {'adversary_0': -61.634630899630295, 'agent_0': 17.874524489409982, 'agent_1': 17.874524489409982, 'agent_2': 17.874524489409982}
model saving.................................
episode:  16 training step:  701 loss of agent  0 :  0.05457596480846405
episode:  16 training step:  701 loss of agent  1 :  0.28018900752067566
episode:  16 training step:  701 loss of agent  2 :  0.16945089399814606
episode:  16 training step:  701 loss of agent  3 :  0.13342483341693878
episode:  16 training step:  702 loss of agent  0 :  0.06048031896352768
episode:  16 training step:  702 loss of agent  1 :  0.19085784256458282
episode:  16 training step:  702 loss of agent  2 :  0.28330978751182556
episode:  16 training step:  702 loss of agent  3 :  0.1485595852136612
episode:  16 training step:  703 loss of agent  0 :  0.04382171109318733
episode:  16 training step:  703 loss of agent  1 :  0.3111332952976227
episode:  16 training step:  703 loss of agent  2 :  0.23718208074569702
episode:  16 training step:  703 loss of agent  3 :  0.09770467877388
episode:  16 training step:  704 loss of agent  0 :  0.048927273601293564
episode:  16 training step:  704 loss of agent  1 :  0.14510993659496307
episode:  16 training step:  704 loss of agent  2 :  0.16530732810497284
episode:  16 training step:  704 loss of agent  3 :  0.14501014351844788
episode:  16 training step:  705 loss of agent  0 :  0.054976239800453186
episode:  16 training step:  705 loss of agent  1 :  0.17299731075763702
episode:  16 training step:  705 loss of agent  2 :  0.10512980073690414
episode:  16 training step:  705 loss of agent  3 :  0.12235786765813828
Evaluation
env seed: 6 evaluation score at the training step:  705 :  {'adversary_0': -22.745989700874624, 'agent_0': -7.441780020476666, 'agent_1': -7.441780020476666, 'agent_2': -7.441780020476666}
episode:  16 training step:  706 loss of agent  0 :  0.04759592190384865
episode:  16 training step:  706 loss of agent  1 :  0.17124925553798676
episode:  16 training step:  706 loss of agent  2 :  0.11309967935085297
episode:  16 training step:  706 loss of agent  3 :  0.16062641143798828
episode:  16 training step:  707 loss of agent  0 :  0.03812771290540695
episode:  16 training step:  707 loss of agent  1 :  0.19127121567726135
episode:  16 training step:  707 loss of agent  2 :  0.11261510103940964
episode:  16 training step:  707 loss of agent  3 :  0.1699923276901245
episode:  16 training step:  708 loss of agent  0 :  0.05930013954639435
episode:  16 training step:  708 loss of agent  1 :  0.31107887625694275
episode:  16 training step:  708 loss of agent  2 :  0.2094200998544693
episode:  16 training step:  708 loss of agent  3 :  0.16914574801921844
episode:  16 training step:  709 loss of agent  0 :  0.12539291381835938
episode:  16 training step:  709 loss of agent  1 :  0.3169257342815399
episode:  16 training step:  709 loss of agent  2 :  0.1990300416946411
episode:  16 training step:  709 loss of agent  3 :  0.13304460048675537
episode:  16 training step:  710 loss of agent  0 :  0.05443316698074341
episode:  16 training step:  710 loss of agent  1 :  0.18087920546531677
episode:  16 training step:  710 loss of agent  2 :  0.2027241289615631
episode:  16 training step:  710 loss of agent  3 :  0.13478133082389832
Evaluation
env seed: 6 evaluation score at the training step:  710 :  {'adversary_0': -23.196327091250772, 'agent_0': -6.483473594893779, 'agent_1': -6.483473594893779, 'agent_2': -6.483473594893779}
model saving.................................
episode:  16 training step:  711 loss of agent  0 :  0.06427877396345139
episode:  16 training step:  711 loss of agent  1 :  0.1959996372461319
episode:  16 training step:  711 loss of agent  2 :  0.1476191282272339
episode:  16 training step:  711 loss of agent  3 :  0.13899655640125275
episode:  16 training step:  712 loss of agent  0 :  0.051845233887434006
episode:  16 training step:  712 loss of agent  1 :  0.21950966119766235
episode:  16 training step:  712 loss of agent  2 :  0.24020777642726898
episode:  16 training step:  712 loss of agent  3 :  0.2988717555999756
episode:  16 training step:  713 loss of agent  0 :  0.05430197715759277
episode:  16 training step:  713 loss of agent  1 :  0.18166735768318176
episode:  16 training step:  713 loss of agent  2 :  0.1395988017320633
episode:  16 training step:  713 loss of agent  3 :  0.1522846668958664
episode:  16 training step:  714 loss of agent  0 :  0.05198182165622711
episode:  16 training step:  714 loss of agent  1 :  0.2530781030654907
episode:  16 training step:  714 loss of agent  2 :  0.13484805822372437
episode:  16 training step:  714 loss of agent  3 :  0.36599981784820557
episode:  16 training step:  715 loss of agent  0 :  0.034961480647325516
episode:  16 training step:  715 loss of agent  1 :  0.23231764137744904
episode:  16 training step:  715 loss of agent  2 :  0.2090611755847931
episode:  16 training step:  715 loss of agent  3 :  0.14859619736671448
Evaluation
env seed: 6 evaluation score at the training step:  715 :  {'adversary_0': -24.018002197482737, 'agent_0': -6.093973981531958, 'agent_1': -6.093973981531958, 'agent_2': -6.093973981531958}
episode:  16 training step:  716 loss of agent  0 :  0.03561758995056152
episode:  16 training step:  716 loss of agent  1 :  0.29538729786872864
episode:  16 training step:  716 loss of agent  2 :  0.12250968813896179
episode:  16 training step:  716 loss of agent  3 :  0.2111843228340149
episode:  16 training step:  717 loss of agent  0 :  0.049116913229227066
episode:  16 training step:  717 loss of agent  1 :  0.2911166846752167
episode:  16 training step:  717 loss of agent  2 :  0.24759545922279358
episode:  16 training step:  717 loss of agent  3 :  0.2584264576435089
episode 16 terminated at 850
episode: 17
epoch: 1
episode:  17 training step:  718 loss of agent  0 :  0.04621388018131256
episode:  17 training step:  718 loss of agent  1 :  0.2433444857597351
episode:  17 training step:  718 loss of agent  2 :  0.18837350606918335
episode:  17 training step:  718 loss of agent  3 :  0.13958339393138885
episode:  17 training step:  719 loss of agent  0 :  0.04486940801143646
episode:  17 training step:  719 loss of agent  1 :  0.3727080225944519
episode:  17 training step:  719 loss of agent  2 :  0.13844242691993713
episode:  17 training step:  719 loss of agent  3 :  0.14115802943706512
episode:  17 training step:  720 loss of agent  0 :  0.03990325331687927
episode:  17 training step:  720 loss of agent  1 :  0.2806437015533447
episode:  17 training step:  720 loss of agent  2 :  0.21024350821971893
episode:  17 training step:  720 loss of agent  3 :  0.1698542982339859
Evaluation
env seed: 6 evaluation score at the training step:  720 :  {'adversary_0': -25.670218147927862, 'agent_0': -4.092610671090513, 'agent_1': -4.092610671090513, 'agent_2': -4.092610671090513}
model saving.................................
episode:  17 training step:  721 loss of agent  0 :  0.08020014315843582
episode:  17 training step:  721 loss of agent  1 :  0.2485133707523346
episode:  17 training step:  721 loss of agent  2 :  0.1698620468378067
episode:  17 training step:  721 loss of agent  3 :  0.17171335220336914
episode:  17 training step:  722 loss of agent  0 :  0.053400129079818726
episode:  17 training step:  722 loss of agent  1 :  0.1982993632555008
episode:  17 training step:  722 loss of agent  2 :  0.12411873787641525
episode:  17 training step:  722 loss of agent  3 :  0.18811026215553284
episode:  17 training step:  723 loss of agent  0 :  0.05229201167821884
episode:  17 training step:  723 loss of agent  1 :  0.3463779091835022
episode:  17 training step:  723 loss of agent  2 :  0.17814914882183075
episode:  17 training step:  723 loss of agent  3 :  0.18405210971832275
episode:  17 training step:  724 loss of agent  0 :  0.05739615112543106
episode:  17 training step:  724 loss of agent  1 :  0.2284940928220749
episode:  17 training step:  724 loss of agent  2 :  0.2093450427055359
episode:  17 training step:  724 loss of agent  3 :  0.17432034015655518
episode:  17 training step:  725 loss of agent  0 :  0.04871872067451477
episode:  17 training step:  725 loss of agent  1 :  0.2282169908285141
episode:  17 training step:  725 loss of agent  2 :  0.13743989169597626
episode:  17 training step:  725 loss of agent  3 :  0.19649429619312286
Evaluation
env seed: 6 evaluation score at the training step:  725 :  {'adversary_0': -27.520350271682247, 'agent_0': -2.228918557279143, 'agent_1': -2.228918557279143, 'agent_2': -2.228918557279143}
episode:  17 training step:  726 loss of agent  0 :  0.047213584184646606
episode:  17 training step:  726 loss of agent  1 :  0.27656108140945435
episode:  17 training step:  726 loss of agent  2 :  0.10659651458263397
episode:  17 training step:  726 loss of agent  3 :  0.17389105260372162
episode:  17 training step:  727 loss of agent  0 :  0.07944092899560928
episode:  17 training step:  727 loss of agent  1 :  0.3158203065395355
episode:  17 training step:  727 loss of agent  2 :  0.19975653290748596
episode:  17 training step:  727 loss of agent  3 :  0.14187107980251312
episode:  17 training step:  728 loss of agent  0 :  0.06749595701694489
episode:  17 training step:  728 loss of agent  1 :  0.147046759724617
episode:  17 training step:  728 loss of agent  2 :  0.18646621704101562
episode:  17 training step:  728 loss of agent  3 :  0.14127449691295624
episode:  17 training step:  729 loss of agent  0 :  0.05719121918082237
episode:  17 training step:  729 loss of agent  1 :  0.2734357416629791
episode:  17 training step:  729 loss of agent  2 :  0.21308350563049316
episode:  17 training step:  729 loss of agent  3 :  0.1338689923286438
episode:  17 training step:  730 loss of agent  0 :  0.07150248438119888
episode:  17 training step:  730 loss of agent  1 :  0.3798733055591583
episode:  17 training step:  730 loss of agent  2 :  0.22079597413539886
episode:  17 training step:  730 loss of agent  3 :  0.17672713100910187
Evaluation
env seed: 6 evaluation score at the training step:  730 :  {'adversary_0': -42.66488715451019, 'agent_0': 12.475423614555837, 'agent_1': 12.475423614555837, 'agent_2': 12.475423614555837}
model saving.................................
episode:  17 training step:  731 loss of agent  0 :  0.06010320782661438
episode:  17 training step:  731 loss of agent  1 :  0.28975608944892883
episode:  17 training step:  731 loss of agent  2 :  0.23069390654563904
episode:  17 training step:  731 loss of agent  3 :  0.10126414149999619
episode:  17 training step:  732 loss of agent  0 :  0.04230165481567383
episode:  17 training step:  732 loss of agent  1 :  0.29350152611732483
episode:  17 training step:  732 loss of agent  2 :  0.288738489151001
episode:  17 training step:  732 loss of agent  3 :  0.16260328888893127
episode:  17 training step:  733 loss of agent  0 :  0.09449288249015808
episode:  17 training step:  733 loss of agent  1 :  0.2847367227077484
episode:  17 training step:  733 loss of agent  2 :  0.23820860683918
episode:  17 training step:  733 loss of agent  3 :  0.10868914425373077
episode:  17 training step:  734 loss of agent  0 :  0.07268783450126648
episode:  17 training step:  734 loss of agent  1 :  0.21689307689666748
episode:  17 training step:  734 loss of agent  2 :  0.17510132491588593
episode:  17 training step:  734 loss of agent  3 :  0.0726991817355156
episode:  17 training step:  735 loss of agent  0 :  0.04778195917606354
episode:  17 training step:  735 loss of agent  1 :  0.23398838937282562
episode:  17 training step:  735 loss of agent  2 :  0.15672767162322998
episode:  17 training step:  735 loss of agent  3 :  0.16842558979988098
Evaluation
env seed: 6 evaluation score at the training step:  735 :  {'adversary_0': -41.115325267780435, 'agent_0': 11.09056146856327, 'agent_1': 11.09056146856327, 'agent_2': 11.09056146856327}
episode:  17 training step:  736 loss of agent  0 :  0.05077332258224487
episode:  17 training step:  736 loss of agent  1 :  0.25912824273109436
episode:  17 training step:  736 loss of agent  2 :  0.15265408158302307
episode:  17 training step:  736 loss of agent  3 :  0.13025760650634766
episode:  17 training step:  737 loss of agent  0 :  0.06386060267686844
episode:  17 training step:  737 loss of agent  1 :  0.2390548437833786
episode:  17 training step:  737 loss of agent  2 :  0.2132071852684021
episode:  17 training step:  737 loss of agent  3 :  0.16737614572048187
episode:  17 training step:  738 loss of agent  0 :  0.07762804627418518
episode:  17 training step:  738 loss of agent  1 :  0.45267149806022644
episode:  17 training step:  738 loss of agent  2 :  0.14596877992153168
episode:  17 training step:  738 loss of agent  3 :  0.21203039586544037
episode:  17 training step:  739 loss of agent  0 :  0.04766744375228882
episode:  17 training step:  739 loss of agent  1 :  0.25909653306007385
episode:  17 training step:  739 loss of agent  2 :  0.15954266488552094
episode:  17 training step:  740 loss of agent  2 :  0.21021679043769836
episode:  17 training step:  740 loss of agent  3 :  0.17944814264774323
Evaluation
env seed: 6 evaluation score at the training step:  740 :  {'adversary_0': -41.05867531482024, 'agent_0': 10.921774689492084, 'agent_1': 10.921774689492084, 'agent_2': 10.921774689492084}
model saving.................................
episode:  17 training step:  741 loss of agent  0 :  0.05034245178103447
episode:  17 training step:  741 loss of agent  1 :  0.282485693693161
episode:  17 training step:  741 loss of agent  2 :  0.14619117975234985
episode:  17 training step:  741 loss of agent  3 :  0.18707361817359924
episode 17 terminated at 875
epoch: 2
episode:  17 training step:  742 loss of agent  0 :  0.07895294576883316
episode:  17 training step:  742 loss of agent  1 :  0.31579914689064026
episode:  17 training step:  742 loss of agent  2 :  0.15264445543289185
episode:  17 training step:  742 loss of agent  3 :  0.16124580800533295
episode:  17 training step:  743 loss of agent  0 :  0.04425779730081558
episode:  17 training step:  743 loss of agent  1 :  0.2632187008857727
episode:  17 training step:  743 loss of agent  2 :  0.20301663875579834
episode:  17 training step:  743 loss of agent  3 :  0.18447142839431763
episode:  17 training step:  744 loss of agent  0 :  0.06134561821818352
episode:  17 training step:  744 loss of agent  1 :  0.3167061507701874
episode:  17 training step:  744 loss of agent  2 :  0.15967175364494324
episode:  17 training step:  744 loss of agent  3 :  0.22768859565258026
episode:  17 training step:  745 loss of agent  0 :  0.038639333099126816
episode:  17 training step:  745 loss of agent  1 :  0.2764910161495209
episode:  17 training step:  745 loss of agent  2 :  0.19705981016159058
episode:  17 training step:  745 loss of agent  3 :  0.13003545999526978
Evaluation
env seed: 6 evaluation score at the training step:  745 :  {'adversary_0': -31.334258095737926, 'agent_0': 1.2217187309449413, 'agent_1': 1.2217187309449413, 'agent_2': 1.2217187309449413}
episode:  17 training step:  746 loss of agent  0 :  0.03310365974903107
episode:  17 training step:  746 loss of agent  1 :  0.28734615445137024
episode:  17 training step:  746 loss of agent  2 :  0.20048287510871887
episode:  17 training step:  746 loss of agent  3 :  0.1837148219347
episode:  17 training step:  747 loss of agent  0 :  0.06127595901489258
episode:  17 training step:  747 loss of agent  1 :  0.2063763290643692
episode:  17 training step:  747 loss of agent  2 :  0.24987190961837769
episode:  17 training step:  747 loss of agent  3 :  0.20674753189086914
episode:  17 training step:  748 loss of agent  0 :  0.03835409879684448
episode:  17 training step:  748 loss of agent  1 :  0.43642058968544006
episode:  17 training step:  748 loss of agent  2 :  0.22865086793899536
episode:  17 training step:  748 loss of agent  3 :  0.18644562363624573
episode:  17 training step:  749 loss of agent  0 :  0.05141393467783928
episode:  17 training step:  749 loss of agent  1 :  0.2390570044517517
episode:  17 training step:  749 loss of agent  2 :  0.15362286567687988
episode:  17 training step:  749 loss of agent  3 :  0.12762902677059174
episode:  17 training step:  750 loss of agent  0 :  0.05496436357498169
episode:  17 training step:  750 loss of agent  1 :  0.303340345621109
episode:  17 training step:  750 loss of agent  2 :  0.21171562373638153
episode:  17 training step:  750 loss of agent  3 :  0.13558004796504974
Evaluation
env seed: 6 evaluation score at the training step:  750 :  {'adversary_0': -23.382044133477933, 'agent_0': -6.836359089161981, 'agent_1': -6.836359089161981, 'agent_2': -6.836359089161981}
model saving.................................
episode:  17 training step:  751 loss of agent  0 :  0.03715389221906662
episode:  17 training step:  751 loss of agent  1 :  0.3009576201438904
episode:  17 training step:  751 loss of agent  2 :  0.14713478088378906
episode:  17 training step:  751 loss of agent  3 :  0.20352213084697723
episode:  17 training step:  752 loss of agent  0 :  0.102748341858387
episode:  17 training step:  752 loss of agent  1 :  0.33760976791381836
episode:  17 training step:  752 loss of agent  2 :  0.18071705102920532
episode:  17 training step:  752 loss of agent  3 :  0.256043404340744
episode:  17 training step:  753 loss of agent  0 :  0.04032764583826065
episode:  17 training step:  753 loss of agent  1 :  0.34348082542419434
episode:  17 training step:  753 loss of agent  2 :  0.19441261887550354
episode:  17 training step:  753 loss of agent  3 :  0.13917970657348633
episode:  17 training step:  754 loss of agent  0 :  0.07700712978839874
episode:  17 training step:  754 loss of agent  1 :  0.30199915170669556
episode:  17 training step:  754 loss of agent  2 :  0.21618522703647614
episode:  17 training step:  754 loss of agent  3 :  0.1853710114955902
episode:  17 training step:  755 loss of agent  0 :  0.059003185480833054
episode:  17 training step:  755 loss of agent  1 :  0.3843706548213959
episode:  17 training step:  755 loss of agent  2 :  0.2701420485973358
episode:  17 training step:  755 loss of agent  3 :  0.16035713255405426
Evaluation
env seed: 6 evaluation score at the training step:  755 :  {'adversary_0': -58.795576960904896, 'agent_0': 15.229551688868089, 'agent_1': 15.229551688868089, 'agent_2': 15.229551688868089}
episode:  17 training step:  756 loss of agent  0 :  0.061114806681871414
episode:  17 training step:  756 loss of agent  1 :  0.2735660970211029
episode:  17 training step:  756 loss of agent  2 :  0.15893006324768066
episode:  17 training step:  756 loss of agent  3 :  0.08138597011566162
episode:  17 training step:  757 loss of agent  0 :  0.09654811024665833
episode:  17 training step:  757 loss of agent  1 :  0.1951090544462204
episode:  17 training step:  757 loss of agent  2 :  0.17468272149562836
episode:  17 training step:  757 loss of agent  3 :  0.1898588091135025
episode:  17 training step:  758 loss of agent  0 :  0.0401463657617569
episode:  17 training step:  758 loss of agent  1 :  0.2712591588497162
episode:  17 training step:  758 loss of agent  2 :  0.12548549473285675
episode:  17 training step:  758 loss of agent  3 :  0.1597691774368286
episode:  17 training step:  759 loss of agent  0 :  0.06754821538925171
episode:  17 training step:  759 loss of agent  1 :  0.5140711069107056
episode:  17 training step:  759 loss of agent  2 :  0.3239096701145172
episode:  17 training step:  759 loss of agent  3 :  0.12602448463439941
episode:  17 training step:  760 loss of agent  0 :  0.05472145229578018
episode:  17 training step:  760 loss of agent  1 :  0.21372364461421967
episode:  17 training step:  760 loss of agent  2 :  0.15948586165905
episode:  17 training step:  760 loss of agent  3 :  0.21309131383895874
Evaluation
env seed: 6 evaluation score at the training step:  760 :  {'adversary_0': -57.54904373243621, 'agent_0': 10.937345396917, 'agent_1': 10.937345396917, 'agent_2': 10.937345396917}
model saving.................................
episode:  17 training step:  761 loss of agent  0 :  0.0363808274269104
episode:  17 training step:  761 loss of agent  1 :  0.2778306007385254
episode:  17 training step:  761 loss of agent  2 :  0.2553737163543701
episode:  17 training step:  761 loss of agent  3 :  0.2043267786502838
episode:  17 training step:  762 loss of agent  0 :  0.045697059482336044
episode:  17 training step:  762 loss of agent  1 :  0.3149905502796173
episode:  17 training step:  762 loss of agent  2 :  0.142686128616333
episode:  17 training step:  762 loss of agent  3 :  0.1802443265914917
episode:  17 training step:  763 loss of agent  0 :  0.05990064889192581
episode:  17 training step:  763 loss of agent  1 :  0.28060296177864075
episode:  17 training step:  763 loss of agent  2 :  0.16936565935611725
episode:  17 training step:  763 loss of agent  3 :  0.28828567266464233
episode:  17 training step:  764 loss of agent  0 :  0.05391876772046089
episode:  17 training step:  764 loss of agent  1 :  0.34713056683540344
episode:  17 training step:  764 loss of agent  2 :  0.07931295037269592
episode:  17 training step:  764 loss of agent  3 :  0.2026045173406601
episode:  17 training step:  765 loss of agent  0 :  0.0486786812543869
episode:  17 training step:  765 loss of agent  1 :  0.190534770488739
episode:  17 training step:  765 loss of agent  2 :  0.2112162858247757
episode:  17 training step:  765 loss of agent  3 :  0.11989401280879974
Evaluation
env seed: 6 evaluation score at the training step:  765 :  {'adversary_0': -46.95842401373866, 'agent_0': -5.539906065904198, 'agent_1': -5.539906065904198, 'agent_2': -5.539906065904198}
episode 17 terminated at 900
episode: 18
epoch: 1
episode:  18 training step:  766 loss of agent  0 :  0.05049573630094528
episode:  18 training step:  766 loss of agent  1 :  0.3695010840892792
episode:  18 training step:  766 loss of agent  2 :  0.22955060005187988
episode:  18 training step:  766 loss of agent  3 :  0.20943143963813782
episode:  18 training step:  767 loss of agent  0 :  0.05515555292367935
episode:  18 training step:  767 loss of agent  1 :  0.2965599298477173
episode:  18 training step:  767 loss of agent  2 :  0.14927791059017181
episode:  18 training step:  767 loss of agent  3 :  0.21016158163547516
episode:  18 training step:  768 loss of agent  0 :  0.07230868935585022
episode:  18 training step:  768 loss of agent  1 :  0.23851732909679413
episode:  18 training step:  768 loss of agent  2 :  0.17893987894058228
episode:  18 training step:  768 loss of agent  3 :  0.17922843992710114
episode:  18 training step:  769 loss of agent  0 :  0.038662075996398926
episode:  18 training step:  769 loss of agent  1 :  0.2980691194534302
episode:  18 training step:  769 loss of agent  2 :  0.1183420717716217
episode:  18 training step:  769 loss of agent  3 :  0.22806096076965332
episode:  18 training step:  770 loss of agent  0 :  0.03311065956950188
episode:  18 training step:  770 loss of agent  1 :  0.26717522740364075
episode:  18 training step:  770 loss of agent  2 :  0.12501536309719086
episode:  18 training step:  770 loss of agent  3 :  0.14649902284145355
Evaluation
env seed: 6 evaluation score at the training step:  770 :  {'adversary_0': -29.418524571940292, 'agent_0': 1.5514650405933035, 'agent_1': 1.5514650405933035, 'agent_2': 1.5514650405933035}
model saving.................................
episode:  18 training step:  771 loss of agent  0 :  0.066684789955616
episode:  18 training step:  771 loss of agent  1 :  0.4036969840526581
episode:  18 training step:  771 loss of agent  2 :  0.11628715693950653
episode:  18 training step:  771 loss of agent  3 :  0.1512206643819809
episode:  18 training step:  772 loss of agent  0 :  0.076299287378788
episode:  18 training step:  772 loss of agent  1 :  0.22621706128120422
episode:  18 training step:  772 loss of agent  2 :  0.16328758001327515
episode:  18 training step:  772 loss of agent  3 :  0.15376688539981842
episode:  18 training step:  773 loss of agent  0 :  0.09080713987350464
episode:  18 training step:  773 loss of agent  1 :  0.3706830143928528
episode:  18 training step:  773 loss of agent  2 :  0.09092588722705841
episode:  18 training step:  773 loss of agent  3 :  0.17726503312587738
episode:  18 training step:  774 loss of agent  0 :  0.056296251714229584
episode:  18 training step:  774 loss of agent  1 :  0.21045581996440887
episode:  18 training step:  774 loss of agent  2 :  0.1930142194032669
episode:  18 training step:  774 loss of agent  3 :  0.11233356595039368
episode:  18 training step:  775 loss of agent  0 :  0.05470889434218407
episode:  18 training step:  775 loss of agent  1 :  0.41988810896873474
episode:  18 training step:  775 loss of agent  2 :  0.13500213623046875
episode:  18 training step:  775 loss of agent  3 :  0.20684123039245605
Evaluation
env seed: 6 evaluation score at the training step:  775 :  {'adversary_0': -30.64822081268776, 'agent_0': 0.3173146596315063, 'agent_1': 0.3173146596315063, 'agent_2': 0.3173146596315063}
episode:  18 training step:  776 loss of agent  0 :  0.034639935940504074
episode:  18 training step:  776 loss of agent  1 :  0.2548523545265198
episode:  18 training step:  776 loss of agent  2 :  0.25072699785232544
episode:  18 training step:  776 loss of agent  3 :  0.18629778921604156
episode:  18 training step:  777 loss of agent  0 :  0.03930260241031647
episode:  18 training step:  777 loss of agent  1 :  0.3559108078479767
episode:  18 training step:  777 loss of agent  2 :  0.0644858255982399
episode:  18 training step:  777 loss of agent  3 :  0.12597037851810455
episode:  18 training step:  778 loss of agent  0 :  0.05583909526467323
episode:  18 training step:  778 loss of agent  1 :  0.3415287137031555
episode:  18 training step:  778 loss of agent  2 :  0.09664620459079742
episode:  18 training step:  778 loss of agent  3 :  0.18600675463676453
episode:  18 training step:  779 loss of agent  0 :  0.04814829304814339
episode:  18 training step:  779 loss of agent  1 :  0.31089353561401367
episode:  18 training step:  779 loss of agent  2 :  0.12470842897891998
episode:  18 training step:  779 loss of agent  3 :  0.1538112908601761
episode:  18 training step:  780 loss of agent  0 :  0.03345199301838875
episode:  18 training step:  780 loss of agent  1 :  0.1448715180158615
episode:  18 training step:  780 loss of agent  2 :  0.14225445687770844
episode:  18 training step:  780 loss of agent  3 :  0.22361253201961517
Evaluation
env seed: 6 evaluation score at the training step:  780 :  {'adversary_0': -31.903286638122097, 'agent_0': 3.5463982214126046, 'agent_1': 3.5463982214126046, 'agent_2': 3.5463982214126046}
model saving.................................
episode:  18 training step:  781 loss of agent  0 :  0.0692647248506546
episode:  18 training step:  781 loss of agent  1 :  0.2894801199436188
episode:  18 training step:  781 loss of agent  2 :  0.16146667301654816
episode:  18 training step:  781 loss of agent  3 :  0.10442956537008286
episode:  18 training step:  782 loss of agent  0 :  0.05559161677956581
episode:  18 training step:  782 loss of agent  1 :  0.39972102642059326
episode:  18 training step:  782 loss of agent  2 :  0.2215001881122589
episode:  18 training step:  782 loss of agent  3 :  0.24707961082458496
episode:  18 training step:  783 loss of agent  0 :  0.047845508903265
episode:  18 training step:  783 loss of agent  1 :  0.27712786197662354
episode:  18 training step:  783 loss of agent  2 :  0.12051986157894135
episode:  18 training step:  783 loss of agent  3 :  0.15484684705734253
episode:  18 training step:  784 loss of agent  0 :  0.06696668267250061
episode:  18 training step:  784 loss of agent  1 :  0.28529608249664307
episode:  18 training step:  784 loss of agent  2 :  0.22463001310825348
episode:  18 training step:  784 loss of agent  3 :  0.22084404528141022
episode:  18 training step:  785 loss of agent  0 :  0.07572288811206818
episode:  18 training step:  785 loss of agent  1 :  0.43333324790000916
episode:  18 training step:  785 loss of agent  2 :  0.1834218055009842
episode:  18 training step:  785 loss of agent  3 :  0.2121950387954712
Evaluation
env seed: 6 evaluation score at the training step:  785 :  {'adversary_0': -23.382044133477933, 'agent_0': -3.2169128029522596, 'agent_1': -3.2169128029522596, 'agent_2': -3.2169128029522596}
episode:  18 training step:  786 loss of agent  0 :  0.04171464964747429
episode:  18 training step:  786 loss of agent  1 :  0.4398110806941986
episode:  18 training step:  786 loss of agent  2 :  0.1495540887117386
episode:  18 training step:  786 loss of agent  3 :  0.17691847681999207
episode:  18 training step:  787 loss of agent  0 :  0.054575104266405106
episode:  18 training step:  787 loss of agent  1 :  0.39239609241485596
episode:  18 training step:  787 loss of agent  2 :  0.162018284201622
episode:  18 training step:  787 loss of agent  3 :  0.21289804577827454
episode:  18 training step:  788 loss of agent  0 :  0.07000225782394409
episode:  18 training step:  788 loss of agent  1 :  0.35753995180130005
episode:  18 training step:  788 loss of agent  2 :  0.1611427664756775
episode:  18 training step:  788 loss of agent  3 :  0.20849499106407166
episode:  18 training step:  789 loss of agent  0 :  0.08123590797185898
episode:  18 training step:  789 loss of agent  1 :  0.5171166062355042
episode:  18 training step:  789 loss of agent  2 :  0.16903156042099
episode:  18 training step:  789 loss of agent  3 :  0.15247948467731476
episode 18 terminated at 925
epoch: 2
episode:  18 training step:  790 loss of agent  0 :  0.04303677752614021
episode:  18 training step:  790 loss of agent  1 :  0.3198677599430084
episode:  18 training step:  790 loss of agent  2 :  0.17904320359230042
episode:  18 training step:  790 loss of agent  3 :  0.16786989569664001
Evaluation
env seed: 6 evaluation score at the training step:  790 :  {'adversary_0': -47.39058422711202, 'agent_0': 20.503495702434357, 'agent_1': 20.503495702434357, 'agent_2': 20.503495702434357}
model saving.................................
episode:  18 training step:  791 loss of agent  0 :  0.07436829060316086
episode:  18 training step:  791 loss of agent  1 :  0.37372878193855286
episode:  18 training step:  791 loss of agent  2 :  0.11402655392885208
episode:  18 training step:  791 loss of agent  3 :  0.21965734660625458
episode:  18 training step:  792 loss of agent  0 :  0.07441728562116623
episode:  18 training step:  792 loss of agent  1 :  0.34132152795791626
episode:  18 training step:  792 loss of agent  2 :  0.1482389271259308
episode:  18 training step:  792 loss of agent  3 :  0.17072159051895142
episode:  18 training step:  793 loss of agent  0 :  0.054647210985422134
episode:  18 training step:  793 loss of agent  1 :  0.28112247586250305
episode:  18 training step:  793 loss of agent  2 :  0.11583610624074936
episode:  18 training step:  794 loss of agent  0 :  0.05777924880385399
episode:  18 training step:  794 loss of agent  1 :  0.35094475746154785
episode:  18 training step:  794 loss of agent  2 :  0.20262077450752258
episode:  18 training step:  794 loss of agent  3 :  0.26025789976119995
episode:  18 training step:  795 loss of agent  0 :  0.0661827027797699
episode:  18 training step:  795 loss of agent  1 :  0.32677656412124634
episode:  18 training step:  795 loss of agent  2 :  0.1747322380542755
episode:  18 training step:  795 loss of agent  3 :  0.17129699885845184
Evaluation
env seed: 6 evaluation score at the training step:  795 :  {'adversary_0': -53.07167618872629, 'agent_0': 23.69777194136508, 'agent_1': 23.69777194136508, 'agent_2': 23.69777194136508}
episode:  18 training step:  796 loss of agent  0 :  0.05286845564842224
episode:  18 training step:  796 loss of agent  1 :  0.29601263999938965
episode:  18 training step:  796 loss of agent  2 :  0.19488999247550964
episode:  18 training step:  796 loss of agent  3 :  0.07691390067338943
episode:  18 training step:  797 loss of agent  0 :  0.059037234634160995
episode:  18 training step:  797 loss of agent  1 :  0.20809553563594818
episode:  18 training step:  797 loss of agent  2 :  0.14080902934074402
episode:  18 training step:  797 loss of agent  3 :  0.059150345623493195
episode:  18 training step:  798 loss of agent  0 :  0.04788688197731972
episode:  18 training step:  798 loss of agent  1 :  0.3637448847293854
episode:  18 training step:  798 loss of agent  2 :  0.22595611214637756
episode:  18 training step:  798 loss of agent  3 :  0.2213728129863739
episode:  18 training step:  799 loss of agent  0 :  0.06747069209814072
episode:  18 training step:  799 loss of agent  1 :  0.22051270306110382
episode:  18 training step:  799 loss of agent  2 :  0.10623300075531006
episode:  18 training step:  799 loss of agent  3 :  0.26228782534599304
episode:  18 training step:  800 loss of agent  0 :  0.05695769190788269
episode:  18 training step:  800 loss of agent  1 :  0.3092191517353058
episode:  18 training step:  800 loss of agent  2 :  0.19389943778514862
episode:  18 training step:  800 loss of agent  3 :  0.21091340482234955
Evaluation
env seed: 6 evaluation score at the training step:  800 :  {'adversary_0': -47.811566882720804, 'agent_0': 19.780531840316225, 'agent_1': 19.780531840316225, 'agent_2': 19.780531840316225}
model saving.................................
episode:  18 training step:  801 loss of agent  0 :  0.10213812440633774
episode:  18 training step:  801 loss of agent  1 :  0.4493962526321411
episode:  18 training step:  801 loss of agent  2 :  0.19102683663368225
episode:  18 training step:  801 loss of agent  3 :  0.2648000419139862
episode:  18 training step:  802 loss of agent  0 :  0.06300058960914612
episode:  18 training step:  802 loss of agent  1 :  0.30494195222854614
episode:  18 training step:  802 loss of agent  2 :  0.15702170133590698
episode:  18 training step:  802 loss of agent  3 :  0.2014111578464508
episode:  18 training step:  803 loss of agent  0 :  0.042261023074388504
episode:  18 training step:  803 loss of agent  1 :  0.16412904858589172
episode:  18 training step:  803 loss of agent  2 :  0.13206931948661804
episode:  18 training step:  803 loss of agent  3 :  0.2110573798418045
episode:  18 training step:  804 loss of agent  0 :  0.04810545593500137
episode:  18 training step:  804 loss of agent  1 :  0.2538028657436371
episode:  18 training step:  804 loss of agent  2 :  0.192414328455925
episode:  18 training step:  804 loss of agent  3 :  0.22415286302566528
episode:  18 training step:  805 loss of agent  0 :  0.04863467067480087
episode:  18 training step:  805 loss of agent  1 :  0.32219207286834717
episode:  18 training step:  805 loss of agent  2 :  0.16322727501392365
episode:  18 training step:  805 loss of agent  3 :  0.11642370373010635
Evaluation
env seed: 6 evaluation score at the training step:  805 :  {'adversary_0': -24.4373805012413, 'agent_0': -2.5247866030018082, 'agent_1': -2.5247866030018082, 'agent_2': -2.5247866030018082}
episode:  18 training step:  806 loss of agent  0 :  0.08062254637479782
episode:  18 training step:  806 loss of agent  1 :  0.49061402678489685
episode:  18 training step:  806 loss of agent  2 :  0.23354008793830872
episode:  18 training step:  806 loss of agent  3 :  0.20910753309726715
episode:  18 training step:  807 loss of agent  0 :  0.042414210736751556
episode:  18 training step:  807 loss of agent  1 :  0.29319944977760315
episode:  18 training step:  807 loss of agent  2 :  0.11972132325172424
episode:  18 training step:  807 loss of agent  3 :  0.1677285134792328
episode:  18 training step:  808 loss of agent  0 :  0.05809249356389046
episode:  18 training step:  808 loss of agent  1 :  0.4199706017971039
episode:  18 training step:  808 loss of agent  2 :  0.1397232711315155
episode:  18 training step:  808 loss of agent  3 :  0.14275091886520386
episode:  18 training step:  809 loss of agent  0 :  0.10276202857494354
episode:  18 training step:  809 loss of agent  1 :  0.23376579582691193
episode:  18 training step:  809 loss of agent  2 :  0.19169054925441742
episode:  18 training step:  809 loss of agent  3 :  0.13587109744548798
episode:  18 training step:  810 loss of agent  0 :  0.056454528123140335
episode:  18 training step:  810 loss of agent  1 :  0.2140667587518692
episode:  18 training step:  810 loss of agent  2 :  0.2095452845096588
episode:  18 training step:  810 loss of agent  3 :  0.15679310262203217
Evaluation
env seed: 6 evaluation score at the training step:  810 :  {'adversary_0': -23.251190738993753, 'agent_0': -6.664850879192248, 'agent_1': -6.664850879192248, 'agent_2': -6.664850879192248}
model saving.................................
episode:  18 training step:  811 loss of agent  0 :  0.09446652978658676
episode:  18 training step:  811 loss of agent  1 :  0.30745837092399597
episode:  18 training step:  811 loss of agent  2 :  0.2629447877407074
episode:  18 training step:  811 loss of agent  3 :  0.13819871842861176
episode:  18 training step:  812 loss of agent  0 :  0.04214627295732498
episode:  18 training step:  812 loss of agent  1 :  0.4219576120376587
episode:  18 training step:  812 loss of agent  2 :  0.17248304188251495
episode:  18 training step:  812 loss of agent  3 :  0.18556088209152222
episode:  18 training step:  813 loss of agent  0 :  0.0697198137640953
episode:  18 training step:  813 loss of agent  1 :  0.3347041606903076
episode:  18 training step:  813 loss of agent  2 :  0.13430684804916382
episode:  18 training step:  813 loss of agent  3 :  0.13915866613388062
episode 18 terminated at 950
episode: 19
epoch: 1
episode:  19 training step:  814 loss of agent  0 :  0.07154235988855362
episode:  19 training step:  814 loss of agent  1 :  0.2909102737903595
episode:  19 training step:  814 loss of agent  2 :  0.08901787549257278
episode:  19 training step:  814 loss of agent  3 :  0.16471749544143677
episode:  19 training step:  815 loss of agent  0 :  0.057908546179533005
episode:  19 training step:  815 loss of agent  1 :  0.21860851347446442
episode:  19 training step:  815 loss of agent  2 :  0.20794568955898285
episode:  19 training step:  815 loss of agent  3 :  0.2780706584453583
Evaluation
env seed: 6 evaluation score at the training step:  815 :  {'adversary_0': -57.177004319356016, 'agent_0': 21.44134949512505, 'agent_1': 21.44134949512505, 'agent_2': 21.44134949512505}
episode:  19 training step:  816 loss of agent  0 :  0.07822394371032715
episode:  19 training step:  816 loss of agent  1 :  0.33481645584106445
episode:  19 training step:  816 loss of agent  2 :  0.10474354028701782
episode:  19 training step:  816 loss of agent  3 :  0.16601115465164185
episode:  19 training step:  817 loss of agent  0 :  0.06483287364244461
episode:  19 training step:  817 loss of agent  1 :  0.35297536849975586
episode:  19 training step:  817 loss of agent  2 :  0.11704318970441818
episode:  19 training step:  817 loss of agent  3 :  0.09830332547426224
episode:  19 training step:  818 loss of agent  0 :  0.029394321143627167
episode:  19 training step:  818 loss of agent  1 :  0.3278256952762604
episode:  19 training step:  818 loss of agent  2 :  0.22735469043254852
episode:  19 training step:  818 loss of agent  3 :  0.1614406406879425
episode:  19 training step:  819 loss of agent  0 :  0.06259604543447495
episode:  19 training step:  819 loss of agent  1 :  0.33210989832878113
episode:  19 training step:  819 loss of agent  2 :  0.13075348734855652
episode:  19 training step:  819 loss of agent  3 :  0.1738891303539276
episode:  19 training step:  820 loss of agent  0 :  0.045702215284109116
episode:  19 training step:  820 loss of agent  1 :  0.24112476408481598
episode:  19 training step:  820 loss of agent  2 :  0.08441662788391113
episode:  19 training step:  820 loss of agent  3 :  0.1888808161020279
Evaluation
env seed: 6 evaluation score at the training step:  820 :  {'adversary_0': -58.0715762951324, 'agent_0': 35.100678973921575, 'agent_1': 35.100678973921575, 'agent_2': 35.100678973921575}
model saving.................................
episode:  19 training step:  821 loss of agent  0 :  0.05119040980935097
episode:  19 training step:  821 loss of agent  1 :  0.2653007209300995
episode:  19 training step:  821 loss of agent  2 :  0.1434311717748642
episode:  19 training step:  821 loss of agent  3 :  0.1480017751455307
episode:  19 training step:  822 loss of agent  0 :  0.043682873249053955
episode:  19 training step:  822 loss of agent  1 :  0.23671545088291168
episode:  19 training step:  822 loss of agent  2 :  0.14083756506443024
episode:  19 training step:  822 loss of agent  3 :  0.20966216921806335
episode:  19 training step:  823 loss of agent  0 :  0.056120142340660095
episode:  19 training step:  823 loss of agent  1 :  0.29693686962127686
episode:  19 training step:  823 loss of agent  2 :  0.1521092802286148
episode:  19 training step:  823 loss of agent  3 :  0.08638112992048264
episode:  19 training step:  824 loss of agent  0 :  0.0916578620672226
episode:  19 training step:  824 loss of agent  1 :  0.32728832960128784
episode:  19 training step:  824 loss of agent  2 :  0.11341111361980438
episode:  19 training step:  824 loss of agent  3 :  0.2159491628408432
episode:  19 training step:  825 loss of agent  0 :  0.04839452728629112
episode:  19 training step:  825 loss of agent  1 :  0.3763582706451416
episode:  19 training step:  825 loss of agent  2 :  0.13949213922023773
episode:  19 training step:  825 loss of agent  3 :  0.23977293074131012
Evaluation
env seed: 6 evaluation score at the training step:  825 :  {'adversary_0': -60.310563181375116, 'agent_0': 33.971090011365774, 'agent_1': 33.971090011365774, 'agent_2': 33.971090011365774}
episode:  19 training step:  826 loss of agent  0 :  0.05820862948894501
episode:  19 training step:  826 loss of agent  1 :  0.26951226592063904
episode:  19 training step:  826 loss of agent  2 :  0.13448935747146606
episode:  19 training step:  826 loss of agent  3 :  0.2010127454996109
episode:  19 training step:  827 loss of agent  0 :  0.07037375122308731
episode:  19 training step:  827 loss of agent  1 :  0.271488755941391
episode:  19 training step:  827 loss of agent  2 :  0.13763883709907532
episode:  19 training step:  827 loss of agent  3 :  0.12475944310426712
episode:  19 training step:  828 loss of agent  0 :  0.04020761698484421
episode:  19 training step:  828 loss of agent  1 :  0.3414599299430847
episode:  19 training step:  828 loss of agent  2 :  0.17816071212291718
episode:  19 training step:  828 loss of agent  3 :  0.21185211837291718
episode:  19 training step:  829 loss of agent  0 :  0.03641723841428757
episode:  19 training step:  829 loss of agent  1 :  0.3075962960720062
episode:  19 training step:  829 loss of agent  2 :  0.09908758848905563
episode:  19 training step:  829 loss of agent  3 :  0.09123780578374863
episode:  19 training step:  830 loss of agent  0 :  0.05853452533483505
episode:  19 training step:  830 loss of agent  1 :  0.2598322331905365
episode:  19 training step:  830 loss of agent  2 :  0.16415579617023468
episode:  19 training step:  830 loss of agent  3 :  0.14197395741939545
Evaluation
env seed: 6 evaluation score at the training step:  830 :  {'adversary_0': -54.241328910163034, 'agent_0': 20.645926588608155, 'agent_1': 20.645926588608155, 'agent_2': 20.645926588608155}
model saving.................................
episode:  19 training step:  831 loss of agent  0 :  0.04678836837410927
episode:  19 training step:  831 loss of agent  1 :  0.30243808031082153
episode:  19 training step:  831 loss of agent  2 :  0.16816703975200653
episode:  19 training step:  831 loss of agent  3 :  0.1625927835702896
episode:  19 training step:  832 loss of agent  0 :  0.05387384444475174
episode:  19 training step:  832 loss of agent  1 :  0.2990786135196686
episode:  19 training step:  832 loss of agent  2 :  0.15868723392486572
episode:  19 training step:  832 loss of agent  3 :  0.1528031975030899
episode:  19 training step:  833 loss of agent  0 :  0.050041623413562775
episode:  19 training step:  833 loss of agent  1 :  0.30920448899269104
episode:  19 training step:  833 loss of agent  2 :  0.1862318515777588
episode:  19 training step:  833 loss of agent  3 :  0.1724468171596527
episode:  19 training step:  834 loss of agent  0 :  0.023776236921548843
episode:  19 training step:  834 loss of agent  1 :  0.29821130633354187
episode:  19 training step:  834 loss of agent  2 :  0.11424598097801208
episode:  19 training step:  834 loss of agent  3 :  0.1296708732843399
episode:  19 training step:  835 loss of agent  0 :  0.05841159448027611
episode:  19 training step:  835 loss of agent  1 :  0.3456675410270691
episode:  19 training step:  835 loss of agent  2 :  0.2577427327632904
episode:  19 training step:  835 loss of agent  3 :  0.2839328348636627
Evaluation
env seed: 6 evaluation score at the training step:  835 :  {'adversary_0': -35.02685698129072, 'agent_0': 7.406322815898966, 'agent_1': 7.406322815898966, 'agent_2': 7.406322815898966}
episode:  19 training step:  836 loss of agent  0 :  0.055236004292964935
episode:  19 training step:  836 loss of agent  1 :  0.3698873817920685
episode:  19 training step:  836 loss of agent  2 :  0.1735074520111084
episode:  19 training step:  836 loss of agent  3 :  0.12270303070545197
episode:  19 training step:  837 loss of agent  0 :  0.03701263666152954
episode:  19 training step:  837 loss of agent  1 :  0.3734015226364136
episode:  19 training step:  837 loss of agent  2 :  0.15737688541412354
episode:  19 training step:  837 loss of agent  3 :  0.19914206862449646
episode 19 terminated at 975
epoch: 2
episode:  19 training step:  838 loss of agent  0 :  0.047461193054914474
episode:  19 training step:  838 loss of agent  1 :  0.3175199329853058
episode:  19 training step:  838 loss of agent  2 :  0.16191162168979645
episode:  19 training step:  838 loss of agent  3 :  0.07680145651102066
episode:  19 training step:  839 loss of agent  0 :  0.11353281140327454
episode:  19 training step:  839 loss of agent  1 :  0.20259058475494385
episode:  19 training step:  839 loss of agent  2 :  0.19222010672092438
episode:  19 training step:  839 loss of agent  3 :  0.2103787511587143
episode:  19 training step:  840 loss of agent  0 :  0.07488470524549484
episode:  19 training step:  840 loss of agent  1 :  0.3649514615535736
episode:  19 training step:  840 loss of agent  2 :  0.25514960289001465
episode:  19 training step:  840 loss of agent  3 :  0.20198914408683777
Evaluation
env seed: 6 evaluation score at the training step:  840 :  {'adversary_0': -29.262878993946327, 'agent_0': -0.9853535761616836, 'agent_1': -0.9853535761616836, 'agent_2': -0.9853535761616836}
model saving.................................
episode:  19 training step:  841 loss of agent  0 :  0.061791595071554184
episode:  19 training step:  841 loss of agent  1 :  0.20185115933418274
episode:  19 training step:  841 loss of agent  2 :  0.172612726688385
episode:  19 training step:  841 loss of agent  3 :  0.12687155604362488
episode:  19 training step:  842 loss of agent  0 :  0.0703587681055069
episode:  19 training step:  842 loss of agent  1 :  0.38925275206565857
episode:  19 training step:  842 loss of agent  2 :  0.29268866777420044
episode:  19 training step:  842 loss of agent  3 :  0.11957619339227676
episode:  19 training step:  843 loss of agent  0 :  0.077095165848732
episode:  19 training step:  843 loss of agent  1 :  0.3535158932209015
episode:  19 training step:  843 loss of agent  2 :  0.24769161641597748
episode:  19 training step:  843 loss of agent  3 :  0.18992497026920319
episode:  19 training step:  844 loss of agent  0 :  0.05092044547200203
episode:  19 training step:  844 loss of agent  1 :  0.31916266679763794
episode:  19 training step:  844 loss of agent  2 :  0.16858455538749695
episode:  19 training step:  844 loss of agent  3 :  0.21006989479064941
episode:  19 training step:  845 loss of agent  0 :  0.031351979821920395
episode:  19 training step:  845 loss of agent  1 :  0.3725878894329071
episode:  19 training step:  845 loss of agent  2 :  0.13585251569747925
episode:  19 training step:  845 loss of agent  3 :  0.2906397879123688
Evaluation
env seed: 6 evaluation score at the training step:  845 :  {'adversary_0': -29.42528076388581, 'agent_0': -0.7931224587541713, 'agent_1': -0.7931224587541713, 'agent_2': -0.7931224587541713}
episode:  19 training step:  846 loss of agent  0 :  0.05787887051701546
episode:  19 training step:  846 loss of agent  1 :  0.2786862850189209
episode:  19 training step:  846 loss of agent  2 :  0.186885267496109
episode:  19 training step:  846 loss of agent  3 :  0.1674443930387497
episode:  19 training step:  847 loss of agent  0 :  0.06512756645679474
episode:  19 training step:  847 loss of agent  1 :  0.26726314425468445
episode:  19 training step:  847 loss of agent  2 :  0.09713399410247803
episode:  19 training step:  847 loss of agent  3 :  0.14818091690540314
episode:  19 training step:  848 loss of agent  0 :  0.05894944444298744
episode:  19 training step:  848 loss of agent  1 :  0.29228857159614563
episode:  19 training step:  848 loss of agent  2 :  0.18778206408023834
episode:  19 training step:  848 loss of agent  3 :  0.15525051951408386
episode:  19 training step:  849 loss of agent  0 :  0.042582400143146515
episode:  19 training step:  849 loss of agent  1 :  0.24769648909568787
episode:  19 training step:  849 loss of agent  2 :  0.16277965903282166
episode:  19 training step:  849 loss of agent  3 :  0.14082302153110504
episode:  19 training step:  850 loss of agent  0 :  0.061633866280317307
episode:  19 training step:  850 loss of agent  1 :  0.21343232691287994
episode:  19 training step:  850 loss of agent  2 :  0.1807573437690735
episode:  19 training step:  850 loss of agent  3 :  0.17277954518795013
Evaluation
env seed: 6 evaluation score at the training step:  850 :  {'adversary_0': -23.208784138097478, 'agent_0': -6.602909705396163, 'agent_1': -6.602909705396163, 'agent_2': -6.602909705396163}
model saving.................................
episode:  19 training step:  851 loss of agent  0 :  0.054538220167160034
episode:  19 training step:  851 loss of agent  1 :  0.27695727348327637
episode:  19 training step:  851 loss of agent  2 :  0.15293492376804352
episode:  19 training step:  851 loss of agent  3 :  0.2265348583459854
episode:  19 training step:  852 loss of agent  0 :  0.0244516022503376
episode:  19 training step:  852 loss of agent  1 :  0.32441285252571106
episode:  19 training step:  852 loss of agent  2 :  0.22482088208198547
episode:  19 training step:  852 loss of agent  3 :  0.1568448841571808
episode:  19 training step:  853 loss of agent  0 :  0.0423714779317379
episode:  19 training step:  853 loss of agent  1 :  0.40670469403266907
episode:  19 training step:  853 loss of agent  2 :  0.11490622162818909
episode:  19 training step:  853 loss of agent  3 :  0.182195782661438
episode:  19 training step:  854 loss of agent  0 :  0.039157137274742126
episode:  19 training step:  854 loss of agent  1 :  0.3041587471961975
episode:  19 training step:  854 loss of agent  2 :  0.16730228066444397
episode:  19 training step:  854 loss of agent  3 :  0.16889774799346924
episode:  19 training step:  855 loss of agent  0 :  0.03172220662236214
episode:  19 training step:  855 loss of agent  1 :  0.23423805832862854
episode:  19 training step:  855 loss of agent  2 :  0.19607971608638763
episode:  19 training step:  855 loss of agent  3 :  0.18957795202732086
Evaluation
env seed: 6 evaluation score at the training step:  855 :  {'adversary_0': -60.644777068016744, 'agent_0': 30.83271452238522, 'agent_1': 30.83271452238522, 'agent_2': 30.83271452238522}
episode:  19 training step:  856 loss of agent  0 :  0.0434507392346859
episode:  19 training step:  856 loss of agent  1 :  0.34555989503860474
episode:  19 training step:  856 loss of agent  2 :  0.16737163066864014
episode:  19 training step:  856 loss of agent  3 :  0.17768266797065735
episode:  19 training step:  857 loss of agent  0 :  0.045942556113004684
episode:  19 training step:  857 loss of agent  1 :  0.41413137316703796
episode:  19 training step:  857 loss of agent  2 :  0.23454011976718903
episode:  19 training step:  857 loss of agent  3 :  0.1855229288339615
episode:  19 training step:  858 loss of agent  0 :  0.05381756275892258
episode:  19 training step:  858 loss of agent  1 :  0.33871880173683167
episode:  19 training step:  858 loss of agent  2 :  0.16854146122932434
episode:  19 training step:  858 loss of agent  3 :  0.14017195999622345
episode:  19 training step:  859 loss of agent  0 :  0.028895994648337364
episode:  19 training step:  859 loss of agent  1 :  0.16385231912136078
episode:  19 training step:  859 loss of agent  2 :  0.12999823689460754
episode:  19 training step:  859 loss of agent  3 :  0.20643161237239838
episode:  19 training step:  860 loss of agent  0 :  0.06924417614936829
episode:  19 training step:  860 loss of agent  1 :  0.27010083198547363
episode:  19 training step:  860 loss of agent  2 :  0.16161802411079407
episode:  19 training step:  860 loss of agent  3 :  0.21025577187538147
Evaluation
env seed: 6 evaluation score at the training step:  860 :  {'adversary_0': -62.210725621819805, 'agent_0': 32.41232533509581, 'agent_1': 32.41232533509581, 'agent_2': 32.41232533509581}
model saving.................................
episode:  19 training step:  861 loss of agent  0 :  0.07305696606636047
episode:  19 training step:  861 loss of agent  1 :  0.4698612093925476
episode:  19 training step:  861 loss of agent  2 :  0.1643383800983429
episode:  19 training step:  861 loss of agent  3 :  0.20711052417755127
episode 19 terminated at 1000
episode: 20
epoch: 1
episode:  20 training step:  862 loss of agent  0 :  0.04011949524283409
episode:  20 training step:  862 loss of agent  1 :  0.3458687365055084
episode:  20 training step:  862 loss of agent  2 :  0.1146475300192833
episode:  20 training step:  862 loss of agent  3 :  0.19842204451560974
episode:  20 training step:  863 loss of agent  0 :  0.03270421922206879
episode:  20 training step:  863 loss of agent  1 :  0.320489764213562
episode:  20 training step:  863 loss of agent  2 :  0.18999549746513367
episode:  20 training step:  863 loss of agent  3 :  0.19496048986911774
episode:  20 training step:  864 loss of agent  0 :  0.08002282679080963
episode:  20 training step:  864 loss of agent  1 :  0.4534977674484253
episode:  20 training step:  864 loss of agent  2 :  0.26772958040237427
episode:  20 training step:  864 loss of agent  3 :  0.11746189743280411
episode:  20 training step:  865 loss of agent  0 :  0.06567695736885071
episode:  20 training step:  865 loss of agent  1 :  0.29638198018074036
episode:  20 training step:  865 loss of agent  2 :  0.16820122301578522
episode:  20 training step:  865 loss of agent  3 :  0.13869111239910126
Evaluation
env seed: 6 evaluation score at the training step:  865 :  {'adversary_0': -59.68538763483575, 'agent_0': 29.548804166005517, 'agent_1': 29.548804166005517, 'agent_2': 29.548804166005517}
episode:  20 training step:  866 loss of agent  0 :  0.06334921717643738
episode:  20 training step:  866 loss of agent  1 :  0.4295704960823059
episode:  20 training step:  866 loss of agent  2 :  0.2091149091720581
episode:  20 training step:  866 loss of agent  3 :  0.289385050535202
episode:  20 training step:  867 loss of agent  0 :  0.05073010176420212
episode:  20 training step:  867 loss of agent  1 :  0.331901878118515
episode:  20 training step:  867 loss of agent  2 :  0.15077386796474457
episode:  20 training step:  867 loss of agent  3 :  0.11154299974441528
episode:  20 training step:  868 loss of agent  0 :  0.04106270521879196
episode:  20 training step:  868 loss of agent  1 :  0.49946945905685425
episode:  20 training step:  868 loss of agent  2 :  0.10573438555002213
episode:  20 training step:  868 loss of agent  3 :  0.16537126898765564
episode:  20 training step:  869 loss of agent  0 :  0.022175703197717667
episode:  20 training step:  869 loss of agent  1 :  0.33436426520347595
episode:  20 training step:  869 loss of agent  2 :  0.2762893736362457
episode:  20 training step:  869 loss of agent  3 :  0.13415929675102234
episode:  20 training step:  870 loss of agent  0 :  0.0797632709145546
episode:  20 training step:  870 loss of agent  1 :  0.3822660446166992
episode:  20 training step:  870 loss of agent  2 :  0.23149240016937256
episode:  20 training step:  870 loss of agent  3 :  0.19027554988861084
Evaluation
env seed: 6 evaluation score at the training step:  870 :  {'adversary_0': -57.14315171189016, 'agent_0': 27.11253745532361, 'agent_1': 27.11253745532361, 'agent_2': 27.11253745532361}
model saving.................................
episode:  20 training step:  871 loss of agent  0 :  0.04007713496685028
episode:  20 training step:  871 loss of agent  1 :  0.21422907710075378
episode:  20 training step:  871 loss of agent  2 :  0.23448166251182556
episode:  20 training step:  871 loss of agent  3 :  0.19006088376045227
episode:  20 training step:  872 loss of agent  0 :  0.033529333770275116
episode:  20 training step:  872 loss of agent  1 :  0.2547646760940552
episode:  20 training step:  872 loss of agent  2 :  0.1261177957057953
episode:  20 training step:  872 loss of agent  3 :  0.20677196979522705
episode:  20 training step:  873 loss of agent  0 :  0.040482886135578156
episode:  20 training step:  873 loss of agent  1 :  0.2549506425857544
episode:  20 training step:  873 loss of agent  2 :  0.1747266948223114
episode:  20 training step:  873 loss of agent  3 :  0.2304171770811081
episode:  20 training step:  874 loss of agent  0 :  0.07750844210386276
episode:  20 training step:  874 loss of agent  1 :  0.2982652187347412
episode:  20 training step:  874 loss of agent  2 :  0.12903523445129395
episode:  20 training step:  874 loss of agent  3 :  0.183132141828537
episode:  20 training step:  875 loss of agent  0 :  0.052279818803071976
episode:  20 training step:  875 loss of agent  1 :  0.32765859365463257
episode:  20 training step:  875 loss of agent  2 :  0.20465043187141418
episode:  20 training step:  875 loss of agent  3 :  0.22436438500881195
Evaluation
env seed: 6 evaluation score at the training step:  875 :  {'adversary_0': -27.797732084618143, 'agent_0': -2.2530959652985105, 'agent_1': -2.2530959652985105, 'agent_2': -2.2530959652985105}
episode:  20 training step:  876 loss of agent  0 :  0.06074635311961174
episode:  20 training step:  876 loss of agent  1 :  0.32941704988479614
episode:  20 training step:  876 loss of agent  2 :  0.15576349198818207
episode:  20 training step:  876 loss of agent  3 :  0.15281502902507782
episode:  20 training step:  877 loss of agent  0 :  0.049221690744161606
episode:  20 training step:  877 loss of agent  1 :  0.2600475549697876
episode:  20 training step:  877 loss of agent  2 :  0.22187843918800354
episode:  20 training step:  877 loss of agent  3 :  0.06547296792268753
episode:  20 training step:  878 loss of agent  0 :  0.05508546158671379
episode:  20 training step:  878 loss of agent  1 :  0.24471253156661987
episode:  20 training step:  878 loss of agent  2 :  0.17765989899635315
episode:  20 training step:  878 loss of agent  3 :  0.17084035277366638
episode:  20 training step:  879 loss of agent  0 :  0.03577941283583641
episode:  20 training step:  879 loss of agent  1 :  0.2814640402793884
episode:  20 training step:  879 loss of agent  2 :  0.1312846839427948
episode:  20 training step:  879 loss of agent  3 :  0.12109925597906113
episode:  20 training step:  880 loss of agent  0 :  0.04661108925938606
episode:  20 training step:  880 loss of agent  1 :  0.30709314346313477
episode:  20 training step:  880 loss of agent  2 :  0.2730712592601776
episode:  20 training step:  880 loss of agent  3 :  0.1850900650024414
Evaluation
env seed: 6 evaluation score at the training step:  880 :  {'adversary_0': -26.53535563142584, 'agent_0': -3.131375546004838, 'agent_1': -3.131375546004838, 'agent_2': -3.131375546004838}
model saving.................................
episode:  20 training step:  881 loss of agent  0 :  0.04951375722885132
episode:  20 training step:  881 loss of agent  1 :  0.24724361300468445
episode:  20 training step:  881 loss of agent  2 :  0.13991326093673706
episode:  20 training step:  881 loss of agent  3 :  0.21666590869426727
episode:  20 training step:  882 loss of agent  0 :  0.05229508504271507
episode:  20 training step:  882 loss of agent  1 :  0.2643143832683563
episode:  20 training step:  882 loss of agent  2 :  0.12710903584957123
episode:  20 training step:  882 loss of agent  3 :  0.14855603873729706
episode:  20 training step:  883 loss of agent  0 :  0.045457661151885986
episode:  20 training step:  883 loss of agent  1 :  0.2854810059070587
episode:  20 training step:  883 loss of agent  2 :  0.25394654273986816
episode:  20 training step:  883 loss of agent  3 :  0.2066706418991089
episode:  20 training step:  884 loss of agent  0 :  0.031909145414829254
episode:  20 training step:  884 loss of agent  1 :  0.38547560572624207
episode:  20 training step:  884 loss of agent  2 :  0.10071603953838348
episode:  20 training step:  884 loss of agent  3 :  0.1451808512210846
episode:  20 training step:  885 loss of agent  0 :  0.04989250749349594
episode:  20 training step:  885 loss of agent  1 :  0.4017738699913025
episode:  20 training step:  885 loss of agent  2 :  0.11519427597522736
episode:  20 training step:  885 loss of agent  3 :  0.1573115438222885
Evaluation
env seed: 6 evaluation score at the training step:  885 :  {'adversary_0': -28.061876281054857, 'agent_0': -1.395236022197296, 'agent_1': -1.395236022197296, 'agent_2': -1.395236022197296}
episode 20 terminated at 1025
epoch: 2
episode:  20 training step:  886 loss of agent  0 :  0.06459321826696396
episode:  20 training step:  886 loss of agent  1 :  0.3129599690437317
episode:  20 training step:  886 loss of agent  2 :  0.13464173674583435
episode:  20 training step:  886 loss of agent  3 :  0.11767251789569855
episode:  20 training step:  887 loss of agent  0 :  0.04372718930244446
episode:  20 training step:  887 loss of agent  1 :  0.3081037104129791
episode:  20 training step:  887 loss of agent  2 :  0.07885171473026276
episode:  20 training step:  887 loss of agent  3 :  0.15393008291721344
episode:  20 training step:  888 loss of agent  0 :  0.05958263948559761
episode:  20 training step:  888 loss of agent  1 :  0.46864908933639526
episode:  20 training step:  888 loss of agent  2 :  0.21784690022468567
episode:  20 training step:  888 loss of agent  3 :  0.2189398556947708
episode:  20 training step:  889 loss of agent  0 :  0.05722415819764137
episode:  20 training step:  889 loss of agent  1 :  0.41245371103286743
episode:  20 training step:  889 loss of agent  2 :  0.21884620189666748
episode:  20 training step:  889 loss of agent  3 :  0.18530616164207458
episode:  20 training step:  890 loss of agent  0 :  0.04413158446550369
episode:  20 training step:  890 loss of agent  1 :  0.35190778970718384
episode:  20 training step:  890 loss of agent  2 :  0.17897914350032806
episode:  20 training step:  890 loss of agent  3 :  0.21086834371089935
Evaluation
env seed: 6 evaluation score at the training step:  890 :  {'adversary_0': -28.50712459969622, 'agent_0': -1.3120750716973681, 'agent_1': -1.3120750716973681, 'agent_2': -1.3120750716973681}
model saving.................................
episode:  20 training step:  891 loss of agent  0 :  0.046838074922561646
episode:  20 training step:  891 loss of agent  1 :  0.2879297435283661
episode:  20 training step:  891 loss of agent  2 :  0.11935307830572128
episode:  20 training step:  891 loss of agent  3 :  0.24945560097694397
episode:  20 training step:  892 loss of agent  0 :  0.039728276431560516
episode:  20 training step:  892 loss of agent  1 :  0.29216593503952026
episode:  20 training step:  892 loss of agent  2 :  0.13596634566783905
episode:  20 training step:  892 loss of agent  3 :  0.17826958000659943
episode:  20 training step:  893 loss of agent  0 :  0.028567712754011154
episode:  20 training step:  893 loss of agent  1 :  0.22409413754940033
episode:  20 training step:  893 loss of agent  2 :  0.08614123612642288
episode:  20 training step:  893 loss of agent  3 :  0.0904397964477539
episode:  20 training step:  894 loss of agent  0 :  0.028474237769842148
episode:  20 training step:  894 loss of agent  1 :  0.44726893305778503
episode:  20 training step:  894 loss of agent  2 :  0.2004447877407074
episode:  20 training step:  894 loss of agent  3 :  0.20892399549484253
episode:  20 training step:  895 loss of agent  0 :  0.04545191302895546
episode:  20 training step:  895 loss of agent  1 :  0.37551161646842957
episode:  20 training step:  895 loss of agent  2 :  0.1361449658870697
episode:  20 training step:  895 loss of agent  3 :  0.1445910930633545
Evaluation
env seed: 6 evaluation score at the training step:  895 :  {'adversary_0': -62.478350479681374, 'agent_0': 30.826215037563298, 'agent_1': 30.826215037563298, 'agent_2': 30.826215037563298}
episode:  20 training step:  896 loss of agent  0 :  0.04143165424466133
episode:  20 training step:  896 loss of agent  1 :  0.22294646501541138
episode:  20 training step:  896 loss of agent  2 :  0.20090973377227783
episode:  20 training step:  896 loss of agent  3 :  0.2002926468849182
episode:  20 training step:  897 loss of agent  0 :  0.02991161122918129
episode:  20 training step:  897 loss of agent  1 :  0.2432389259338379
episode:  20 training step:  897 loss of agent  2 :  0.1411198377609253
episode:  20 training step:  897 loss of agent  3 :  0.11022628843784332
episode:  20 training step:  898 loss of agent  0 :  0.05322106555104256
episode:  20 training step:  898 loss of agent  1 :  0.38187211751937866
episode:  20 training step:  898 loss of agent  2 :  0.14235615730285645
episode:  20 training step:  898 loss of agent  3 :  0.21341060101985931
episode:  20 training step:  899 loss of agent  0 :  0.03589457646012306
episode:  20 training step:  899 loss of agent  1 :  0.2564779818058014
episode:  20 training step:  899 loss of agent  2 :  0.13187387585639954
episode:  20 training step:  899 loss of agent  3 :  0.22013676166534424
episode:  20 training step:  900 loss of agent  0 :  0.0390586256980896
episode:  20 training step:  900 loss of agent  1 :  0.25634801387786865
episode:  20 training step:  900 loss of agent  2 :  0.13504965603351593
episode:  20 training step:  900 loss of agent  3 :  0.15807749330997467
Evaluation
env seed: 6 evaluation score at the training step:  900 :  {'adversary_0': -70.18893754390538, 'agent_0': 39.09265156103861, 'agent_1': 39.09265156103861, 'agent_2': 39.09265156103861}
model saving.................................
episode:  20 training step:  901 loss of agent  0 :  0.0876481831073761
episode:  20 training step:  901 loss of agent  1 :  0.42869096994400024
episode:  20 training step:  901 loss of agent  2 :  0.12014006078243256
episode:  20 training step:  901 loss of agent  3 :  0.12444432079792023
episode:  20 training step:  902 loss of agent  0 :  0.0653049498796463
episode:  20 training step:  902 loss of agent  1 :  0.44717541337013245
episode:  20 training step:  902 loss of agent  2 :  0.1349080353975296
episode:  20 training step:  902 loss of agent  3 :  0.23633794486522675
episode:  20 training step:  903 loss of agent  0 :  0.0725146234035492
episode:  20 training step:  903 loss of agent  1 :  0.28471753001213074
episode:  20 training step:  903 loss of agent  2 :  0.09980739653110504
episode:  20 training step:  903 loss of agent  3 :  0.23484846949577332
episode:  20 training step:  904 loss of agent  0 :  0.05470354110002518
episode:  20 training step:  904 loss of agent  1 :  0.3254808187484741
episode:  20 training step:  904 loss of agent  2 :  0.12310732156038284
episode:  20 training step:  904 loss of agent  3 :  0.22603869438171387
episode:  20 training step:  905 loss of agent  0 :  0.07309283316135406
episode:  20 training step:  905 loss of agent  1 :  0.18377774953842163
episode:  20 training step:  905 loss of agent  2 :  0.22543689608573914
episode:  20 training step:  905 loss of agent  3 :  0.12239659577608109
Evaluation
env seed: 6 evaluation score at the training step:  905 :  {'adversary_0': -69.67709074036244, 'agent_0': 38.26842812083201, 'agent_1': 38.26842812083201, 'agent_2': 38.26842812083201}
episode:  20 training step:  906 loss of agent  0 :  0.039539884775877
episode:  20 training step:  906 loss of agent  1 :  0.22968131303787231
episode:  20 training step:  906 loss of agent  2 :  0.18411003053188324
episode:  20 training step:  906 loss of agent  3 :  0.1343357115983963
episode:  20 training step:  907 loss of agent  0 :  0.0669659972190857
episode:  20 training step:  907 loss of agent  1 :  0.44832682609558105
episode:  20 training step:  907 loss of agent  2 :  0.2784678339958191
episode:  20 training step:  907 loss of agent  3 :  0.16837981343269348
episode:  20 training step:  908 loss of agent  0 :  0.04028341546654701
episode:  20 training step:  908 loss of agent  1 :  0.3997250199317932
episode:  20 training step:  908 loss of agent  2 :  0.16287434101104736
episode:  20 training step:  908 loss of agent  3 :  0.18653841316699982
episode:  20 training step:  909 loss of agent  0 :  0.03235370293259621
episode:  20 training step:  909 loss of agent  1 :  0.34786516427993774
episode:  20 training step:  909 loss of agent  2 :  0.1377420574426651
episode:  20 training step:  909 loss of agent  3 :  0.11161027103662491
episode 20 terminated at 1050
episode: 21
epoch: 1
episode:  21 training step:  910 loss of agent  0 :  0.052683230489492416
episode:  21 training step:  910 loss of agent  1 :  0.2612943947315216
episode:  21 training step:  910 loss of agent  2 :  0.1362631767988205
episode:  21 training step:  910 loss of agent  3 :  0.24520136415958405
Evaluation
env seed: 6 evaluation score at the training step:  910 :  {'adversary_0': -56.765991311935565, 'agent_0': 23.195204416755637, 'agent_1': 23.195204416755637, 'agent_2': 23.195204416755637}
model saving.................................
episode:  21 training step:  911 loss of agent  0 :  0.017693093046545982
episode:  21 training step:  911 loss of agent  1 :  0.3974164128303528
episode:  21 training step:  911 loss of agent  2 :  0.21682344377040863
episode:  21 training step:  911 loss of agent  3 :  0.13073217868804932
episode:  21 training step:  912 loss of agent  0 :  0.03506508842110634
episode:  21 training step:  912 loss of agent  1 :  0.4019700586795807
episode:  21 training step:  912 loss of agent  2 :  0.18786181509494781
episode:  21 training step:  912 loss of agent  3 :  0.14189809560775757
episode:  21 training step:  913 loss of agent  0 :  0.06252569705247879
episode:  21 training step:  913 loss of agent  1 :  0.4154644310474396
episode:  21 training step:  913 loss of agent  2 :  0.10922088474035263
episode:  21 training step:  913 loss of agent  3 :  0.148585706949234
episode:  21 training step:  914 loss of agent  0 :  0.038803476840257645
episode:  21 training step:  914 loss of agent  1 :  0.3863186240196228
episode:  21 training step:  914 loss of agent  2 :  0.22073961794376373
episode:  21 training step:  914 loss of agent  3 :  0.15800832211971283
episode:  21 training step:  915 loss of agent  0 :  0.06577547639608383
episode:  21 training step:  915 loss of agent  1 :  0.3774566650390625
episode:  21 training step:  915 loss of agent  2 :  0.21222630143165588
episode:  21 training step:  915 loss of agent  3 :  0.1476617306470871
Evaluation
env seed: 6 evaluation score at the training step:  915 :  {'adversary_0': -58.94335467618826, 'agent_0': 36.42331384489689, 'agent_1': 36.42331384489689, 'agent_2': 36.42331384489689}
episode:  21 training step:  916 loss of agent  0 :  0.04398110508918762
episode:  21 training step:  916 loss of agent  1 :  0.26432910561561584
episode:  21 training step:  916 loss of agent  2 :  0.21953833103179932
episode:  21 training step:  916 loss of agent  3 :  0.20674064755439758
episode:  21 training step:  917 loss of agent  0 :  0.043170202523469925
episode:  21 training step:  917 loss of agent  1 :  0.3611553907394409
episode:  21 training step:  917 loss of agent  2 :  0.21608340740203857
episode:  21 training step:  917 loss of agent  3 :  0.21538391709327698
episode:  21 training step:  918 loss of agent  0 :  0.03502999246120453
episode:  21 training step:  918 loss of agent  1 :  0.28316155076026917
episode:  21 training step:  918 loss of agent  2 :  0.23093198239803314
episode:  21 training step:  918 loss of agent  3 :  0.15766851603984833
episode:  21 training step:  919 loss of agent  0 :  0.04359215870499611
episode:  21 training step:  919 loss of agent  1 :  0.3069077730178833
episode:  21 training step:  919 loss of agent  2 :  0.16042131185531616
episode:  21 training step:  919 loss of agent  3 :  0.15177609026432037
episode:  21 training step:  920 loss of agent  0 :  0.0433645024895668
episode:  21 training step:  920 loss of agent  1 :  0.27028656005859375
episode:  21 training step:  920 loss of agent  2 :  0.165649875998497
episode:  21 training step:  920 loss of agent  3 :  0.09567241370677948
Evaluation
env seed: 6 evaluation score at the training step:  920 :  {'adversary_0': -30.69793095248081, 'agent_0': 4.315158279591773, 'agent_1': 4.315158279591773, 'agent_2': 4.315158279591773}
model saving.................................
episode:  21 training step:  921 loss of agent  0 :  0.04177386686205864
episode:  21 training step:  921 loss of agent  1 :  0.36561521887779236
episode:  21 training step:  921 loss of agent  2 :  0.15065236389636993
episode:  21 training step:  921 loss of agent  3 :  0.13732795417308807
episode:  21 training step:  922 loss of agent  0 :  0.0660230815410614
episode:  21 training step:  922 loss of agent  1 :  0.3722088932991028
episode:  21 training step:  922 loss of agent  2 :  0.14538681507110596
episode:  21 training step:  922 loss of agent  3 :  0.20172256231307983
episode:  21 training step:  923 loss of agent  0 :  0.06351338326931
episode:  21 training step:  923 loss of agent  1 :  0.22428902983665466
episode:  21 training step:  923 loss of agent  2 :  0.1477067917585373
episode:  21 training step:  923 loss of agent  3 :  0.1433611810207367
episode:  21 training step:  924 loss of agent  0 :  0.038819823414087296
episode:  21 training step:  924 loss of agent  1 :  0.27560243010520935
episode:  21 training step:  924 loss of agent  2 :  0.17627176642417908
episode:  21 training step:  924 loss of agent  3 :  0.17337778210639954
episode:  21 training step:  925 loss of agent  0 :  0.03309187665581703
episode:  21 training step:  925 loss of agent  1 :  0.2505733370780945
episode:  21 training step:  925 loss of agent  2 :  0.08671241253614426
episode:  21 training step:  925 loss of agent  3 :  0.11623534560203552
Evaluation
env seed: 6 evaluation score at the training step:  925 :  {'adversary_0': -34.993339576326555, 'agent_0': 11.17166860734611, 'agent_1': 11.17166860734611, 'agent_2': 11.17166860734611}
episode:  21 training step:  926 loss of agent  0 :  0.07574783265590668
episode:  21 training step:  926 loss of agent  1 :  0.5574009418487549
episode:  21 training step:  926 loss of agent  2 :  0.19061003625392914
episode:  21 training step:  926 loss of agent  3 :  0.1060946062207222
episode:  21 training step:  927 loss of agent  0 :  0.05509406700730324
episode:  21 training step:  927 loss of agent  1 :  0.29267749190330505
episode:  21 training step:  927 loss of agent  2 :  0.1252267211675644
episode:  21 training step:  927 loss of agent  3 :  0.2709030508995056
episode:  21 training step:  928 loss of agent  0 :  0.04946771636605263
episode:  21 training step:  928 loss of agent  1 :  0.23703040182590485
episode:  21 training step:  928 loss of agent  2 :  0.2375124990940094
episode:  21 training step:  928 loss of agent  3 :  0.13697312772274017
episode:  21 training step:  929 loss of agent  0 :  0.055950429290533066
episode:  21 training step:  929 loss of agent  1 :  0.37966281175613403
episode:  21 training step:  929 loss of agent  2 :  0.15772025287151337
episode:  21 training step:  929 loss of agent  3 :  0.12081769853830338
episode:  21 training step:  930 loss of agent  0 :  0.08769605308771133
episode:  21 training step:  930 loss of agent  1 :  0.4542258083820343
episode:  21 training step:  930 loss of agent  2 :  0.15193456411361694
episode:  21 training step:  930 loss of agent  3 :  0.14738841354846954
Evaluation
env seed: 6 evaluation score at the training step:  930 :  {'adversary_0': -35.520206663703384, 'agent_0': 5.538318075940433, 'agent_1': 5.538318075940433, 'agent_2': 5.538318075940433}
model saving.................................
episode:  21 training step:  931 loss of agent  0 :  0.04542113468050957
episode:  21 training step:  931 loss of agent  1 :  0.4278959333896637
episode:  21 training step:  931 loss of agent  2 :  0.1886102706193924
episode:  21 training step:  931 loss of agent  3 :  0.2330804318189621
episode:  21 training step:  932 loss of agent  0 :  0.046750202775001526
episode:  21 training step:  932 loss of agent  1 :  0.2985260486602783
episode:  21 training step:  932 loss of agent  2 :  0.19009634852409363
episode:  21 training step:  932 loss of agent  3 :  0.06946943700313568
episode:  21 training step:  933 loss of agent  0 :  0.04631292074918747
episode:  21 training step:  933 loss of agent  1 :  0.22463828325271606
episode:  21 training step:  933 loss of agent  2 :  0.29544663429260254
episode:  21 training step:  933 loss of agent  3 :  0.07551666349172592
episode 21 terminated at 1075
epoch: 2
episode:  21 training step:  934 loss of agent  0 :  0.0321996845304966
episode:  21 training step:  934 loss of agent  1 :  0.23823358118534088
episode:  21 training step:  934 loss of agent  2 :  0.21089228987693787
episode:  21 training step:  934 loss of agent  3 :  0.13211549818515778
episode:  21 training step:  935 loss of agent  0 :  0.07704108208417892
episode:  21 training step:  935 loss of agent  1 :  0.2334052473306656
episode:  21 training step:  935 loss of agent  2 :  0.1649184226989746
episode:  21 training step:  935 loss of agent  3 :  0.11633187532424927
Evaluation
env seed: 6 evaluation score at the training step:  935 :  {'adversary_0': -34.838967872375065, 'agent_0': 5.248885853241895, 'agent_1': 5.248885853241895, 'agent_2': 5.248885853241895}
episode:  21 training step:  936 loss of agent  0 :  0.03825598955154419
episode:  21 training step:  936 loss of agent  1 :  0.37730270624160767
episode:  21 training step:  936 loss of agent  2 :  0.1822352260351181
episode:  21 training step:  936 loss of agent  3 :  0.10059584677219391
episode:  21 training step:  937 loss of agent  0 :  0.04830881953239441
episode:  21 training step:  937 loss of agent  1 :  0.23431910574436188
episode:  21 training step:  937 loss of agent  2 :  0.17110185325145721
episode:  21 training step:  937 loss of agent  3 :  0.17233838140964508
episode:  21 training step:  938 loss of agent  0 :  0.05097071826457977
episode:  21 training step:  938 loss of agent  1 :  0.4381553530693054
episode:  21 training step:  938 loss of agent  2 :  0.19676978886127472
episode:  21 training step:  938 loss of agent  3 :  0.1302081197500229
episode:  21 training step:  939 loss of agent  0 :  0.033445604145526886
episode:  21 training step:  939 loss of agent  1 :  0.3346342146396637
episode:  21 training step:  939 loss of agent  2 :  0.14282912015914917
episode:  21 training step:  939 loss of agent  3 :  0.13108782470226288
episode:  21 training step:  940 loss of agent  0 :  0.034962307661771774
episode:  21 training step:  940 loss of agent  1 :  0.3192709982395172
episode:  21 training step:  940 loss of agent  2 :  0.11812658607959747
episode:  21 training step:  940 loss of agent  3 :  0.1745469868183136
Evaluation
env seed: 6 evaluation score at the training step:  940 :  {'adversary_0': -32.10677586853347, 'agent_0': 2.1856352108020136, 'agent_1': 2.1856352108020136, 'agent_2': 2.1856352108020136}
model saving.................................
episode:  21 training step:  941 loss of agent  0 :  0.03037724457681179
episode:  21 training step:  941 loss of agent  1 :  0.262449711561203
episode:  21 training step:  941 loss of agent  2 :  0.16452203691005707
episode:  21 training step:  941 loss of agent  3 :  0.15377765893936157
episode:  21 training step:  942 loss of agent  0 :  0.038495983928442
episode:  21 training step:  942 loss of agent  1 :  0.31262344121932983
episode:  21 training step:  942 loss of agent  2 :  0.14719951152801514
episode:  21 training step:  942 loss of agent  3 :  0.08744806796312332
episode:  21 training step:  943 loss of agent  0 :  0.047367390245199203
episode:  21 training step:  943 loss of agent  1 :  0.3537027835845947
episode:  21 training step:  943 loss of agent  2 :  0.14598995447158813
episode:  21 training step:  943 loss of agent  3 :  0.2137851119041443
episode:  21 training step:  944 loss of agent  0 :  0.05033114552497864
episode:  21 training step:  944 loss of agent  1 :  0.4009372591972351
episode:  21 training step:  944 loss of agent  2 :  0.1964450478553772
episode:  21 training step:  944 loss of agent  3 :  0.18132005631923676
episode:  21 training step:  945 loss of agent  0 :  0.07048779726028442
episode:  21 training step:  945 loss of agent  1 :  0.3846140205860138
episode:  21 training step:  945 loss of agent  2 :  0.25555574893951416
episode:  21 training step:  945 loss of agent  3 :  0.23008127510547638
Evaluation
env seed: 6 evaluation score at the training step:  945 :  {'adversary_0': -31.71173855639222, 'agent_0': 1.9877480950524231, 'agent_1': 1.9877480950524231, 'agent_2': 1.9877480950524231}
episode:  21 training step:  946 loss of agent  0 :  0.05996057018637657
episode:  21 training step:  946 loss of agent  1 :  0.30822253227233887
episode:  21 training step:  946 loss of agent  2 :  0.14345180988311768
episode:  21 training step:  946 loss of agent  3 :  0.16328760981559753
episode:  21 training step:  947 loss of agent  0 :  0.04214376211166382
episode:  21 training step:  947 loss of agent  1 :  0.44230449199676514
episode:  21 training step:  947 loss of agent  2 :  0.19735495746135712
episode:  21 training step:  947 loss of agent  3 :  0.07763343304395676
episode:  21 training step:  948 loss of agent  0 :  0.025543492287397385
episode:  21 training step:  948 loss of agent  1 :  0.19871927797794342
episode:  21 training step:  948 loss of agent  2 :  0.15218386054039001
episode:  21 training step:  948 loss of agent  3 :  0.14977779984474182
episode:  21 training step:  949 loss of agent  0 :  0.025939738377928734
episode:  21 training step:  949 loss of agent  1 :  0.3971974849700928
episode:  21 training step:  949 loss of agent  2 :  0.15504387021064758
episode:  21 training step:  949 loss of agent  3 :  0.20790305733680725
episode:  21 training step:  950 loss of agent  0 :  0.04830825328826904
episode:  21 training step:  950 loss of agent  1 :  0.23917731642723083
episode:  21 training step:  950 loss of agent  2 :  0.1709030419588089
episode:  21 training step:  950 loss of agent  3 :  0.16831842064857483
Evaluation
env seed: 6 evaluation score at the training step:  950 :  {'adversary_0': -28.50712459969622, 'agent_0': -1.3699025802895934, 'agent_1': -1.3699025802895934, 'agent_2': -1.3699025802895934}
model saving.................................
episode:  21 training step:  951 loss of agent  0 :  0.020128441974520683
episode:  21 training step:  951 loss of agent  1 :  0.3423290550708771
episode:  21 training step:  951 loss of agent  2 :  0.21331891417503357
episode:  21 training step:  951 loss of agent  3 :  0.2099367082118988
episode:  21 training step:  952 loss of agent  0 :  0.05098874866962433
episode:  21 training step:  952 loss of agent  1 :  0.3661116063594818
episode:  21 training step:  952 loss of agent  2 :  0.10992849618196487
episode:  21 training step:  952 loss of agent  3 :  0.09439649432897568
episode:  21 training step:  953 loss of agent  0 :  0.0544908381998539
episode:  21 training step:  953 loss of agent  1 :  0.4072200357913971
episode:  21 training step:  953 loss of agent  2 :  0.16830745339393616
episode:  21 training step:  953 loss of agent  3 :  0.16543103754520416
episode:  21 training step:  954 loss of agent  0 :  0.05472616106271744
episode:  21 training step:  954 loss of agent  1 :  0.44769877195358276
episode:  21 training step:  954 loss of agent  2 :  0.14093635976314545
episode:  21 training step:  954 loss of agent  3 :  0.16815412044525146
episode:  21 training step:  955 loss of agent  0 :  0.0383688285946846
episode:  21 training step:  955 loss of agent  1 :  0.4705946147441864
episode:  21 training step:  955 loss of agent  2 :  0.22124382853507996
episode:  21 training step:  955 loss of agent  3 :  0.17355842888355255
Evaluation
env seed: 6 evaluation score at the training step:  955 :  {'adversary_0': -28.50712459969622, 'agent_0': -1.234304728986831, 'agent_1': -1.234304728986831, 'agent_2': -1.234304728986831}
episode:  21 training step:  956 loss of agent  0 :  0.040844839066267014
episode:  21 training step:  956 loss of agent  1 :  0.42919057607650757
episode:  21 training step:  956 loss of agent  2 :  0.21296803653240204
episode:  21 training step:  956 loss of agent  3 :  0.20380686223506927
episode:  21 training step:  957 loss of agent  0 :  0.03440280631184578
episode:  21 training step:  957 loss of agent  1 :  0.30379483103752136
episode:  21 training step:  957 loss of agent  2 :  0.1893872767686844
episode:  21 training step:  957 loss of agent  3 :  0.1886110156774521
episode 21 terminated at 1100
episode: 22
epoch: 1
episode:  22 training step:  958 loss of agent  0 :  0.04951148480176926
episode:  22 training step:  958 loss of agent  1 :  0.22312459349632263
episode:  22 training step:  958 loss of agent  2 :  0.17065128684043884
episode:  22 training step:  958 loss of agent  3 :  0.08089680224657059
episode:  22 training step:  959 loss of agent  0 :  0.024092812091112137
episode:  22 training step:  959 loss of agent  1 :  0.40485572814941406
episode:  22 training step:  959 loss of agent  2 :  0.22633813321590424
episode:  22 training step:  959 loss of agent  3 :  0.22804118692874908
episode:  22 training step:  960 loss of agent  0 :  0.03333942964673042
episode:  22 training step:  960 loss of agent  1 :  0.49366217851638794
episode:  22 training step:  960 loss of agent  2 :  0.25073131918907166
episode:  22 training step:  960 loss of agent  3 :  0.12473173439502716
Evaluation
env seed: 6 evaluation score at the training step:  960 :  {'adversary_0': -34.62820520016358, 'agent_0': 7.631314313587568, 'agent_1': 7.631314313587568, 'agent_2': 7.631314313587568}
model saving.................................
episode:  22 training step:  961 loss of agent  0 :  0.06816580891609192
episode:  22 training step:  961 loss of agent  1 :  0.30933570861816406
episode:  22 training step:  961 loss of agent  2 :  0.1353616863489151
episode:  22 training step:  961 loss of agent  3 :  0.16877909004688263
episode:  22 training step:  962 loss of agent  0 :  0.02922402322292328
episode:  22 training step:  962 loss of agent  1 :  0.21392637491226196
episode:  22 training step:  962 loss of agent  2 :  0.27889636158943176
episode:  22 training step:  962 loss of agent  3 :  0.17224344611167908
episode:  22 training step:  963 loss of agent  0 :  0.04249315336346626
episode:  22 training step:  963 loss of agent  1 :  0.33334818482398987
episode:  22 training step:  963 loss of agent  2 :  0.20890586078166962
episode:  22 training step:  963 loss of agent  3 :  0.15198630094528198
episode:  22 training step:  964 loss of agent  0 :  0.03322737663984299
episode:  22 training step:  964 loss of agent  1 :  0.3717835545539856
episode:  22 training step:  964 loss of agent  2 :  0.0984453558921814
episode:  22 training step:  964 loss of agent  3 :  0.16151778399944305
episode:  22 training step:  965 loss of agent  0 :  0.02939578890800476
episode:  22 training step:  965 loss of agent  1 :  0.28837165236473083
episode:  22 training step:  965 loss of agent  2 :  0.16075530648231506
episode:  22 training step:  965 loss of agent  3 :  0.10479459166526794
Evaluation
env seed: 6 evaluation score at the training step:  965 :  {'adversary_0': -35.64937597325993, 'agent_0': 9.319934958974967, 'agent_1': 9.319934958974967, 'agent_2': 9.319934958974967}
episode:  22 training step:  966 loss of agent  0 :  0.04240765422582626
episode:  22 training step:  966 loss of agent  1 :  0.2470247447490692
episode:  22 training step:  966 loss of agent  2 :  0.1256602257490158
episode:  22 training step:  966 loss of agent  3 :  0.15630891919136047
episode:  22 training step:  967 loss of agent  0 :  0.050618965178728104
episode:  22 training step:  967 loss of agent  1 :  0.20878785848617554
episode:  22 training step:  967 loss of agent  2 :  0.1902780830860138
episode:  22 training step:  967 loss of agent  3 :  0.16721950471401215
episode:  22 training step:  968 loss of agent  0 :  0.08024100959300995
episode:  22 training step:  968 loss of agent  1 :  0.38548609614372253
episode:  22 training step:  968 loss of agent  2 :  0.2927530109882355
episode:  22 training step:  968 loss of agent  3 :  0.18236853182315826
episode:  22 training step:  969 loss of agent  0 :  0.07613461464643478
episode:  22 training step:  969 loss of agent  1 :  0.18811292946338654
episode:  22 training step:  969 loss of agent  2 :  0.14282764494419098
episode:  22 training step:  969 loss of agent  3 :  0.13958942890167236
episode:  22 training step:  970 loss of agent  0 :  0.05090758576989174
episode:  22 training step:  970 loss of agent  1 :  0.37458598613739014
episode:  22 training step:  970 loss of agent  2 :  0.07544726133346558
episode:  22 training step:  970 loss of agent  3 :  0.07691659778356552
Evaluation
env seed: 6 evaluation score at the training step:  970 :  {'adversary_0': -35.181174424534866, 'agent_0': 9.21162703794663, 'agent_1': 9.21162703794663, 'agent_2': 9.21162703794663}
model saving.................................
episode:  22 training step:  971 loss of agent  0 :  0.04027383401989937
episode:  22 training step:  971 loss of agent  1 :  0.35626938939094543
episode:  22 training step:  971 loss of agent  2 :  0.07091651856899261
episode:  22 training step:  971 loss of agent  3 :  0.2219337522983551
episode:  22 training step:  972 loss of agent  0 :  0.039425529539585114
episode:  22 training step:  972 loss of agent  1 :  0.513299286365509
episode:  22 training step:  972 loss of agent  2 :  0.1542692631483078
episode:  22 training step:  972 loss of agent  3 :  0.12426862865686417
episode:  22 training step:  973 loss of agent  0 :  0.047768525779247284
episode:  22 training step:  973 loss of agent  1 :  0.3238910436630249
episode:  22 training step:  973 loss of agent  2 :  0.142602801322937
episode:  22 training step:  973 loss of agent  3 :  0.20332536101341248
episode:  22 training step:  974 loss of agent  0 :  0.05463825538754463
episode:  22 training step:  974 loss of agent  1 :  0.4115062355995178
episode:  22 training step:  974 loss of agent  2 :  0.21130600571632385
episode:  22 training step:  974 loss of agent  3 :  0.08841818571090698
episode:  22 training step:  975 loss of agent  0 :  0.07317332178354263
episode:  22 training step:  975 loss of agent  1 :  0.28497540950775146
episode:  22 training step:  975 loss of agent  2 :  0.1610681563615799
episode:  22 training step:  975 loss of agent  3 :  0.10244866460561752
Evaluation
env seed: 6 evaluation score at the training step:  975 :  {'adversary_0': -35.39162687601225, 'agent_0': 9.120183606876818, 'agent_1': 9.120183606876818, 'agent_2': 9.120183606876818}
episode:  22 training step:  976 loss of agent  0 :  0.044011108577251434
episode:  22 training step:  976 loss of agent  1 :  0.3039606213569641
episode:  22 training step:  976 loss of agent  2 :  0.19751869142055511
episode:  22 training step:  976 loss of agent  3 :  0.18254783749580383
episode:  22 training step:  977 loss of agent  0 :  0.0473032146692276
episode:  22 training step:  977 loss of agent  1 :  0.18945974111557007
episode:  22 training step:  977 loss of agent  2 :  0.276705801486969
episode:  22 training step:  977 loss of agent  3 :  0.16492252051830292
episode:  22 training step:  978 loss of agent  0 :  0.05313538759946823
episode:  22 training step:  978 loss of agent  1 :  0.26153406500816345
episode:  22 training step:  978 loss of agent  2 :  0.20970100164413452
episode:  22 training step:  978 loss of agent  3 :  0.13832876086235046
episode:  22 training step:  979 loss of agent  0 :  0.060433998703956604
episode:  22 training step:  979 loss of agent  1 :  0.3114277124404907
episode:  22 training step:  979 loss of agent  2 :  0.10244965553283691
episode:  22 training step:  979 loss of agent  3 :  0.059195347130298615
episode:  22 training step:  980 loss of agent  0 :  0.05499410256743431
episode:  22 training step:  980 loss of agent  1 :  0.27906107902526855
episode:  22 training step:  980 loss of agent  2 :  0.19554975628852844
episode:  22 training step:  980 loss of agent  3 :  0.1395992785692215
Evaluation
env seed: 6 evaluation score at the training step:  980 :  {'adversary_0': -35.5842937089342, 'agent_0': 8.549178287434488, 'agent_1': 8.549178287434488, 'agent_2': 8.549178287434488}
model saving.................................
episode:  22 training step:  981 loss of agent  0 :  0.04035711660981178
episode:  22 training step:  981 loss of agent  1 :  0.37808099389076233
episode:  22 training step:  981 loss of agent  2 :  0.14167261123657227
episode:  22 training step:  981 loss of agent  3 :  0.07849960774183273
episode 22 terminated at 1125
epoch: 2
episode:  22 training step:  982 loss of agent  0 :  0.055174827575683594
episode:  22 training step:  982 loss of agent  1 :  0.39604634046554565
episode:  22 training step:  982 loss of agent  2 :  0.1781008541584015
episode:  22 training step:  982 loss of agent  3 :  0.14705203473567963
episode:  22 training step:  983 loss of agent  0 :  0.08183997869491577
episode:  22 training step:  983 loss of agent  1 :  0.32747289538383484
episode:  22 training step:  983 loss of agent  2 :  0.19247421622276306
episode:  22 training step:  983 loss of agent  3 :  0.12721744179725647
episode:  22 training step:  984 loss of agent  0 :  0.04914006218314171
episode:  22 training step:  984 loss of agent  1 :  0.1785879135131836
episode:  22 training step:  984 loss of agent  2 :  0.2062215656042099
episode:  22 training step:  984 loss of agent  3 :  0.10903320461511612
episode:  22 training step:  985 loss of agent  0 :  0.04739362746477127
episode:  22 training step:  985 loss of agent  1 :  0.34547537565231323
episode:  22 training step:  985 loss of agent  2 :  0.2315628081560135
episode:  22 training step:  985 loss of agent  3 :  0.10858801007270813
Evaluation
env seed: 6 evaluation score at the training step:  985 :  {'adversary_0': -35.66347916690637, 'agent_0': 13.35870007908714, 'agent_1': 13.35870007908714, 'agent_2': 13.35870007908714}
episode:  22 training step:  986 loss of agent  0 :  0.06933285295963287
episode:  22 training step:  986 loss of agent  1 :  0.3538031578063965
episode:  22 training step:  986 loss of agent  2 :  0.1562431901693344
episode:  22 training step:  986 loss of agent  3 :  0.1682327687740326
episode:  22 training step:  987 loss of agent  0 :  0.05592454969882965
episode:  22 training step:  987 loss of agent  1 :  0.3364231586456299
episode:  22 training step:  987 loss of agent  2 :  0.15372489392757416
episode:  22 training step:  987 loss of agent  3 :  0.12570607662200928
episode:  22 training step:  988 loss of agent  0 :  0.04713520407676697
episode:  22 training step:  988 loss of agent  1 :  0.351521760225296
episode:  22 training step:  988 loss of agent  2 :  0.20362558960914612
episode:  22 training step:  988 loss of agent  3 :  0.14083491265773773
episode:  22 training step:  989 loss of agent  0 :  0.09136153012514114
episode:  22 training step:  989 loss of agent  1 :  0.3679780662059784
episode:  22 training step:  989 loss of agent  2 :  0.05868997424840927
episode:  22 training step:  989 loss of agent  3 :  0.09967571496963501
episode:  22 training step:  990 loss of agent  0 :  0.03793361037969589
episode:  22 training step:  990 loss of agent  1 :  0.28682199120521545
episode:  22 training step:  990 loss of agent  2 :  0.18585941195487976
episode:  22 training step:  990 loss of agent  3 :  0.12994568049907684
Evaluation
env seed: 6 evaluation score at the training step:  990 :  {'adversary_0': -40.80598706213658, 'agent_0': 10.537054786825923, 'agent_1': 10.537054786825923, 'agent_2': 10.537054786825923}
model saving.................................
episode:  22 training step:  991 loss of agent  0 :  0.05138484388589859
episode:  22 training step:  991 loss of agent  1 :  0.3805278241634369
episode:  22 training step:  991 loss of agent  2 :  0.12336105108261108
episode:  22 training step:  991 loss of agent  3 :  0.1847284436225891
episode:  22 training step:  992 loss of agent  0 :  0.043417997658252716
episode:  22 training step:  992 loss of agent  1 :  0.31592807173728943
episode:  22 training step:  992 loss of agent  2 :  0.2901011109352112
episode:  22 training step:  992 loss of agent  3 :  0.35278546810150146
episode:  22 training step:  993 loss of agent  0 :  0.04494469612836838
episode:  22 training step:  993 loss of agent  1 :  0.33105185627937317
episode:  22 training step:  993 loss of agent  2 :  0.1580272614955902
episode:  22 training step:  993 loss of agent  3 :  0.14379119873046875
episode:  22 training step:  994 loss of agent  0 :  0.0545501671731472
episode:  22 training step:  994 loss of agent  1 :  0.32976198196411133
episode:  22 training step:  994 loss of agent  2 :  0.1788931041955948
episode:  22 training step:  994 loss of agent  3 :  0.16968995332717896
episode:  22 training step:  995 loss of agent  0 :  0.037571344524621964
episode:  22 training step:  995 loss of agent  1 :  0.34223103523254395
episode:  22 training step:  995 loss of agent  2 :  0.1800546944141388
episode:  22 training step:  995 loss of agent  3 :  0.17850500345230103
Evaluation
env seed: 6 evaluation score at the training step:  995 :  {'adversary_0': -59.358734229024, 'agent_0': 25.654998163194637, 'agent_1': 25.654998163194637, 'agent_2': 25.654998163194637}
episode:  22 training step:  996 loss of agent  0 :  0.049485452473163605
episode:  22 training step:  996 loss of agent  1 :  0.34781360626220703
episode:  22 training step:  996 loss of agent  2 :  0.18692417442798615
episode:  22 training step:  996 loss of agent  3 :  0.22220231592655182
episode:  22 training step:  997 loss of agent  0 :  0.06444135308265686
episode:  22 training step:  997 loss of agent  1 :  0.3831440806388855
episode:  22 training step:  997 loss of agent  2 :  0.15369045734405518
episode:  22 training step:  997 loss of agent  3 :  0.17270871996879578
episode:  22 training step:  998 loss of agent  0 :  0.06441248208284378
episode:  22 training step:  998 loss of agent  1 :  0.2767237722873688
episode:  22 training step:  998 loss of agent  2 :  0.265707790851593
episode:  22 training step:  998 loss of agent  3 :  0.2369086742401123
episode:  22 training step:  999 loss of agent  0 :  0.05537804588675499
episode:  22 training step:  999 loss of agent  1 :  0.23834604024887085
episode:  22 training step:  999 loss of agent  2 :  0.21865373849868774
episode:  22 training step:  999 loss of agent  3 :  0.14082904160022736
episode:  22 training step:  1000 loss of agent  0 :  0.04756639897823334
episode:  22 training step:  1000 loss of agent  1 :  0.44019031524658203
episode:  22 training step:  1000 loss of agent  2 :  0.14031118154525757
episode:  22 training step:  1000 loss of agent  3 :  0.14576290547847748
Evaluation
env seed: 6 evaluation score at the training step:  1000 :  {'adversary_0': -24.748608377635314, 'agent_0': -7.254839733074841, 'agent_1': -7.254839733074841, 'agent_2': -7.254839733074841}
model saving.................................
episode:  22 training step:  1001 loss of agent  0 :  0.04808763414621353
episode:  22 training step:  1001 loss of agent  1 :  0.362369179725647
episode:  22 training step:  1001 loss of agent  2 :  0.10545068979263306
episode:  22 training step:  1001 loss of agent  3 :  0.1790405809879303
episode:  22 training step:  1002 loss of agent  0 :  0.04871563985943794
episode:  22 training step:  1002 loss of agent  1 :  0.39912891387939453
episode:  22 training step:  1002 loss of agent  2 :  0.13043475151062012
episode:  22 training step:  1002 loss of agent  3 :  0.18170255422592163
episode:  22 training step:  1003 loss of agent  0 :  0.046865880489349365
episode:  22 training step:  1003 loss of agent  1 :  0.3007638454437256
episode:  22 training step:  1003 loss of agent  2 :  0.07604944705963135
episode:  22 training step:  1003 loss of agent  3 :  0.15336549282073975
episode:  22 training step:  1004 loss of agent  0 :  0.04056616872549057
episode:  22 training step:  1004 loss of agent  1 :  0.3801012933254242
episode:  22 training step:  1004 loss of agent  2 :  0.16657237708568573
episode:  22 training step:  1004 loss of agent  3 :  0.18429994583129883
episode:  22 training step:  1005 loss of agent  0 :  0.06680306792259216
episode:  22 training step:  1005 loss of agent  1 :  0.30212289094924927
episode:  22 training step:  1005 loss of agent  2 :  0.17397823929786682
episode:  22 training step:  1005 loss of agent  3 :  0.23225143551826477
Evaluation
env seed: 6 evaluation score at the training step:  1005 :  {'adversary_0': -27.6685443441536, 'agent_0': -5.500287546166349, 'agent_1': -5.500287546166349, 'agent_2': -5.500287546166349}
episode 22 terminated at 1150
episode: 23
epoch: 1
episode:  23 training step:  1006 loss of agent  0 :  0.04950522631406784
episode:  23 training step:  1006 loss of agent  1 :  0.33761826157569885
episode:  23 training step:  1006 loss of agent  2 :  0.19528351724147797
episode:  23 training step:  1006 loss of agent  3 :  0.1828063428401947
episode:  23 training step:  1007 loss of agent  0 :  0.043911609798669815
episode:  23 training step:  1007 loss of agent  1 :  0.35739678144454956
episode:  23 training step:  1007 loss of agent  2 :  0.30226004123687744
episode:  23 training step:  1007 loss of agent  3 :  0.19566063582897186
episode:  23 training step:  1008 loss of agent  0 :  0.05430106073617935
episode:  23 training step:  1008 loss of agent  1 :  0.5366671085357666
episode:  23 training step:  1008 loss of agent  2 :  0.1801145374774933
episode:  23 training step:  1008 loss of agent  3 :  0.09407756477594376
episode:  23 training step:  1009 loss of agent  0 :  0.04561064764857292
episode:  23 training step:  1009 loss of agent  1 :  0.15836535394191742
episode:  23 training step:  1009 loss of agent  2 :  0.18131597340106964
episode:  23 training step:  1009 loss of agent  3 :  0.17142590880393982
episode:  23 training step:  1010 loss of agent  0 :  0.05300407484173775
episode:  23 training step:  1010 loss of agent  1 :  0.2911342680454254
episode:  23 training step:  1010 loss of agent  2 :  0.28680336475372314
episode:  23 training step:  1010 loss of agent  3 :  0.15266960859298706
Evaluation
env seed: 6 evaluation score at the training step:  1010 :  {'adversary_0': -35.45923061596501, 'agent_0': 6.354472973422171, 'agent_1': 6.354472973422171, 'agent_2': 6.354472973422171}
model saving.................................
episode:  23 training step:  1011 loss of agent  0 :  0.035189419984817505
episode:  23 training step:  1011 loss of agent  1 :  0.27964356541633606
episode:  23 training step:  1011 loss of agent  2 :  0.20464174449443817
episode:  23 training step:  1011 loss of agent  3 :  0.0885072648525238
episode:  23 training step:  1012 loss of agent  0 :  0.05586971342563629
episode:  23 training step:  1012 loss of agent  1 :  0.35105401277542114
episode:  23 training step:  1012 loss of agent  2 :  0.10415130853652954
episode:  23 training step:  1012 loss of agent  3 :  0.12030443549156189
episode:  23 training step:  1013 loss of agent  0 :  0.05414712056517601
episode:  23 training step:  1013 loss of agent  1 :  0.3402351438999176
episode:  23 training step:  1013 loss of agent  2 :  0.24752306938171387
episode:  23 training step:  1013 loss of agent  3 :  0.2198425978422165
episode:  23 training step:  1014 loss of agent  0 :  0.06737710535526276
episode:  23 training step:  1014 loss of agent  1 :  0.2219763994216919
episode:  23 training step:  1014 loss of agent  2 :  0.14302882552146912
episode:  23 training step:  1014 loss of agent  3 :  0.2785545587539673
episode:  23 training step:  1015 loss of agent  0 :  0.07695655524730682
episode:  23 training step:  1015 loss of agent  1 :  0.31470561027526855
episode:  23 training step:  1015 loss of agent  2 :  0.18417257070541382
episode:  23 training step:  1015 loss of agent  3 :  0.12972700595855713
Evaluation
env seed: 6 evaluation score at the training step:  1015 :  {'adversary_0': -35.541692179554374, 'agent_0': 8.070017461041743, 'agent_1': 8.070017461041743, 'agent_2': 8.070017461041743}
episode:  23 training step:  1016 loss of agent  0 :  0.0721215158700943
episode:  23 training step:  1016 loss of agent  1 :  0.32013824582099915
episode:  23 training step:  1016 loss of agent  2 :  0.15209369361400604
episode:  23 training step:  1016 loss of agent  3 :  0.2039310783147812
episode:  23 training step:  1017 loss of agent  0 :  0.056247785687446594
episode:  23 training step:  1017 loss of agent  1 :  0.4383101165294647
episode:  23 training step:  1017 loss of agent  2 :  0.11952923238277435
episode:  23 training step:  1017 loss of agent  3 :  0.19594229757785797
episode:  23 training step:  1018 loss of agent  0 :  0.047097086906433105
episode:  23 training step:  1018 loss of agent  1 :  0.3276181221008301
episode:  23 training step:  1018 loss of agent  2 :  0.16790194809436798
episode:  23 training step:  1018 loss of agent  3 :  0.16209089756011963
episode:  23 training step:  1019 loss of agent  0 :  0.030068064108490944
episode:  23 training step:  1019 loss of agent  1 :  0.3425942659378052
episode:  23 training step:  1019 loss of agent  2 :  0.18978114426136017
episode:  23 training step:  1019 loss of agent  3 :  0.15899792313575745
episode:  23 training step:  1020 loss of agent  0 :  0.07627445459365845
episode:  23 training step:  1020 loss of agent  1 :  0.22349318861961365
episode:  23 training step:  1020 loss of agent  2 :  0.11290547996759415
episode:  23 training step:  1020 loss of agent  3 :  0.1333061158657074
Evaluation
env seed: 6 evaluation score at the training step:  1020 :  {'adversary_0': -61.78154877247446, 'agent_0': 37.416169791801856, 'agent_1': 37.416169791801856, 'agent_2': 37.416169791801856}
model saving.................................
episode:  23 training step:  1021 loss of agent  0 :  0.06197093427181244
episode:  23 training step:  1021 loss of agent  1 :  0.32460683584213257
episode:  23 training step:  1021 loss of agent  2 :  0.2197681963443756
episode:  23 training step:  1021 loss of agent  3 :  0.23164281249046326
episode:  23 training step:  1022 loss of agent  0 :  0.048172589391469955
episode:  23 training step:  1022 loss of agent  1 :  0.4241565763950348
episode:  23 training step:  1022 loss of agent  2 :  0.23659300804138184
episode:  23 training step:  1022 loss of agent  3 :  0.19544056057929993
episode:  23 training step:  1023 loss of agent  0 :  0.06094085052609444
episode:  23 training step:  1023 loss of agent  1 :  0.3484945595264435
episode:  23 training step:  1023 loss of agent  2 :  0.23040907084941864
episode:  23 training step:  1023 loss of agent  3 :  0.18900462985038757
episode:  23 training step:  1024 loss of agent  0 :  0.0718362033367157
episode:  23 training step:  1024 loss of agent  1 :  0.369072824716568
episode:  23 training step:  1024 loss of agent  2 :  0.23273219168186188
episode:  23 training step:  1024 loss of agent  3 :  0.23081977665424347
episode:  23 training step:  1025 loss of agent  0 :  0.03851604834198952
episode:  23 training step:  1025 loss of agent  1 :  0.36463025212287903
episode:  23 training step:  1025 loss of agent  2 :  0.19544941186904907
episode:  23 training step:  1025 loss of agent  3 :  0.17918480932712555
Evaluation
env seed: 6 evaluation score at the training step:  1025 :  {'adversary_0': -70.07621003503618, 'agent_0': 42.00225352273531, 'agent_1': 42.00225352273531, 'agent_2': 42.00225352273531}
episode:  23 training step:  1026 loss of agent  0 :  0.07788264006376266
episode:  23 training step:  1026 loss of agent  1 :  0.34285467863082886
episode:  23 training step:  1026 loss of agent  2 :  0.18347743153572083
episode:  23 training step:  1026 loss of agent  3 :  0.18238672614097595
episode:  23 training step:  1027 loss of agent  0 :  0.06011796370148659
episode:  23 training step:  1027 loss of agent  1 :  0.34018996357917786
episode:  23 training step:  1027 loss of agent  2 :  0.27802330255508423
episode:  23 training step:  1027 loss of agent  3 :  0.20351865887641907
episode:  23 training step:  1028 loss of agent  0 :  0.07187927514314651
episode:  23 training step:  1028 loss of agent  1 :  0.25064966082572937
episode:  23 training step:  1028 loss of agent  2 :  0.1636209487915039
episode:  23 training step:  1028 loss of agent  3 :  0.2156260758638382
episode:  23 training step:  1029 loss of agent  0 :  0.05442815274000168
episode:  23 training step:  1029 loss of agent  1 :  0.29390472173690796
episode:  23 training step:  1029 loss of agent  2 :  0.1302943229675293
episode:  23 training step:  1029 loss of agent  3 :  0.10027861595153809
episode 23 terminated at 1175
epoch: 2
episode:  23 training step:  1030 loss of agent  0 :  0.05728868022561073
episode:  23 training step:  1030 loss of agent  1 :  0.24839168787002563
episode:  23 training step:  1030 loss of agent  2 :  0.20867779850959778
episode:  23 training step:  1030 loss of agent  3 :  0.2561578154563904
Evaluation
env seed: 6 evaluation score at the training step:  1030 :  {'adversary_0': -69.84757138311426, 'agent_0': 39.62916816047436, 'agent_1': 39.62916816047436, 'agent_2': 39.62916816047436}
model saving.................................
episode:  23 training step:  1031 loss of agent  0 :  0.08019036799669266
episode:  23 training step:  1031 loss of agent  1 :  0.2816360890865326
episode:  23 training step:  1031 loss of agent  2 :  0.1562119871377945
episode:  23 training step:  1031 loss of agent  3 :  0.15248586237430573
episode:  23 training step:  1032 loss of agent  0 :  0.04937223717570305
episode:  23 training step:  1032 loss of agent  1 :  0.2788456380367279
episode:  23 training step:  1032 loss of agent  2 :  0.12831972539424896
episode:  23 training step:  1032 loss of agent  3 :  0.23259451985359192
episode:  23 training step:  1033 loss of agent  0 :  0.03891688957810402
episode:  23 training step:  1033 loss of agent  1 :  0.4421365559101105
episode:  23 training step:  1033 loss of agent  2 :  0.2917650043964386
episode:  23 training step:  1033 loss of agent  3 :  0.19445335865020752
episode:  23 training step:  1034 loss of agent  0 :  0.07889493554830551
episode:  23 training step:  1034 loss of agent  1 :  0.28524330258369446
episode:  23 training step:  1034 loss of agent  2 :  0.1511431485414505
episode:  23 training step:  1034 loss of agent  3 :  0.19333121180534363
episode:  23 training step:  1035 loss of agent  0 :  0.057595014572143555
episode:  23 training step:  1035 loss of agent  1 :  0.4110087752342224
episode:  23 training step:  1035 loss of agent  2 :  0.15142598748207092
episode:  23 training step:  1035 loss of agent  3 :  0.18686842918395996
Evaluation
env seed: 6 evaluation score at the training step:  1035 :  {'adversary_0': -31.377732699887652, 'agent_0': 1.347118443321069, 'agent_1': 1.347118443321069, 'agent_2': 1.347118443321069}
episode:  23 training step:  1036 loss of agent  0 :  0.03931768983602524
episode:  23 training step:  1036 loss of agent  1 :  0.45626819133758545
episode:  23 training step:  1036 loss of agent  2 :  0.25730371475219727
episode:  23 training step:  1036 loss of agent  3 :  0.1249256506562233
episode:  23 training step:  1037 loss of agent  0 :  0.0716458335518837
episode:  23 training step:  1037 loss of agent  1 :  0.3210563361644745
episode:  23 training step:  1037 loss of agent  2 :  0.1855015754699707
episode:  23 training step:  1037 loss of agent  3 :  0.12088195979595184
episode:  23 training step:  1038 loss of agent  0 :  0.05825792998075485
episode:  23 training step:  1038 loss of agent  1 :  0.2743557095527649
episode:  23 training step:  1038 loss of agent  2 :  0.24407172203063965
episode:  23 training step:  1038 loss of agent  3 :  0.07578489929437637
episode:  23 training step:  1039 loss of agent  0 :  0.06106483191251755
episode:  23 training step:  1039 loss of agent  1 :  0.37397217750549316
episode:  23 training step:  1039 loss of agent  2 :  0.13111065328121185
episode:  23 training step:  1039 loss of agent  3 :  0.18527230620384216
episode:  23 training step:  1040 loss of agent  0 :  0.05239807069301605
episode:  23 training step:  1040 loss of agent  1 :  0.4358912706375122
episode:  23 training step:  1040 loss of agent  2 :  0.18321502208709717
episode:  23 training step:  1040 loss of agent  3 :  0.12147512286901474
Evaluation
env seed: 6 evaluation score at the training step:  1040 :  {'adversary_0': -26.937744642610898, 'agent_0': -2.9723435721234397, 'agent_1': -2.9723435721234397, 'agent_2': -2.9723435721234397}
model saving.................................
episode:  23 training step:  1041 loss of agent  0 :  0.04877098649740219
episode:  23 training step:  1041 loss of agent  1 :  0.32681095600128174
episode:  23 training step:  1041 loss of agent  2 :  0.17560763657093048
episode:  23 training step:  1041 loss of agent  3 :  0.26716282963752747
episode:  23 training step:  1042 loss of agent  0 :  0.06782655417919159
episode:  23 training step:  1042 loss of agent  1 :  0.20190919935703278
episode:  23 training step:  1042 loss of agent  2 :  0.14149464666843414
episode:  23 training step:  1042 loss of agent  3 :  0.11499236524105072
episode:  23 training step:  1043 loss of agent  0 :  0.04576956108212471
episode:  23 training step:  1043 loss of agent  1 :  0.47719597816467285
episode:  23 training step:  1043 loss of agent  2 :  0.10742005705833435
episode:  23 training step:  1043 loss of agent  3 :  0.16274425387382507
episode:  23 training step:  1044 loss of agent  0 :  0.06853267550468445
episode:  23 training step:  1044 loss of agent  1 :  0.3187555968761444
episode:  23 training step:  1044 loss of agent  2 :  0.14159122109413147
episode:  23 training step:  1044 loss of agent  3 :  0.2661873996257782
episode:  23 training step:  1045 loss of agent  0 :  0.0270745400339365
episode:  23 training step:  1045 loss of agent  1 :  0.49409258365631104
episode:  23 training step:  1045 loss of agent  2 :  0.15965376794338226
episode:  23 training step:  1045 loss of agent  3 :  0.1375601589679718
Evaluation
env seed: 6 evaluation score at the training step:  1045 :  {'adversary_0': -26.514684258790215, 'agent_0': -3.4040781583016075, 'agent_1': -3.4040781583016075, 'agent_2': -3.4040781583016075}
episode:  23 training step:  1046 loss of agent  0 :  0.05430268123745918
episode:  23 training step:  1046 loss of agent  1 :  0.2872554361820221
episode:  23 training step:  1046 loss of agent  2 :  0.2773749828338623
episode:  23 training step:  1046 loss of agent  3 :  0.18835186958312988
episode:  23 training step:  1047 loss of agent  0 :  0.03940674662590027
episode:  23 training step:  1047 loss of agent  1 :  0.356575608253479
episode:  23 training step:  1047 loss of agent  2 :  0.23974686861038208
episode:  23 training step:  1047 loss of agent  3 :  0.12011883407831192
episode:  23 training step:  1048 loss of agent  0 :  0.04433907940983772
episode:  23 training step:  1048 loss of agent  1 :  0.3721461892127991
episode:  23 training step:  1048 loss of agent  2 :  0.23375701904296875
episode:  23 training step:  1048 loss of agent  3 :  0.2384789139032364
episode:  23 training step:  1049 loss of agent  0 :  0.06574955582618713
episode:  23 training step:  1049 loss of agent  1 :  0.5485656261444092
episode:  23 training step:  1049 loss of agent  2 :  0.22848021984100342
episode:  23 training step:  1049 loss of agent  3 :  0.19824443757534027
episode:  23 training step:  1050 loss of agent  0 :  0.03979533165693283
episode:  23 training step:  1050 loss of agent  1 :  0.3363409638404846
episode:  23 training step:  1050 loss of agent  2 :  0.1957988739013672
episode:  23 training step:  1050 loss of agent  3 :  0.08948265761137009
Evaluation
env seed: 6 evaluation score at the training step:  1050 :  {'adversary_0': -26.11139273689374, 'agent_0': -4.107010485746266, 'agent_1': -4.107010485746266, 'agent_2': -4.107010485746266}
model saving.................................
episode:  23 training step:  1051 loss of agent  0 :  0.02622331865131855
episode:  23 training step:  1051 loss of agent  1 :  0.42367467284202576
episode:  23 training step:  1051 loss of agent  2 :  0.13727933168411255
episode:  23 training step:  1051 loss of agent  3 :  0.23672010004520416
episode:  23 training step:  1052 loss of agent  0 :  0.05511028319597244
episode:  23 training step:  1052 loss of agent  1 :  0.33064496517181396
episode:  23 training step:  1052 loss of agent  2 :  0.12817798554897308
episode:  23 training step:  1052 loss of agent  3 :  0.15728652477264404
episode:  23 training step:  1053 loss of agent  0 :  0.04525217041373253
episode:  23 training step:  1053 loss of agent  1 :  0.4008263349533081
episode:  23 training step:  1053 loss of agent  2 :  0.2153196781873703
episode:  23 training step:  1053 loss of agent  3 :  0.3312157094478607
episode 23 terminated at 1200
episode: 24
epoch: 1
episode:  24 training step:  1054 loss of agent  0 :  0.03481991961598396
episode:  24 training step:  1054 loss of agent  1 :  0.2386760711669922
episode:  24 training step:  1054 loss of agent  2 :  0.1551515907049179
episode:  24 training step:  1054 loss of agent  3 :  0.2169923484325409
episode:  24 training step:  1055 loss of agent  0 :  0.041623298078775406
episode:  24 training step:  1055 loss of agent  1 :  0.3099677264690399
episode:  24 training step:  1055 loss of agent  2 :  0.15289847552776337
episode:  24 training step:  1055 loss of agent  3 :  0.19371582567691803
Evaluation
env seed: 6 evaluation score at the training step:  1055 :  {'adversary_0': -26.444595010716693, 'agent_0': -3.611951676312215, 'agent_1': -3.611951676312215, 'agent_2': -3.611951676312215}
episode:  24 training step:  1056 loss of agent  0 :  0.048409465700387955
episode:  24 training step:  1056 loss of agent  1 :  0.3167165219783783
episode:  24 training step:  1056 loss of agent  2 :  0.16537094116210938
episode:  24 training step:  1056 loss of agent  3 :  0.18953877687454224
episode:  24 training step:  1057 loss of agent  0 :  0.029492855072021484
episode:  24 training step:  1057 loss of agent  1 :  0.4351685643196106
episode:  24 training step:  1057 loss of agent  2 :  0.18145205080509186
episode:  24 training step:  1057 loss of agent  3 :  0.13112878799438477
episode:  24 training step:  1058 loss of agent  0 :  0.08436615765094757
episode:  24 training step:  1058 loss of agent  1 :  0.22370681166648865
episode:  24 training step:  1058 loss of agent  2 :  0.17785362899303436
episode:  24 training step:  1058 loss of agent  3 :  0.14597372710704803
episode:  24 training step:  1059 loss of agent  0 :  0.042142756283283234
episode:  24 training step:  1059 loss of agent  1 :  0.33619651198387146
episode:  24 training step:  1059 loss of agent  2 :  0.13420574367046356
episode:  24 training step:  1059 loss of agent  3 :  0.18095563352108002
episode:  24 training step:  1060 loss of agent  0 :  0.06655613332986832
episode:  24 training step:  1060 loss of agent  1 :  0.3972656726837158
episode:  24 training step:  1060 loss of agent  2 :  0.16257727146148682
episode:  24 training step:  1060 loss of agent  3 :  0.11592178791761398
Evaluation
env seed: 6 evaluation score at the training step:  1060 :  {'adversary_0': -26.781334663182, 'agent_0': -2.833831526067893, 'agent_1': -2.833831526067893, 'agent_2': -2.833831526067893}
model saving.................................
episode:  24 training step:  1061 loss of agent  0 :  0.05389377102255821
episode:  24 training step:  1061 loss of agent  1 :  0.38586097955703735
episode:  24 training step:  1061 loss of agent  2 :  0.16094878315925598
episode:  24 training step:  1061 loss of agent  3 :  0.21383807063102722
episode:  24 training step:  1062 loss of agent  0 :  0.06076354160904884
episode:  24 training step:  1062 loss of agent  1 :  0.4156484305858612
episode:  24 training step:  1062 loss of agent  2 :  0.1348375380039215
episode:  24 training step:  1062 loss of agent  3 :  0.17629602551460266
episode:  24 training step:  1063 loss of agent  0 :  0.04908484220504761
episode:  24 training step:  1063 loss of agent  1 :  0.5032769441604614
episode:  24 training step:  1063 loss of agent  2 :  0.15488919615745544
episode:  24 training step:  1063 loss of agent  3 :  0.10581521689891815
episode:  24 training step:  1064 loss of agent  0 :  0.04534395784139633
episode:  24 training step:  1064 loss of agent  1 :  0.3761216700077057
episode:  24 training step:  1064 loss of agent  2 :  0.17385146021842957
episode:  24 training step:  1064 loss of agent  3 :  0.08655097335577011
episode:  24 training step:  1065 loss of agent  0 :  0.05536290258169174
episode:  24 training step:  1065 loss of agent  1 :  0.34508591890335083
episode:  24 training step:  1065 loss of agent  2 :  0.27223294973373413
episode:  24 training step:  1065 loss of agent  3 :  0.1937696933746338
Evaluation
env seed: 6 evaluation score at the training step:  1065 :  {'adversary_0': -31.953341483976374, 'agent_0': 2.8735369224950107, 'agent_1': 2.8735369224950107, 'agent_2': 2.8735369224950107}
episode:  24 training step:  1066 loss of agent  0 :  0.05863521248102188
episode:  24 training step:  1066 loss of agent  1 :  0.2733868360519409
episode:  24 training step:  1066 loss of agent  2 :  0.20832310616970062
episode:  24 training step:  1066 loss of agent  3 :  0.1800183206796646
episode:  24 training step:  1067 loss of agent  0 :  0.03941003978252411
episode:  24 training step:  1067 loss of agent  1 :  0.3295108377933502
episode:  24 training step:  1067 loss of agent  2 :  0.08813317120075226
episode:  24 training step:  1067 loss of agent  3 :  0.13006356358528137
episode:  24 training step:  1068 loss of agent  0 :  0.06284354627132416
episode:  24 training step:  1068 loss of agent  1 :  0.2992914319038391
episode:  24 training step:  1068 loss of agent  2 :  0.2175704389810562
episode:  24 training step:  1068 loss of agent  3 :  0.0859081894159317
episode:  24 training step:  1069 loss of agent  0 :  0.03274378925561905
episode:  24 training step:  1069 loss of agent  1 :  0.4219326674938202
episode:  24 training step:  1069 loss of agent  2 :  0.17479892075061798
episode:  24 training step:  1069 loss of agent  3 :  0.16174113750457764
episode:  24 training step:  1070 loss of agent  0 :  0.04936470091342926
episode:  24 training step:  1070 loss of agent  1 :  0.3110353648662567
episode:  24 training step:  1070 loss of agent  2 :  0.09564052522182465
episode:  24 training step:  1070 loss of agent  3 :  0.2662562131881714
Evaluation
env seed: 6 evaluation score at the training step:  1070 :  {'adversary_0': -35.724582486847815, 'agent_0': 7.821863050234688, 'agent_1': 7.821863050234688, 'agent_2': 7.821863050234688}
model saving.................................
episode:  24 training step:  1071 loss of agent  0 :  0.05106914043426514
episode:  24 training step:  1071 loss of agent  1 :  0.2440883070230484
episode:  24 training step:  1071 loss of agent  2 :  0.1859457641839981
episode:  24 training step:  1071 loss of agent  3 :  0.20895275473594666
episode:  24 training step:  1072 loss of agent  0 :  0.055966079235076904
episode:  24 training step:  1072 loss of agent  1 :  0.2998310923576355
episode:  24 training step:  1072 loss of agent  2 :  0.16659927368164062
episode:  24 training step:  1072 loss of agent  3 :  0.18797467648983002
episode:  24 training step:  1073 loss of agent  0 :  0.043934937566518784
episode:  24 training step:  1073 loss of agent  1 :  0.30211424827575684
episode:  24 training step:  1073 loss of agent  2 :  0.1942456066608429
episode:  24 training step:  1073 loss of agent  3 :  0.31047096848487854
episode:  24 training step:  1074 loss of agent  0 :  0.03682829439640045
episode:  24 training step:  1074 loss of agent  1 :  0.5244542956352234
episode:  24 training step:  1074 loss of agent  2 :  0.14185629785060883
episode:  24 training step:  1074 loss of agent  3 :  0.18207919597625732
episode:  24 training step:  1075 loss of agent  0 :  0.06994839012622833
episode:  24 training step:  1075 loss of agent  1 :  0.3493569791316986
episode:  24 training step:  1075 loss of agent  2 :  0.15562650561332703
episode:  24 training step:  1075 loss of agent  3 :  0.24286498129367828
Evaluation
env seed: 6 evaluation score at the training step:  1075 :  {'adversary_0': -35.205928446494795, 'agent_0': 6.630433522732216, 'agent_1': 6.630433522732216, 'agent_2': 6.630433522732216}
episode:  24 training step:  1076 loss of agent  0 :  0.06257525831460953
episode:  24 training step:  1076 loss of agent  1 :  0.27596282958984375
episode:  24 training step:  1076 loss of agent  2 :  0.1707998812198639
episode:  24 training step:  1076 loss of agent  3 :  0.2061968445777893
episode:  24 training step:  1077 loss of agent  0 :  0.03415977582335472
episode:  24 training step:  1077 loss of agent  1 :  0.39360225200653076
episode:  24 training step:  1077 loss of agent  2 :  0.2064698189496994
episode:  24 training step:  1077 loss of agent  3 :  0.21669070422649384
episode 24 terminated at 1225
epoch: 2
episode:  24 training step:  1078 loss of agent  0 :  0.05227074399590492
episode:  24 training step:  1078 loss of agent  1 :  0.5053141117095947
episode:  24 training step:  1078 loss of agent  2 :  0.23959824442863464
episode:  24 training step:  1078 loss of agent  3 :  0.13387638330459595
episode:  24 training step:  1079 loss of agent  0 :  0.056750837713479996
episode:  24 training step:  1079 loss of agent  1 :  0.32993605732917786
episode:  24 training step:  1079 loss of agent  2 :  0.11717270314693451
episode:  24 training step:  1079 loss of agent  3 :  0.18849237263202667
episode:  24 training step:  1080 loss of agent  0 :  0.051100268959999084
episode:  24 training step:  1080 loss of agent  1 :  0.35769328474998474
episode:  24 training step:  1080 loss of agent  2 :  0.1942523717880249
episode:  24 training step:  1080 loss of agent  3 :  0.142378568649292
Evaluation
env seed: 6 evaluation score at the training step:  1080 :  {'adversary_0': -58.39781689480304, 'agent_0': 37.51156633964177, 'agent_1': 37.51156633964177, 'agent_2': 37.51156633964177}
model saving.................................
episode:  24 training step:  1081 loss of agent  0 :  0.06355096399784088
episode:  24 training step:  1081 loss of agent  1 :  0.4252786338329315
episode:  24 training step:  1081 loss of agent  2 :  0.0742744579911232
episode:  24 training step:  1081 loss of agent  3 :  0.1993134319782257
episode:  24 training step:  1082 loss of agent  0 :  0.05200814828276634
episode:  24 training step:  1082 loss of agent  1 :  0.24815207719802856
episode:  24 training step:  1082 loss of agent  2 :  0.13940225541591644
episode:  24 training step:  1082 loss of agent  3 :  0.14713610708713531
episode:  24 training step:  1083 loss of agent  0 :  0.06267678737640381
episode:  24 training step:  1083 loss of agent  1 :  0.20693552494049072
episode:  24 training step:  1083 loss of agent  2 :  0.22027918696403503
episode:  24 training step:  1083 loss of agent  3 :  0.19299310445785522
episode:  24 training step:  1084 loss of agent  0 :  0.06332972645759583
episode:  24 training step:  1084 loss of agent  1 :  0.3214634656906128
episode:  24 training step:  1084 loss of agent  2 :  0.17549572885036469
episode:  24 training step:  1084 loss of agent  3 :  0.2887793183326721
episode:  24 training step:  1085 loss of agent  0 :  0.04861040413379669
episode:  24 training step:  1085 loss of agent  1 :  0.611973762512207
episode:  24 training step:  1085 loss of agent  2 :  0.17415505647659302
episode:  24 training step:  1085 loss of agent  3 :  0.16512364149093628
Evaluation
env seed: 6 evaluation score at the training step:  1085 :  {'adversary_0': -52.4014902211963, 'agent_0': 22.932162685866587, 'agent_1': 22.932162685866587, 'agent_2': 22.932162685866587}
episode:  24 training step:  1086 loss of agent  0 :  0.08126984536647797
episode:  24 training step:  1086 loss of agent  1 :  0.2229476422071457
episode:  24 training step:  1086 loss of agent  2 :  0.14745841920375824
episode:  24 training step:  1086 loss of agent  3 :  0.19978541135787964
episode:  24 training step:  1087 loss of agent  0 :  0.05108654499053955
episode:  24 training step:  1087 loss of agent  1 :  0.4623446464538574
episode:  24 training step:  1087 loss of agent  2 :  0.2672775387763977
episode:  24 training step:  1087 loss of agent  3 :  0.1197742223739624
episode:  24 training step:  1088 loss of agent  0 :  0.06547834724187851
episode:  24 training step:  1088 loss of agent  1 :  0.40512755513191223
episode:  24 training step:  1088 loss of agent  2 :  0.17251908779144287
episode:  24 training step:  1088 loss of agent  3 :  0.15435393154621124
episode:  24 training step:  1089 loss of agent  0 :  0.05891990661621094
episode:  24 training step:  1089 loss of agent  1 :  0.34581300616264343
episode:  24 training step:  1089 loss of agent  2 :  0.15175792574882507
episode:  24 training step:  1089 loss of agent  3 :  0.15836237370967865
episode:  24 training step:  1090 loss of agent  0 :  0.06864778697490692
episode:  24 training step:  1090 loss of agent  1 :  0.33121493458747864
episode:  24 training step:  1090 loss of agent  2 :  0.11148671805858612
episode:  24 training step:  1090 loss of agent  3 :  0.22515618801116943
Evaluation
env seed: 6 evaluation score at the training step:  1090 :  {'adversary_0': -58.75223333437016, 'agent_0': 28.803490515532985, 'agent_1': 28.803490515532985, 'agent_2': 28.803490515532985}
model saving.................................
episode:  24 training step:  1091 loss of agent  0 :  0.07407540082931519
episode:  24 training step:  1091 loss of agent  1 :  0.45783060789108276
episode:  24 training step:  1091 loss of agent  2 :  0.14501315355300903
episode:  24 training step:  1091 loss of agent  3 :  0.18304888904094696
episode:  24 training step:  1092 loss of agent  0 :  0.034769363701343536
episode:  24 training step:  1092 loss of agent  1 :  0.3624610900878906
episode:  24 training step:  1092 loss of agent  2 :  0.3081209361553192
episode:  24 training step:  1092 loss of agent  3 :  0.16833649575710297
episode:  24 training step:  1093 loss of agent  0 :  0.041244179010391235
episode:  24 training step:  1093 loss of agent  1 :  0.35477763414382935
episode:  24 training step:  1093 loss of agent  2 :  0.15743610262870789
episode:  24 training step:  1093 loss of agent  3 :  0.21035072207450867
episode:  24 training step:  1094 loss of agent  0 :  0.04427197948098183
episode:  24 training step:  1094 loss of agent  1 :  0.45341578125953674
episode:  24 training step:  1094 loss of agent  2 :  0.0710841566324234
episode:  24 training step:  1094 loss of agent  3 :  0.10319533944129944
episode:  24 training step:  1095 loss of agent  0 :  0.05329665541648865
episode:  24 training step:  1095 loss of agent  1 :  0.2672068476676941
episode:  24 training step:  1095 loss of agent  2 :  0.17563247680664062
episode:  24 training step:  1095 loss of agent  3 :  0.14215517044067383
Evaluation
env seed: 6 evaluation score at the training step:  1095 :  {'adversary_0': -46.77212764414211, 'agent_0': 17.53760129828995, 'agent_1': 17.53760129828995, 'agent_2': 17.53760129828995}
episode:  24 training step:  1096 loss of agent  0 :  0.06600946187973022
episode:  24 training step:  1096 loss of agent  1 :  0.32218998670578003
episode:  24 training step:  1096 loss of agent  2 :  0.2075122445821762
episode:  24 training step:  1096 loss of agent  3 :  0.18979187309741974
episode:  24 training step:  1097 loss of agent  0 :  0.04692583158612251
episode:  24 training step:  1097 loss of agent  1 :  0.4028151035308838
episode:  24 training step:  1097 loss of agent  2 :  0.2477843463420868
episode:  24 training step:  1097 loss of agent  3 :  0.15886102616786957
episode:  24 training step:  1098 loss of agent  0 :  0.08601829409599304
episode:  24 training step:  1098 loss of agent  1 :  0.40429550409317017
episode:  24 training step:  1098 loss of agent  2 :  0.2679053544998169
episode:  24 training step:  1098 loss of agent  3 :  0.18008293211460114
episode:  24 training step:  1099 loss of agent  0 :  0.06060440465807915
episode:  24 training step:  1099 loss of agent  1 :  0.53365159034729
episode:  24 training step:  1099 loss of agent  2 :  0.21610015630722046
episode:  24 training step:  1099 loss of agent  3 :  0.2142145186662674
episode:  24 training step:  1100 loss of agent  0 :  0.06542692333459854
episode:  24 training step:  1100 loss of agent  1 :  0.23365110158920288
episode:  24 training step:  1100 loss of agent  2 :  0.14355385303497314
episode:  24 training step:  1100 loss of agent  3 :  0.17777836322784424
Evaluation
env seed: 6 evaluation score at the training step:  1100 :  {'adversary_0': -26.613778484781385, 'agent_0': -2.7015821244814133, 'agent_1': -2.7015821244814133, 'agent_2': -2.7015821244814133}
model saving.................................
episode:  24 training step:  1101 loss of agent  0 :  0.03503638878464699
episode:  24 training step:  1101 loss of agent  1 :  0.3056909441947937
episode:  24 training step:  1101 loss of agent  2 :  0.30408531427383423
episode:  24 training step:  1101 loss of agent  3 :  0.22981366515159607
