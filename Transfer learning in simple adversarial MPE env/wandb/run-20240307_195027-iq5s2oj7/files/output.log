----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 5, 6]              20
              ReLU-2                 [-1, 5, 6]               0
            Conv1d-3                [-1, 10, 4]             160
              ReLU-4                [-1, 10, 4]               0
            Conv1d-5                [-1, 15, 4]             465
              ReLU-6                [-1, 15, 4]               0
            Conv1d-7                [-1, 20, 4]             920
              ReLU-8                [-1, 20, 4]               0
            Conv1d-9                [-1, 25, 4]           1,525
             ReLU-10                [-1, 25, 4]               0
           Conv1d-11                [-1, 30, 2]           2,280
             ReLU-12                [-1, 30, 2]               0
          Flatten-13                   [-1, 60]               0
           Linear-14                  [-1, 100]           6,100
             ReLU-15                  [-1, 100]               0
           Linear-16                    [-1, 1]             101
           Linear-17                    [-1, 5]             505
================================================================
Total params: 12,076
Trainable params: 12,076
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.05
Estimated Total Size (MB): 0.05
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                 [-1, 1, 8]             104
          Inputnet-2                 [-1, 1, 8]               0
            Conv1d-3                 [-1, 5, 6]              20
              ReLU-4                 [-1, 5, 6]               0
            Conv1d-5                [-1, 10, 4]             160
              ReLU-6                [-1, 10, 4]               0
            Conv1d-7                [-1, 15, 4]             465
              ReLU-8                [-1, 15, 4]               0
            Conv1d-9                [-1, 20, 4]             920
             ReLU-10                [-1, 20, 4]               0
           Conv1d-11                [-1, 25, 4]           1,525
             ReLU-12                [-1, 25, 4]               0
           Conv1d-13                [-1, 30, 2]           2,280
             ReLU-14                [-1, 30, 2]               0
          Flatten-15                   [-1, 60]               0
           Linear-16                  [-1, 100]           6,100
             ReLU-17                  [-1, 100]               0
           Linear-18                    [-1, 1]             101
           Linear-19                    [-1, 5]             505
         dddQ_Net-20  [[-1, 1], [-1, 5], [-1, 5]]               0
================================================================
Total params: 12,180
Trainable params: 6,810
Non-trainable params: 5,370
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.05
Estimated Total Size (MB): 0.05
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                [-1, 1, 10]             150
          Inputnet-2                [-1, 1, 10]               0
            Conv1d-3                 [-1, 4, 8]              16
              ReLU-4                 [-1, 4, 8]               0
            Conv1d-5                 [-1, 8, 6]             104
              ReLU-6                 [-1, 8, 6]               0
            Conv1d-7                [-1, 16, 4]             400
              ReLU-8                [-1, 16, 4]               0
            Conv1d-9                [-1, 32, 4]             544
             ReLU-10                [-1, 32, 4]               0
          Flatten-11                  [-1, 128]               0
           Linear-12                  [-1, 100]          12,900
             ReLU-13                  [-1, 100]               0
           Linear-14                    [-1, 1]             101
           Linear-15                    [-1, 5]             505
         dddQ_Net-16  [[-1, 1], [-1, 5], [-1, 5]]               0
================================================================
Total params: 14,720
Trainable params: 13,656
Non-trainable params: 1,064
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                [-1, 1, 10]             150
          Inputnet-2                [-1, 1, 10]               0
            Conv1d-3                 [-1, 4, 8]              16
              ReLU-4                 [-1, 4, 8]               0
            Conv1d-5                 [-1, 8, 6]             104
              ReLU-6                 [-1, 8, 6]               0
            Conv1d-7                [-1, 16, 4]             400
              ReLU-8                [-1, 16, 4]               0
            Conv1d-9                [-1, 32, 4]             544
             ReLU-10                [-1, 32, 4]               0
          Flatten-11                  [-1, 128]               0
           Linear-12                  [-1, 100]          12,900
             ReLU-13                  [-1, 100]               0
           Linear-14                    [-1, 1]             101
           Linear-15                    [-1, 5]             505
         dddQ_Net-16  [[-1, 1], [-1, 5], [-1, 5]]               0
================================================================
Total params: 14,720
Trainable params: 13,656
Non-trainable params: 1,064
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                 [-1, 4, 8]              16
              ReLU-2                 [-1, 4, 8]               0
            Conv1d-3                 [-1, 8, 6]             104
              ReLU-4                 [-1, 8, 6]               0
            Conv1d-5                [-1, 16, 4]             400
              ReLU-6                [-1, 16, 4]               0
            Conv1d-7                [-1, 32, 4]             544
              ReLU-8                [-1, 32, 4]               0
           Flatten-9                  [-1, 128]               0
           Linear-10                  [-1, 100]          12,900
             ReLU-11                  [-1, 100]               0
           Linear-12                    [-1, 1]             101
           Linear-13                    [-1, 5]             505
================================================================
Total params: 14,570
Trainable params: 14,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Linear-1                [-1, 1, 10]             150
          Inputnet-2                [-1, 1, 10]               0
            Conv1d-3                 [-1, 4, 8]              16
              ReLU-4                 [-1, 4, 8]               0
            Conv1d-5                 [-1, 8, 6]             104
              ReLU-6                 [-1, 8, 6]               0
            Conv1d-7                [-1, 16, 4]             400
              ReLU-8                [-1, 16, 4]               0
            Conv1d-9                [-1, 32, 4]             544
             ReLU-10                [-1, 32, 4]               0
          Flatten-11                  [-1, 128]               0
           Linear-12                  [-1, 100]          12,900
             ReLU-13                  [-1, 100]               0
           Linear-14                    [-1, 1]             101
           Linear-15                    [-1, 5]             505
         dddQ_Net-16  [[-1, 1], [-1, 5], [-1, 5]]               0
================================================================
Total params: 14,720
Trainable params: 13,656
Non-trainable params: 1,064
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.06
Estimated Total Size (MB): 0.06
----------------------------------------------------------------
episode: 0
epoch: 0
episode 0 terminated at 25
epoch: 1
episode 0 terminated at 50
episode: 1
epoch: 0
episode 1 terminated at 75
epoch: 1
episode 1 terminated at 100
episode: 2
epoch: 0
episode:  2 training step:  1 loss of agent  0 :  0.6822612285614014
episode:  2 training step:  1 loss of agent  1 :  0.538750410079956
episode:  2 training step:  1 loss of agent  2 :  0.6346022486686707
episode:  2 training step:  1 loss of agent  3 :  0.4212789535522461
episode:  2 training step:  2 loss of agent  0 :  0.5815879106521606
episode:  2 training step:  2 loss of agent  1 :  0.5281431078910828
episode:  2 training step:  2 loss of agent  2 :  0.7975500822067261
episode:  2 training step:  2 loss of agent  3 :  0.4148670732975006
episode:  2 training step:  3 loss of agent  0 :  0.5235990285873413
episode:  2 training step:  3 loss of agent  1 :  0.5969733595848083
episode:  2 training step:  3 loss of agent  2 :  0.740077018737793
episode:  2 training step:  3 loss of agent  3 :  0.39681893587112427
episode:  2 training step:  4 loss of agent  0 :  0.5395395159721375
episode:  2 training step:  4 loss of agent  1 :  0.5443787574768066
episode:  2 training step:  4 loss of agent  2 :  0.7195767760276794
episode:  2 training step:  4 loss of agent  3 :  0.34935668110847473
episode:  2 training step:  5 loss of agent  0 :  0.5684860348701477
episode:  2 training step:  5 loss of agent  1 :  0.5348312258720398
episode:  2 training step:  5 loss of agent  2 :  0.6164558529853821
episode:  2 training step:  5 loss of agent  3 :  0.4605768918991089
Evaluation
env seed: 6 evaluation score at the training step:  5 :  {'adversary_0': -35.40128750693329, 'agent_0': -9.238834097469061, 'agent_1': -9.238834097469061, 'agent_2': -9.238834097469061}
episode:  2 training step:  6 loss of agent  0 :  0.5736950635910034
episode:  2 training step:  6 loss of agent  1 :  0.4276978075504303
episode:  2 training step:  6 loss of agent  2 :  0.40264028310775757
episode:  2 training step:  6 loss of agent  3 :  0.24645277857780457
episode:  2 training step:  7 loss of agent  0 :  0.4577661156654358
episode:  2 training step:  7 loss of agent  1 :  0.42572256922721863
episode:  2 training step:  7 loss of agent  2 :  0.4925089478492737
episode:  2 training step:  7 loss of agent  3 :  0.23870395123958588
episode:  2 training step:  8 loss of agent  0 :  0.3634535074234009
episode:  2 training step:  8 loss of agent  1 :  0.46756982803344727
episode:  2 training step:  8 loss of agent  2 :  0.5687904357910156
episode:  2 training step:  8 loss of agent  3 :  0.31627750396728516
episode:  2 training step:  9 loss of agent  0 :  0.5869253873825073
episode:  2 training step:  9 loss of agent  1 :  0.37193599343299866
episode:  2 training step:  9 loss of agent  2 :  0.6465506553649902
episode:  2 training step:  9 loss of agent  3 :  0.4269118309020996
episode:  2 training step:  10 loss of agent  0 :  0.34725436568260193
episode:  2 training step:  10 loss of agent  1 :  0.3605850636959076
episode:  2 training step:  10 loss of agent  2 :  0.42489683628082275
episode:  2 training step:  10 loss of agent  3 :  0.3083508014678955
Evaluation
env seed: 6 evaluation score at the training step:  10 :  {'adversary_0': -35.724582486847815, 'agent_0': -7.2188245313021095, 'agent_1': -7.2188245313021095, 'agent_2': -7.2188245313021095}
model saving.................................
episode:  2 training step:  11 loss of agent  0 :  0.3434153199195862
episode:  2 training step:  11 loss of agent  1 :  0.4552404582500458
episode:  2 training step:  11 loss of agent  2 :  0.5357555747032166
episode:  2 training step:  11 loss of agent  3 :  0.2986515164375305
episode:  2 training step:  12 loss of agent  0 :  0.37476223707199097
episode:  2 training step:  12 loss of agent  1 :  0.36446380615234375
episode:  2 training step:  12 loss of agent  2 :  0.5231137275695801
episode:  2 training step:  12 loss of agent  3 :  0.32280707359313965
episode:  2 training step:  13 loss of agent  0 :  0.31912747025489807
episode:  2 training step:  13 loss of agent  1 :  0.38131585717201233
episode:  2 training step:  13 loss of agent  2 :  0.45567673444747925
episode:  2 training step:  13 loss of agent  3 :  0.2865382730960846
episode:  2 training step:  14 loss of agent  0 :  0.3357178270816803
episode:  2 training step:  14 loss of agent  1 :  0.22841361165046692
episode:  2 training step:  14 loss of agent  2 :  0.42199018597602844
episode:  2 training step:  14 loss of agent  3 :  0.29777780175209045
episode:  2 training step:  15 loss of agent  0 :  0.25283288955688477
episode:  2 training step:  15 loss of agent  1 :  0.46906447410583496
episode:  2 training step:  15 loss of agent  2 :  0.5395724177360535
episode:  2 training step:  15 loss of agent  3 :  0.2703098952770233
Evaluation
env seed: 6 evaluation score at the training step:  15 :  {'adversary_0': -35.44090252402965, 'agent_0': -3.6542749326296535, 'agent_1': -3.6542749326296535, 'agent_2': -3.6542749326296535}
episode:  2 training step:  16 loss of agent  0 :  0.3241889774799347
episode:  2 training step:  16 loss of agent  1 :  0.2931649088859558
episode:  2 training step:  16 loss of agent  2 :  0.38236939907073975
episode:  2 training step:  16 loss of agent  3 :  0.253780722618103
episode:  2 training step:  17 loss of agent  0 :  0.26748985052108765
episode:  2 training step:  17 loss of agent  1 :  0.2529984712600708
episode:  2 training step:  17 loss of agent  2 :  0.43392279744148254
episode:  2 training step:  17 loss of agent  3 :  0.38467615842819214
episode:  2 training step:  18 loss of agent  0 :  0.22543194890022278
episode:  2 training step:  18 loss of agent  1 :  0.32748886942863464
episode:  2 training step:  18 loss of agent  2 :  0.3718408942222595
episode:  2 training step:  18 loss of agent  3 :  0.2640117108821869
episode:  2 training step:  19 loss of agent  0 :  0.15971872210502625
episode:  2 training step:  19 loss of agent  1 :  0.2027239054441452
episode:  2 training step:  19 loss of agent  2 :  0.32834184169769287
episode:  2 training step:  19 loss of agent  3 :  0.17910122871398926
episode:  2 training step:  20 loss of agent  0 :  0.33032429218292236
episode:  2 training step:  20 loss of agent  1 :  0.26738977432250977
episode:  2 training step:  20 loss of agent  2 :  0.3439311981201172
episode:  2 training step:  20 loss of agent  3 :  0.2948431372642517
Evaluation
env seed: 6 evaluation score at the training step:  20 :  {'adversary_0': -35.724582486847815, 'agent_0': -0.9329726428700642, 'agent_1': -0.9329726428700642, 'agent_2': -0.9329726428700642}
model saving.................................
episode:  2 training step:  21 loss of agent  0 :  0.18365627527236938
episode:  2 training step:  21 loss of agent  1 :  0.2877853810787201
episode:  2 training step:  21 loss of agent  2 :  0.4042796492576599
episode:  2 training step:  21 loss of agent  3 :  0.281948447227478
episode 2 terminated at 125
epoch: 1
episode:  2 training step:  22 loss of agent  0 :  0.25097987055778503
episode:  2 training step:  22 loss of agent  1 :  0.18562141060829163
episode:  2 training step:  22 loss of agent  2 :  0.3626578450202942
episode:  2 training step:  22 loss of agent  3 :  0.2958711087703705
episode:  2 training step:  23 loss of agent  0 :  0.15284249186515808
episode:  2 training step:  23 loss of agent  1 :  0.238218292593956
episode:  2 training step:  23 loss of agent  2 :  0.4019150137901306
episode:  2 training step:  23 loss of agent  3 :  0.21129204332828522
episode:  2 training step:  24 loss of agent  0 :  0.15348362922668457
episode:  2 training step:  24 loss of agent  1 :  0.2656661868095398
episode:  2 training step:  24 loss of agent  2 :  0.36231574416160583
episode:  2 training step:  24 loss of agent  3 :  0.306063175201416
episode:  2 training step:  25 loss of agent  0 :  0.1771760880947113
episode:  2 training step:  25 loss of agent  1 :  0.2028615027666092
episode:  2 training step:  25 loss of agent  2 :  0.3133210837841034
episode:  2 training step:  25 loss of agent  3 :  0.20226722955703735
Evaluation
env seed: 6 evaluation score at the training step:  25 :  {'adversary_0': -35.14842304257421, 'agent_0': 0.33414082370177206, 'agent_1': 0.33414082370177206, 'agent_2': 0.33414082370177206}
episode:  2 training step:  26 loss of agent  0 :  0.1499541848897934
episode:  2 training step:  26 loss of agent  1 :  0.18798045814037323
episode:  2 training step:  26 loss of agent  2 :  0.29085493087768555
episode:  2 training step:  26 loss of agent  3 :  0.2052757441997528
episode:  2 training step:  27 loss of agent  0 :  0.18841905891895294
episode:  2 training step:  27 loss of agent  1 :  0.14924860000610352
episode:  2 training step:  27 loss of agent  2 :  0.3070409893989563
episode:  2 training step:  27 loss of agent  3 :  0.2324579656124115
episode:  2 training step:  28 loss of agent  0 :  0.18737107515335083
episode:  2 training step:  28 loss of agent  1 :  0.1417664736509323
episode:  2 training step:  28 loss of agent  2 :  0.23599660396575928
episode:  2 training step:  28 loss of agent  3 :  0.23976992070674896
episode:  2 training step:  29 loss of agent  0 :  0.14905709028244019
episode:  2 training step:  29 loss of agent  1 :  0.16467662155628204
episode:  2 training step:  29 loss of agent  2 :  0.23875518143177032
episode:  2 training step:  29 loss of agent  3 :  0.20459584891796112
episode:  2 training step:  30 loss of agent  0 :  0.14276759326457977
episode:  2 training step:  30 loss of agent  1 :  0.10990331321954727
episode:  2 training step:  30 loss of agent  2 :  0.2845580577850342
episode:  2 training step:  30 loss of agent  3 :  0.2455548644065857
Evaluation
env seed: 6 evaluation score at the training step:  30 :  {'adversary_0': -35.2295911503879, 'agent_0': 4.6530458095920295, 'agent_1': 4.6530458095920295, 'agent_2': 4.6530458095920295}
model saving.................................
episode:  2 training step:  31 loss of agent  0 :  0.1691024899482727
episode:  2 training step:  31 loss of agent  1 :  0.1508329212665558
episode:  2 training step:  31 loss of agent  2 :  0.16199666261672974
episode:  2 training step:  31 loss of agent  3 :  0.2997989058494568
episode:  2 training step:  32 loss of agent  0 :  0.13309964537620544
episode:  2 training step:  32 loss of agent  1 :  0.1685418039560318
episode:  2 training step:  32 loss of agent  2 :  0.2433917075395584
episode:  2 training step:  32 loss of agent  3 :  0.26203036308288574
episode:  2 training step:  33 loss of agent  0 :  0.07272552698850632
episode:  2 training step:  33 loss of agent  1 :  0.1105407178401947
episode:  2 training step:  33 loss of agent  2 :  0.26495620608329773
episode:  2 training step:  33 loss of agent  3 :  0.2398310750722885
episode:  2 training step:  34 loss of agent  0 :  0.14132511615753174
episode:  2 training step:  34 loss of agent  1 :  0.1898224949836731
episode:  2 training step:  34 loss of agent  2 :  0.2641851305961609
episode:  2 training step:  34 loss of agent  3 :  0.2174992859363556
episode:  2 training step:  35 loss of agent  0 :  0.09764441102743149
episode:  2 training step:  35 loss of agent  1 :  0.22915019094944
episode:  2 training step:  35 loss of agent  2 :  0.23134490847587585
episode:  2 training step:  35 loss of agent  3 :  0.2938944101333618
Evaluation
env seed: 6 evaluation score at the training step:  35 :  {'adversary_0': -35.462292840058346, 'agent_0': 5.370562803841009, 'agent_1': 5.370562803841009, 'agent_2': 5.370562803841009}
episode:  2 training step:  36 loss of agent  0 :  0.11064803600311279
episode:  2 training step:  36 loss of agent  1 :  0.18496181070804596
episode:  2 training step:  36 loss of agent  2 :  0.2563609778881073
episode:  2 training step:  36 loss of agent  3 :  0.23783552646636963
episode:  2 training step:  37 loss of agent  0 :  0.18926292657852173
episode:  2 training step:  37 loss of agent  1 :  0.21501821279525757
episode:  2 training step:  37 loss of agent  2 :  0.25796687602996826
episode:  2 training step:  37 loss of agent  3 :  0.2667698264122009
episode:  2 training step:  38 loss of agent  0 :  0.08799484372138977
episode:  2 training step:  38 loss of agent  1 :  0.23323041200637817
episode:  2 training step:  38 loss of agent  2 :  0.2105458378791809
episode:  2 training step:  38 loss of agent  3 :  0.12748582661151886
episode:  2 training step:  39 loss of agent  0 :  0.12693922221660614
episode:  2 training step:  39 loss of agent  1 :  0.11789941787719727
episode:  2 training step:  39 loss of agent  2 :  0.30427783727645874
episode:  2 training step:  39 loss of agent  3 :  0.28444409370422363
episode:  2 training step:  40 loss of agent  0 :  0.15876084566116333
episode:  2 training step:  40 loss of agent  1 :  0.21767932176589966
episode:  2 training step:  40 loss of agent  2 :  0.20386426150798798
episode:  2 training step:  40 loss of agent  3 :  0.22264672815799713
Evaluation
env seed: 6 evaluation score at the training step:  40 :  {'adversary_0': -35.273673300133886, 'agent_0': 17.267279842851686, 'agent_1': 17.267279842851686, 'agent_2': 17.267279842851686}
model saving.................................
episode:  2 training step:  41 loss of agent  0 :  0.10630057752132416
episode:  2 training step:  41 loss of agent  1 :  0.16704460978507996
episode:  2 training step:  41 loss of agent  2 :  0.22971077263355255
episode:  2 training step:  41 loss of agent  3 :  0.1991383582353592
episode:  2 training step:  42 loss of agent  0 :  0.10941307246685028
episode:  2 training step:  42 loss of agent  1 :  0.13478074967861176
episode:  2 training step:  42 loss of agent  2 :  0.17848841845989227
episode:  2 training step:  42 loss of agent  3 :  0.25551262497901917
episode:  2 training step:  43 loss of agent  0 :  0.10260342061519623
episode:  2 training step:  43 loss of agent  1 :  0.20899981260299683
episode:  2 training step:  43 loss of agent  2 :  0.3185136318206787
episode:  2 training step:  43 loss of agent  3 :  0.28059178590774536
episode:  2 training step:  44 loss of agent  0 :  0.07210605591535568
episode:  2 training step:  44 loss of agent  1 :  0.1468721479177475
episode:  2 training step:  44 loss of agent  2 :  0.2361275851726532
episode:  2 training step:  44 loss of agent  3 :  0.1742774397134781
episode:  2 training step:  45 loss of agent  0 :  0.1375531554222107
episode:  2 training step:  45 loss of agent  1 :  0.3308725953102112
episode:  2 training step:  45 loss of agent  2 :  0.19192452728748322
episode:  2 training step:  45 loss of agent  3 :  0.3138597309589386
Evaluation
env seed: 6 evaluation score at the training step:  45 :  {'adversary_0': -35.724582486847815, 'agent_0': 16.389288667831863, 'agent_1': 16.389288667831863, 'agent_2': 16.389288667831863}
episode 2 terminated at 150
episode: 3
epoch: 0
episode:  3 training step:  46 loss of agent  0 :  0.11524682492017746
episode:  3 training step:  46 loss of agent  1 :  0.2259225696325302
episode:  3 training step:  46 loss of agent  2 :  0.21600520610809326
episode:  3 training step:  46 loss of agent  3 :  0.21393516659736633
episode:  3 training step:  47 loss of agent  0 :  0.11580948531627655
episode:  3 training step:  47 loss of agent  1 :  0.24865777790546417
episode:  3 training step:  47 loss of agent  2 :  0.32477280497550964
episode:  3 training step:  47 loss of agent  3 :  0.35011258721351624
episode:  3 training step:  48 loss of agent  0 :  0.09558884799480438
episode:  3 training step:  48 loss of agent  1 :  0.1657063215970993
episode:  3 training step:  48 loss of agent  2 :  0.15272173285484314
episode:  3 training step:  48 loss of agent  3 :  0.343506783246994
episode:  3 training step:  49 loss of agent  0 :  0.16930532455444336
episode:  3 training step:  49 loss of agent  1 :  0.1710715889930725
episode:  3 training step:  49 loss of agent  2 :  0.297360360622406
episode:  3 training step:  49 loss of agent  3 :  0.33566275238990784
episode:  3 training step:  50 loss of agent  0 :  0.10244686156511307
episode:  3 training step:  50 loss of agent  1 :  0.18907465040683746
episode:  3 training step:  50 loss of agent  2 :  0.19498959183692932
episode:  3 training step:  50 loss of agent  3 :  0.23133625090122223
Evaluation
env seed: 6 evaluation score at the training step:  50 :  {'adversary_0': -34.762663086775056, 'agent_0': 17.672185680067987, 'agent_1': 17.672185680067987, 'agent_2': 17.672185680067987}
model saving.................................
episode:  3 training step:  51 loss of agent  0 :  0.147291362285614
episode:  3 training step:  51 loss of agent  1 :  0.19491982460021973
episode:  3 training step:  51 loss of agent  2 :  0.2536512613296509
episode:  3 training step:  51 loss of agent  3 :  0.2493411749601364
episode:  3 training step:  52 loss of agent  0 :  0.11699569970369339
episode:  3 training step:  52 loss of agent  1 :  0.18298111855983734
episode:  3 training step:  52 loss of agent  2 :  0.26319900155067444
episode:  3 training step:  52 loss of agent  3 :  0.32589125633239746
episode:  3 training step:  53 loss of agent  0 :  0.08765440434217453
episode:  3 training step:  53 loss of agent  1 :  0.16357430815696716
episode:  3 training step:  53 loss of agent  2 :  0.2560179531574249
episode:  3 training step:  53 loss of agent  3 :  0.28276729583740234
episode:  3 training step:  54 loss of agent  0 :  0.15262377262115479
episode:  3 training step:  54 loss of agent  1 :  0.22877728939056396
episode:  3 training step:  54 loss of agent  2 :  0.2355833649635315
episode:  3 training step:  54 loss of agent  3 :  0.24203237891197205
episode:  3 training step:  55 loss of agent  0 :  0.12036997824907303
episode:  3 training step:  55 loss of agent  1 :  0.16641846299171448
episode:  3 training step:  55 loss of agent  2 :  0.178352952003479
episode:  3 training step:  55 loss of agent  3 :  0.1987328827381134
Evaluation
env seed: 6 evaluation score at the training step:  55 :  {'adversary_0': -34.90721628563744, 'agent_0': 14.388034782355422, 'agent_1': 14.388034782355422, 'agent_2': 14.388034782355422}
episode:  3 training step:  56 loss of agent  0 :  0.13251283764839172
episode:  3 training step:  56 loss of agent  1 :  0.16920603811740875
episode:  3 training step:  56 loss of agent  2 :  0.1909283697605133
episode:  3 training step:  56 loss of agent  3 :  0.18385785818099976
episode:  3 training step:  57 loss of agent  0 :  0.08083276450634003
episode:  3 training step:  57 loss of agent  1 :  0.20570369064807892
episode:  3 training step:  57 loss of agent  2 :  0.22676506638526917
episode:  3 training step:  57 loss of agent  3 :  0.2980870306491852
episode:  3 training step:  58 loss of agent  0 :  0.1114596351981163
episode:  3 training step:  58 loss of agent  1 :  0.1636350154876709
episode:  3 training step:  58 loss of agent  2 :  0.18730662763118744
episode:  3 training step:  58 loss of agent  3 :  0.2626741826534271
episode:  3 training step:  59 loss of agent  0 :  0.08620458096265793
episode:  3 training step:  59 loss of agent  1 :  0.22530950605869293
episode:  3 training step:  59 loss of agent  2 :  0.26893678307533264
episode:  3 training step:  59 loss of agent  3 :  0.2562277615070343
episode:  3 training step:  60 loss of agent  0 :  0.11926992982625961
episode:  3 training step:  60 loss of agent  1 :  0.20364637672901154
episode:  3 training step:  60 loss of agent  2 :  0.285913348197937
episode:  3 training step:  60 loss of agent  3 :  0.2567766010761261
Evaluation
env seed: 6 evaluation score at the training step:  60 :  {'adversary_0': -35.552943936394975, 'agent_0': 13.720570420540753, 'agent_1': 13.720570420540753, 'agent_2': 13.720570420540753}
model saving.................................
episode:  3 training step:  61 loss of agent  0 :  0.1211920827627182
episode:  3 training step:  61 loss of agent  1 :  0.2009807527065277
episode:  3 training step:  61 loss of agent  2 :  0.18552397191524506
episode:  3 training step:  61 loss of agent  3 :  0.18985502421855927
episode:  3 training step:  62 loss of agent  0 :  0.09121830761432648
episode:  3 training step:  62 loss of agent  1 :  0.15526442229747772
episode:  3 training step:  62 loss of agent  2 :  0.1476820558309555
episode:  3 training step:  62 loss of agent  3 :  0.22087234258651733
episode:  3 training step:  63 loss of agent  0 :  0.07706501334905624
episode:  3 training step:  63 loss of agent  1 :  0.26182857155799866
episode:  3 training step:  63 loss of agent  2 :  0.21682117879390717
episode:  3 training step:  63 loss of agent  3 :  0.2974541485309601
episode:  3 training step:  64 loss of agent  0 :  0.12057435512542725
episode:  3 training step:  64 loss of agent  1 :  0.2540818750858307
episode:  3 training step:  64 loss of agent  2 :  0.19787408411502838
episode:  3 training step:  64 loss of agent  3 :  0.2537940442562103
episode:  3 training step:  65 loss of agent  0 :  0.10131598263978958
episode:  3 training step:  65 loss of agent  1 :  0.1616481989622116
episode:  3 training step:  65 loss of agent  2 :  0.2701144814491272
episode:  3 training step:  65 loss of agent  3 :  0.25324004888534546
Evaluation
env seed: 6 evaluation score at the training step:  65 :  {'adversary_0': -34.857523396943755, 'agent_0': 13.105594034434636, 'agent_1': 13.105594034434636, 'agent_2': 13.105594034434636}
episode:  3 training step:  66 loss of agent  0 :  0.13208603858947754
episode:  3 training step:  66 loss of agent  1 :  0.267286479473114
episode:  3 training step:  66 loss of agent  2 :  0.23972952365875244
episode:  3 training step:  66 loss of agent  3 :  0.18600749969482422
episode:  3 training step:  67 loss of agent  0 :  0.1489928960800171
episode:  3 training step:  67 loss of agent  1 :  0.2658957839012146
episode:  3 training step:  67 loss of agent  2 :  0.27592194080352783
episode:  3 training step:  67 loss of agent  3 :  0.23065808415412903
episode:  3 training step:  68 loss of agent  0 :  0.14529691636562347
episode:  3 training step:  68 loss of agent  1 :  0.21569673717021942
episode:  3 training step:  68 loss of agent  2 :  0.28406450152397156
episode:  3 training step:  68 loss of agent  3 :  0.21497571468353271
episode:  3 training step:  69 loss of agent  0 :  0.15938672423362732
episode:  3 training step:  69 loss of agent  1 :  0.2281496673822403
episode:  3 training step:  69 loss of agent  2 :  0.37683066725730896
episode:  3 training step:  69 loss of agent  3 :  0.2612344026565552
episode 3 terminated at 175
epoch: 1
episode:  3 training step:  70 loss of agent  0 :  0.13272549211978912
episode:  3 training step:  70 loss of agent  1 :  0.2763689160346985
episode:  3 training step:  70 loss of agent  2 :  0.32818731665611267
episode:  3 training step:  70 loss of agent  3 :  0.3039211332798004
Evaluation
env seed: 6 evaluation score at the training step:  70 :  {'adversary_0': -35.416310666749595, 'agent_0': 11.793287031424724, 'agent_1': 11.793287031424724, 'agent_2': 11.793287031424724}
model saving.................................
episode:  3 training step:  71 loss of agent  0 :  0.1196315586566925
episode:  3 training step:  71 loss of agent  1 :  0.2522357404232025
episode:  3 training step:  71 loss of agent  2 :  0.24499428272247314
episode:  3 training step:  71 loss of agent  3 :  0.2673247456550598
episode:  3 training step:  72 loss of agent  0 :  0.10965728014707565
episode:  3 training step:  72 loss of agent  1 :  0.2436397224664688
episode:  3 training step:  72 loss of agent  2 :  0.1826302856206894
episode:  3 training step:  72 loss of agent  3 :  0.33082160353660583
episode:  3 training step:  73 loss of agent  0 :  0.10623426735401154
episode:  3 training step:  73 loss of agent  1 :  0.21809613704681396
episode:  3 training step:  73 loss of agent  2 :  0.2703522741794586
episode:  3 training step:  73 loss of agent  3 :  0.28555989265441895
episode:  3 training step:  74 loss of agent  0 :  0.09020944684743881
episode:  3 training step:  74 loss of agent  1 :  0.20530927181243896
episode:  3 training step:  74 loss of agent  2 :  0.21756809949874878
episode:  3 training step:  74 loss of agent  3 :  0.23503543436527252
episode:  3 training step:  75 loss of agent  0 :  0.11097272485494614
episode:  3 training step:  75 loss of agent  1 :  0.179009810090065
episode:  3 training step:  75 loss of agent  2 :  0.2074444591999054
episode:  3 training step:  75 loss of agent  3 :  0.20979906618595123
Evaluation
env seed: 6 evaluation score at the training step:  75 :  {'adversary_0': -35.2933040140107, 'agent_0': 11.054679024342825, 'agent_1': 11.054679024342825, 'agent_2': 11.054679024342825}
episode:  3 training step:  76 loss of agent  0 :  0.13061565160751343
episode:  3 training step:  76 loss of agent  1 :  0.315282940864563
episode:  3 training step:  76 loss of agent  2 :  0.27058154344558716
episode:  3 training step:  76 loss of agent  3 :  0.3261399567127228
episode:  3 training step:  77 loss of agent  0 :  0.13414546847343445
episode:  3 training step:  77 loss of agent  1 :  0.2957952320575714
episode:  3 training step:  77 loss of agent  2 :  0.2631099820137024
episode:  3 training step:  77 loss of agent  3 :  0.3412952721118927
episode:  3 training step:  78 loss of agent  0 :  0.15849284827709198
episode:  3 training step:  78 loss of agent  1 :  0.3229163587093353
episode:  3 training step:  78 loss of agent  2 :  0.30960649251937866
episode:  3 training step:  78 loss of agent  3 :  0.24894662201404572
episode:  3 training step:  79 loss of agent  0 :  0.14367499947547913
episode:  3 training step:  79 loss of agent  1 :  0.2043602466583252
episode:  3 training step:  79 loss of agent  2 :  0.26192355155944824
episode:  3 training step:  79 loss of agent  3 :  0.31540071964263916
episode:  3 training step:  80 loss of agent  0 :  0.13221870362758636
episode:  3 training step:  80 loss of agent  1 :  0.1890440285205841
episode:  3 training step:  80 loss of agent  2 :  0.2044954150915146
episode:  3 training step:  80 loss of agent  3 :  0.261741042137146
Evaluation
env seed: 6 evaluation score at the training step:  80 :  {'adversary_0': -35.16373412400802, 'agent_0': 10.731164640958392, 'agent_1': 10.731164640958392, 'agent_2': 10.731164640958392}
model saving.................................
Traceback (most recent call last):
  File "c:\Users\amalj\OneDrive\Desktop\lecture materials\S3\Research Project\Local Git Repo\Adversarial-MATL\Transfer learning in simple adversarial MPE env\ddDQN parallel api\main.py", line 156, in <module>
    transfer_and_train(agent_models, agent_buffers, num_games, env, eval_env, n_good_agents_target, n_good_agents_source)
  File "c:\Users\amalj\OneDrive\Desktop\lecture materials\S3\Research Project\Local Git Repo\Adversarial-MATL\Transfer learning in simple adversarial MPE env\ddDQN parallel api\main.py", line 115, in transfer_and_train
    loop_iteration(num_games, env, eval_env, opt, agent_models, agent_buffers, good_agents, epochs)
  File "c:\Users\amalj\OneDrive\Desktop\lecture materials\S3\Research Project\Local Git Repo\Adversarial-MATL\Transfer learning in simple adversarial MPE env\ddDQN parallel api\utils.py", line 117, in loop_iteration
    model.save(f"{algo}_{a}",EnvName)
  File "c:\Users\amalj\OneDrive\Desktop\lecture materials\S3\Research Project\Local Git Repo\Adversarial-MATL\Transfer learning in simple adversarial MPE env\ddDQN parallel api\dddqn.py", line 145, in save
    torch.save(self.q_net.state_dict(), save_path)
  File "C:\Users\amalj\anaconda3\lib\site-packages\torch\serialization.py", line 618, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "C:\Users\amalj\anaconda3\lib\site-packages\torch\serialization.py", line 492, in _open_zipfile_writer
    return container(name_or_buffer)
  File "C:\Users\amalj\anaconda3\lib\site-packages\torch\serialization.py", line 463, in __init__
    super().__init__(torch._C.PyTorchFileWriter(self.name))
RuntimeError: File ./ddDQN parallel api/model/dddQN_target_agent_3_simple_adversary_3Good_Agents.pth cannot be opened.