game: 0 black_0 's iteration: 1  trajectory 1 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 1  trajectory 1 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 2  trajectory 2 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 2  trajectory 2 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 3  trajectory 3 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 3  trajectory 3 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 4  trajectory 4 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 4  trajectory 4 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 5  trajectory 5 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 5  trajectory 5 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 6  trajectory 6 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 6  trajectory 6 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 7  trajectory 7 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 7  trajectory 7 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 8  trajectory 8 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 8  trajectory 8 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 9  trajectory 9 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 9  trajectory 9 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 10  trajectory 10 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 10  trajectory 10 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 11  trajectory 11 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 11  trajectory 11 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 12  trajectory 12 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 12  trajectory 12 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 13  trajectory 13 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 13  trajectory 13 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 14  trajectory 14 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 14  trajectory 14 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 15  trajectory 15 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 15  trajectory 15 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 16  trajectory 16 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 16  trajectory 16 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 17  trajectory 17 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 17  trajectory 17 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 18  trajectory 18 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 18  trajectory 18 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 19  trajectory 19 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 19  trajectory 19 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 20  trajectory 20 for  black_0  saved in memory. done flag: False reward:  0.0
Backend QtAgg is interactive backend. Turning interactive mode on.
game: 0 white_0 's iteration: 20  trajectory 20 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 21  trajectory 21 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 21  trajectory 21 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 22  trajectory 22 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 22  trajectory 22 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 23  trajectory 23 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 23  trajectory 23 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 24  trajectory 24 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 24  trajectory 24 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 25  trajectory 25 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 25  trajectory 25 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 26  trajectory 26 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 26  trajectory 26 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 27  trajectory 27 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 27  trajectory 27 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 28  trajectory 28 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 28  trajectory 28 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 29  trajectory 29 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 29  trajectory 29 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 30  trajectory 30 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 30  trajectory 30 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 31  trajectory 31 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 31  trajectory 31 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 32  trajectory 32 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 32  trajectory 32 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 33  trajectory 33 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 33  trajectory 33 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 34  trajectory 34 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 34  trajectory 34 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 35  trajectory 35 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 35  trajectory 35 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 36  trajectory 36 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 36  trajectory 36 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 37  trajectory 37 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 37  trajectory 37 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 38  trajectory 38 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 38  trajectory 38 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 39  trajectory 39 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 39  trajectory 39 for  white_0  saved in memory. done flag: False reward:  0.0
game: 0 black_0 's iteration: 40  trajectory 40 for  black_0  saved in memory. done flag: False reward:  0.0
game: 0 white_0 's iteration: 40  trajectory 40 for  white_0  saved in memory. done flag: False reward:  0.0
Traceback (most recent call last):
  File "c:\Users\amalj\anaconda3\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "c:\Users\amalj\anaconda3\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "c:\Users\amalj\.vscode\extensions\ms-python.debugpy-2024.2.0-win32-x64\bundled\libs\debugpy\__main__.py", line 39, in <module>
    cli.main()
  File "c:\Users\amalj\.vscode\extensions\ms-python.debugpy-2024.2.0-win32-x64\bundled\libs\debugpy/..\debugpy\server\cli.py", line 430, in main
    run()
  File "c:\Users\amalj\.vscode\extensions\ms-python.debugpy-2024.2.0-win32-x64\bundled\libs\debugpy/..\debugpy\server\cli.py", line 284, in run_file
    runpy.run_path(target, run_name="__main__")
  File "c:\Users\amalj\.vscode\extensions\ms-python.debugpy-2024.2.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\_pydevd_bundle\pydevd_runpy.py", line 321, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "c:\Users\amalj\.vscode\extensions\ms-python.debugpy-2024.2.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\_pydevd_bundle\pydevd_runpy.py", line 135, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "c:\Users\amalj\.vscode\extensions\ms-python.debugpy-2024.2.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\_pydevd_bundle\pydevd_runpy.py", line 124, in _run_code
    exec(code, run_globals)
  File "C:\Users\amalj\OneDrive\Desktop\lecture materials\S3\Research Project\Local Git Repo\Adversarial-MATL\Transfer learning in simple adversarial MPE env\PPO\main.py", line 96, in <module>
    env.step(action)
  File "c:\Users\amalj\anaconda3\lib\site-packages\pettingzoo\utils\wrappers\order_enforcing.py", line 91, in step
    super().step(action)
  File "c:\Users\amalj\anaconda3\lib\site-packages\pettingzoo\utils\wrappers\base.py", line 116, in step
    self.env.step(action)
  File "c:\Users\amalj\anaconda3\lib\site-packages\pettingzoo\utils\wrappers\assert_out_of_bounds.py", line 18, in step
    action is None
AssertionError: action is not in action space